{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanZapa7a/Medical-Image-Processing/blob/main/NB4-02%20Getting%20Started%20with%20Roboflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03T45nGa2flV"
      },
      "source": [
        "# [Getting Started with Roboflow](https://blog.roboflow.com/getting-started-with-roboflow/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W21hJ4Uxdi24"
      },
      "source": [
        "\n",
        "## 1. Introduction to [Roboflow](https://docs.roboflow.com/api-reference/introduction)\n",
        "\n",
        "**`Roboflow`** is a platform that _`simplifies the process of building machine learning models`_. It provides tools for data management, annotation, preprocessing, model augmentation and deployment. Roboflow is popular among developers, with over 100,000 developers having built with [Roboflow tools](https://github.com/roboflow). Despite its popularity, there are alternatives to Roboflow, such as [INTSIG](https://www.intsig.us/), [SuperAnnotate](https://www.superannotate.com/), [Google Cloud Vision API](https://cloud.google.com/vision?hl=es) and [Encord](https://encord.com/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bryb_neRdi25"
      },
      "source": [
        "\n",
        "### Limitations of the free version of Roboflow:\n",
        "\n",
        "The free version of Roboflow allows up to _`3 users. Up to 10,000 source images can be managed. 3 training credits are provided. 1,000 inference credits`_ are awarded _`per month`_. Projects, including datasets, are open source to contribute to the community.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCkC8P2ddi25"
      },
      "source": [
        "\n",
        "### Roboflow integration with Google Colab:\n",
        "\n",
        "_`Roboflow integrates well with Google Colab`_. In fact, Roboflow has produced dozens of workbooks showing how to train computer vision models in Google Colab. Roboflow _`maintains a repository called `[`Notebooks`](https://github.com/roboflow/notebooks)_. These workbooks are _`step-by-step guides on how to train models`_ and perform other computer vision tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpH3FV9-QrP3"
      },
      "source": [
        "A _`normal procedure in order to start using Roboflow with Google Colab`_ is as follows:\n",
        "\n",
        "```python\n",
        "# Step 0: Mount your google Drive (it is not strictly necessary)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "```\n",
        "``` python\n",
        "# Step 1: Install Roboflow CLI\n",
        "%pip install --upgrade pip -q\n",
        "%pip install roboflow -q\n",
        "\n",
        "# Step 2: Import the necessary libraries\n",
        "import os\n",
        "import roboflow\n",
        "\n",
        "# Step 3: Log in to Roboflow with your private API KEY\n",
        "rf = roboflow.Roboflow(api_key=\"yourapikey\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ac2tLOMdi27"
      },
      "source": [
        "\n",
        "Your _`private api key is in Settings > Roboflow API in Private API key`_.\n",
        "\n",
        "But first, _**`YOU NEED OBTAIN A ROBOFLOW ACCOUNT`**_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1S1ydKEInCg"
      },
      "source": [
        "## 2. Creating a RoboFlow Account\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpgxpi1nQrP4"
      },
      "source": [
        "---\n",
        "**Follow this link to [create a free Roboflow account](https://app.roboflow.com/?ref=blog.roboflow.com)**\n",
        "\n",
        "---\n",
        "To get started, create a free Roboflow account. For example, my account is associated to GitHub. _`In order to explain the process I am going to create a new account from scratch`_.\n",
        "\n",
        "After _`accepting the terms of service`_ and saving your account, you will be asked to choose between one of two plans: the _`Public Plan`_ and the _`Starter Plan`_. _`Select public plan and name your workspace. \"i.e: PIM\". `_\n",
        "\n",
        "![image.png](https://blog.roboflow.com/content/images/size/w1000/2024/02/Screenshot-2024-02-12-at-09.31.24.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnzy0F3fQrP4"
      },
      "source": [
        "\n",
        "---\n",
        "**Push `Create Workspace`**\n",
        "\n",
        "---\n",
        "\n",
        "Then, _`you will be asked to invite collaborators to your workspace`_. These collaborators can help you annotate images or manage the vision projects in your workspace. Once you have invited people to your workspace (if you want to), you will be able to create a project. You can press _**`Continue without adding others`**_ if you don't want invite to anyone.\n",
        "\n",
        "![imagen10](https://github.com/JuanZapa7a/covid-19/blob/master/2024-09-18_09-52.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRk5GbSLQrP4"
      },
      "source": [
        "\n",
        "---\n",
        "**Press `Continue without adding others`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7Z0aWMX86-N"
      },
      "source": [
        "\n",
        "## 3. Create your project\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0SoY3l3di28"
      },
      "source": [
        "\n",
        "For this example, we will be using a _`dataset of cells`_ to train a model that can _`identify cells for counting`_. This model could be used for medical analysis in a health facility. Having said that, you can use any images you want to train a model.\n",
        "\n",
        "_`Leave the project type as the default \"Object Detection\" option`_ since our model will be identifying specific objects and we want to know their location within the image.\n",
        "\n",
        "- _`Project Name`_: (i.e Count-cells)\n",
        "- _`Annotattion Group`_: (i.e. cells)\n",
        "\n",
        "Next, **Click `Create Public Project.`**\n",
        "\n",
        "![image.png](https://blog.roboflow.com/content/images/size/w1000/2024/02/Screenshot-2024-02-12-at-10.02.25.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGKPjgWBQrP5"
      },
      "source": [
        "\n",
        "---\n",
        "**Click `Create Public Project`**.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJuZD72tUOrZ"
      },
      "source": [
        "Instead of uploading our own database, we will utilize a dataset from _``Roboflow Universe, a massive repository of datasets contributed by Roboflow users``_. This repository offers a vast collection of computer vision datasets, covering object detection, classification, and segmentation tasks.\n",
        "\n",
        "To access these datasets, we can:\n",
        " - _``Drag and drop a dataset from Roboflow Universe into our workflow``_\n",
        " - _``Upload a dataset from Roboflow Universe using their import command``_\n",
        " - _``Choose from a wide range of publicly available datasets, with millions of images available for various computer vision tasks``_\n",
        "\n",
        "By leveraging Roboflow Universe, we can save time and effort, as well as benefit from the collective contributions of the Roboflow community. This approach also enables us to focus on building and deploying our computer vision models, rather than creating and managing our own dataset from scratch.\n",
        "\n",
        "For this walkthrough, we’ll use a Roboflow provided sample cell dataset ([``Count-cells``](https://universe.roboflow.com/harito/cells-rez5s)`` by Harito `cells-upja` ``).\n",
        "\n",
        "`We are going to download this dataset to local, extract its contents which we will place in a folder on our local drive, and upload it to our project`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S2N-BsrUikX"
      },
      "source": [
        "---\n",
        "**Press this link [Count-cells](https://universe.roboflow.com/harito/cells-rez5s)**.\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmjM97gadi29"
      },
      "source": [
        "![imagen1](https://github.com/JuanZapa7a/covid-19/blob/master/2024-09-18_10-07.png?raw=1)\n",
        "\n",
        "Now you can _`press in the left side in Dataset`_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViUiJO6iQrP5"
      },
      "source": [
        "---\n",
        "**Press `Dataset`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPfP0LPQQrP6"
      },
      "source": [
        "\n",
        "\n",
        "![imagen1](https://github.com/JuanZapa7a/covid-19/blob/master/2024-09-18_10-13.png?raw=1)\n",
        "\n",
        "Now you can _`press Download Dataset`_ on the right side."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVqLTJzEQrP6"
      },
      "source": [
        "\n",
        "---\n",
        " **Press  `Download Dataset`**.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWfxQlseQrP6"
      },
      "source": [
        "\n",
        "![imagen1](https://github.com/JuanZapa7a/covid-19/blob/master/2024-09-17_12-38.png?raw=1)\n",
        "\n",
        "\n",
        "  - You can select : _`download zip to computer`_ or _`show dowload code`_ to be used in a notebook.\n",
        "  - This time, _`we will download the zip file using COCO JSON format`_.\n",
        "\n",
        "Therefore, _`Check Download zip to computer and then press Continue`_ .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWui9RuoQrP6"
      },
      "source": [
        "\n",
        "---\n",
        "**Check `Download zip to computer` and press `Continue`**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fv7YfSBQrP6"
      },
      "source": [
        "\n",
        "Next, Roboflow shows us the possible models that we can use to train the dataset. Among them, we can highlight YOLOv8, YOLOv5, and YOLOv7 and many more, which we will study further during the course.\n",
        "\n",
        "![imagen2](https://github.com/JuanZapa7a/covid-19/blob/master/2024-09-17_12-45.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsZn2vM6QrP6"
      },
      "source": [
        "\n",
        "---\n",
        "**Press `Done`**\n",
        "\n",
        "---\n",
        "\n",
        "Once you have downloaded the dataset, you have to _``unzip the file in a local folder (i.e., Cells)``_. _`Click and drag the folder from your local machine onto the highlighted upload area`_. This dataset is structured in the COCO JSON format, [one of 40+ computer vision formats Roboflow supports](https://roboflow.com/formats?ref=blog.roboflow.com).\n",
        "\n",
        "![imagen3](https://github.com/JuanZapa7a/covid-19/blob/master/2024-09-17_12-50.png?raw=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88TPbWdqQrP6"
      },
      "source": [
        "\n",
        "---\n",
        "**Extract the file `Cells.v1i.coco.zip` in a local folder and `drop the folder` onto the highlighted upload area**\n",
        "\n",
        "---\n",
        "\n",
        "Once you drop the cell-dataset folder into Roboflow, the images and annotations are processed for you to see them overlayed.\n",
        "\n",
        "![image2](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_11-19.png?raw=1)\n",
        "\n",
        "_`If any of your annotations have errors, Roboflow alerts you`_. For example, if some of the annotations improperly extended beyond the frame of an image, Roboflow intelligently crops the edge of the annotation to line up with the edge of the image and drops erroneous annotations that lie fully outside the image frame.\n",
        "\n",
        "**At this point, _`our images have not yet been uploaded to Roboflow`_**. We can verify that all the images are, indeed, the ones we want to include in our dataset and that our annotations are being parsed properly._`Any image can be deleted upon mousing over it and selecting the red trash icon`_.\n",
        "\n",
        "**``Note that one of our images is marked as ``_`\"Not Annotated\"`_** on the dashboard. We'll annotate this image in the next section.\n",
        "\n",
        "Everything now looks good. Click **`“Save and Continue”`** in the upper right-hand corner to upload your data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LukFuSpDQrP6"
      },
      "source": [
        "\n",
        "---\n",
        "**Click `Save and Continue`**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjcsy4ub86-O"
      },
      "source": [
        "\n",
        "## 4. Spliting our Dataset: Train, Test and Valid Sets\n",
        "**You will be asked to choose a dataset split**. This refers to how images will be split between three sets: `Train, Test, and Valid`.\n",
        "\n",
        "1. Your train set contains the images that will be used to train your model.\n",
        "2. Your valid set will be used during training to validate performance of your model.\n",
        "3. Your test set contains images you can use to manually test the performance of your model. Learn more about [image dataset splits](https://blog.roboflow.com/train-test-split/) and why to use them.\n",
        "\n",
        "You can set your own custom splits with Roboflow or, if one is available, use an existing split in a dataset. Our dataset has already been split with Roboflow, so _``we can choose the \"Use existing values\" option``_ when asked how to split our images and _``Clik \"Continue\"``_:\n",
        "\n",
        "![image3](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_11-41.png?raw=1)\n",
        "\n",
        ">**NOTE**: You can [upload videos](https://blog.roboflow.com/youtube-video-computer-vision/) as well as images. We already have enough images for our project, but we'll talk through this process in case you want to add video data to your projects in the future.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkbI9V8rQrP6"
      },
      "source": [
        "---\n",
        "**Push `Continue`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEEJ2GZ486-O"
      },
      "source": [
        "\n",
        "## 5. Annotate Images\n",
        "\n",
        "One of the images in the sample dataset is not yet annotated. _`You will use `[`Roboflow Annotate`](https://roboflow.com/annotate?ref=blog.roboflow.com)` to `[`add a box (or boxes) around the unlabeled cells`](https://youtu.be/O-ZPxTpb2Yg?t=220&ref=blog.roboflow.com)` in the image`_.\n",
        "\n",
        "_`Annotations are the answer key from which your model learns`_. The more annotated images we add, the more information our model has to learn what each class is (_`in our case, more images will help our model identify what is a cell`_).\n",
        "\n",
        "1. With _``Roboflow ``_[_``Label Assist``_](https://blog.roboflow.com/announcing-label-assist/) `\"Auto Label\"`, you can use previous versions of your model to annotate future versions. _``Label Assist uses another model to draw annotations on images for you``_, which means you can spend less time annotating and get a model ready for production faster than ever. You can use publicly available models hosted on [Roboflow Universe, our dataset community, for label assist](https://blog.roboflow.com/launch-universe-model-checkpoint/), too.\n",
        "2. _``Roboflow Labeling is not free``_. It is a paid service that offers professional annotation by human labelers for your datasets. Access to Roboflow Labeling requires purchasing a Starter Plan. Bounding Box annotations start at $0.04$ and Polygon annotations start at $0.08$.\n",
        "3. _``Manual Labeling``_. This is the _``normal first use when you have a dataset without annotations``_. In first place, you manual annotate some images and you train a model which is used to labelled the rest of images with \"Auto Label\". Click `\"Start Manual Labeling\"`\n",
        "\n",
        "\n",
        "![image6](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-01.png?raw=1)\n",
        "\n",
        "\n",
        "You can _**`start a Auto Label`**, **`Start Roboflow labeling`** or **`Start Manual Labeling`**_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KPkXfuGQrP7"
      },
      "source": [
        "\n",
        "---\n",
        "**Push in `Start Manual labeling`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vHyZ2iZdi2-"
      },
      "source": [
        "\n",
        "\n",
        "Next, you can assign this task to a teammate with _`Invite Teammate` or `assign to myself`_.\n",
        "\n",
        "![image6b](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-10_10-39.png?raw=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkXKS5PFQrP7"
      },
      "source": [
        "\n",
        "---\n",
        "**Click `Assign to Myself`**\n",
        "\n",
        "---\n",
        "\n",
        "Now you can see that there is annotation work to be done and the labeler is yourself.\n",
        "\n",
        "![image6c](https://github.com/JuanZapa7a/covid-19/blob/master/2024-09-18_10-36.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et23ZPmaQrP7"
      },
      "source": [
        "\n",
        "---\n",
        "**Click on `Start Annotating`**\n",
        "\n",
        "---\n",
        "\n",
        "_`Use your cursor to drag a box around the area on the chess board you want to annotate`_. A box will appear in which you can enter the label to add. In the example below, we will add boxes around cells, and assign the corresponding class: `\"Cells-upja\"`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTxZlgI9di2-"
      },
      "source": [
        "\n",
        "![image7](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-15.png?raw=1)\n",
        "\n",
        "You can also label datasets with polygons, which are shapes with multiple points drawn around an object. Using [polygons to label for object detection](https://blog.roboflow.com/polygon-vs-bounding-box-computer-vision-annotation/) may result in a small boost in model performance.\n",
        "\n",
        "Polygons are essential for _`instance segmentation`_ projects where you want to identify the exact location, to the pixel, of an object in an image. Roboflow offers a few tools to help with labeling with polygons. _``You can manually label polygons using the ``[``Polygon annotation tool``](https://blog.roboflow.com/polygon-annotation-labeling/)`` or you can use ``[``Smart Polygon``](https://blog.roboflow.com/automated-polygon-labeling-computer-vision/)`` to label objects with one click``_.\n",
        "\n",
        "_``To enable Smart Polygon, click the cursor with sparkles icon in the right sidebar``_, above the magic wand icon. A window will pop up that asks what version of Smart Polygon you want to enable.\n",
        "\n",
        "---\n",
        "**Click the `cursor with sparkles`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opwUY8Z9di2_"
      },
      "source": [
        "\n",
        "\n",
        "![image9](https://blog.roboflow.com/content/images/2024/02/Screenshot-2024-02-12-at-10.18.39.png)\n",
        "\n",
        "---\n",
        "**Click `Enhanced`**\n",
        "\n",
        "---\n",
        "\n",
        "_``When Smart Polygon has loaded, you can point and click anywhere on an image to create a label``_. When you hover over an object, a red mask will appear that lets you see what region of the object Smart Polygon will label if you click.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SuK2Yo5di2_"
      },
      "source": [
        "\n",
        "\n",
        "![image8](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-27.png?raw=1)\n",
        "\n",
        "\n",
        "We can move the polygone and clear it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulVLIzzkdi2_"
      },
      "source": [
        "\n",
        "\n",
        "### Annotation Comments and History\n",
        "\n",
        "Need help from a team member on an annotation? Want to leave yourself a note for later on a particular image? We have you covered. _`Click the speech bubble icon on the sidebar of the annotation tool. Then, click the place on the image you want to leave a comment.`_\n",
        "\n",
        "If you have multiple people working with you on a project, you can tag them by using the @ sign, followed by their name. They will get a notification that you have commented and requested their assistance.\n",
        "\n",
        "We can see the history of our annotated image in the sidebar. To view a project at a previous point in the history, hover over the state in history that you want to preview.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tESK-PYCQrP8"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Click `<--`**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yToInFwjQrP8"
      },
      "source": [
        "\n",
        "Next, click `Add 1 Image to Dataset` to add your image to the dataset\n",
        "\n",
        "![image9](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-33.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3VcXhYSQrP8"
      },
      "source": [
        "\n",
        "---\n",
        "**Click `Add 1 Image to Dataset`**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrblPAaCQrP8"
      },
      "source": [
        "\n",
        "and then click `add images` to confirm:\n",
        "\n",
        "![image10](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-34.png?raw=1)\n",
        "\n",
        "You can search the images in your dataset by clicking \"Dataset\" in the sidebar. The search bar runs a [semantic search on your dataset](https://blog.roboflow.com/dataset-search/) to find images related to your query. For example, if we had images with blood, leucocytes, cells, and blastocytes, we could search through them with ease.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMtt7uXhQrP8"
      },
      "source": [
        "\n",
        "---\n",
        "**Click `Add Images` to Dataset**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6yvetFQ86-O"
      },
      "source": [
        "\n",
        "## 7. Preprocessing and Augmentations\n",
        "After you're done annotating and have added your annotated image to your dataset, continue to [generate a new version of your dataset](https://youtu.be/O-ZPxTpb2Yg?t=287&ref=blog.roboflow.com). This creates a point-in-time snapshot of your images processed in a particular way (think of it a bit like version control for data).\n",
        "\n",
        "\n",
        "\n",
        "![imag11](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_13-09.png?raw=1)\n",
        "\n",
        "---\n",
        "**Click in `Create new Version`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqoOQTF5di2_"
      },
      "source": [
        "\n",
        "![imag12](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_13-13.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOlHVnC9di2_"
      },
      "source": [
        "\n",
        "From here, we can apply any [preprocessing](https://docs.roboflow.com/image-transformations/image-preprocessing?ref=blog.roboflow.com) and [augmentation](https://docs.roboflow.com/image-transformations/image-augmentation?ref=blog.roboflow.com) steps that we want to our images. Roboflow seamlessly makes sure all of your annotations correctly bound each of your labeled o\n",
        "\n",
        "> ``By default``, Roboflow opts you into two preprocessing steps: _``auto-orient and resize``_. Auto-orient assures your images are stored on disk the same way your applications open them for you. Resize creates a consistent size for your images, in this case smaller, to expedite training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkdCN4CFQrP8"
      },
      "source": [
        "\n",
        "---\n",
        "**In Prepocesing, Click `Continue`**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvzbya8DQrP8"
      },
      "source": [
        "\n",
        "_`You can also choose to augment your images which generates multiple variations of each source image to help your model generalize better`_.\n",
        "\n",
        "Roboflow supports auto-orient corrections, resizing, grayscaling, contrast adjustments, random flips, random 90-degree rotations, random 0 to N-degree rotations, random brightness modifications, Gaussian blurring, random shearing, random cropping, random noise, and much more. To better understand these options, refer to our [documentation](https://docs.roboflow.com/?ref=blog.roboflow.com).\n",
        "\n",
        "\n",
        "\n",
        "> We recommend starting with one or two augmentations that may work with a dataset, and adding more further down the line if necessary. Adding more augmentations does not necessarily boost the performance of your model.\n",
        "\n",
        "Roboflow recommend applying no augmentations on your first model training job. This is so that you can understand how your model performs without augmentations. If your model performs poorly without augmentations, it is likely you need to revisit your dataset to ask questions like: Are all my images labeled? Are my images consistently labeled? Do my images contain a balance of the classes I want to identify?\n",
        "\n",
        "With that said, we have done some experimentation so you can achieve the best performance without tinkering with augmentation for this cell dataset.\n",
        "\n",
        "For this project, we are going to apply two augmentations: Flip and Rotate.\n",
        "\n",
        "![imag12](https://github.com/JuanZapa7a/covid-19/blob/master/2024-09-18_10-50.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6fmJDezQrP9"
      },
      "source": [
        "\n",
        "---\n",
        "**In Augmentation, Click `Add Augmentation Step`**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuVnQKX_QrP9"
      },
      "source": [
        "\n",
        "We recommend these augmentations in IMAGE LEVEL AUGMENTATIONs _`Flip and 90Rotate`_ for our cell dataset since cells can appear at any angle and we want to identify a cell no matter how it is positioned.\n",
        "\n",
        "Having said that, these augmentations may not work for your data. If you are identifying an object that will only appear at one orientation (such as might be the case on cells micrographs), a flip augmentation will not help as much as others.\n",
        "\n",
        "To learn more about applying augmentations, refer to our [image augmentation and preprocessing guide](https://blog.roboflow.com/why-preprocess-augment/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeLjecv4QrP9"
      },
      "source": [
        "\n",
        "---\n",
        "**Click `Continue`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THVG5Tmadi3A"
      },
      "source": [
        "![imag13](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-11_09-53.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uurg_7wgdi3A"
      },
      "source": [
        "\n",
        "To generate your dataset, click the `Create` button at the bottom of the page.\n",
        "\n",
        "---\n",
        "**Click `Create`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psdeIddNdi3A"
      },
      "source": [
        "\n",
        "It will take a few moments for your dataset to be ready. Then, you can use it to start training a model.\n",
        "\n",
        "\n",
        "![imag13](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-11_09-55.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9oum2Yd86-P"
      },
      "source": [
        "\n",
        "## 8. Prepare Data for Training\n",
        "\n",
        "Once you have generated your dataset, _`you can use it to train a model on the Roboflow platform`_.\n",
        "\n",
        "![imag13](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_09-38.png?raw=1)\n",
        "\n",
        "[Roboflow Train](https://blog.roboflow.com/new-and-improved-roboflow-train/) offers model types that you can train and host using Roboflow. They handle the GPU costs and also give you access to out-of-the-box optimized [deployment](https://docs.roboflow.com/inference?ref=blog.roboflow.com) options which we will cover later in this notebook.\n",
        "\n",
        "Your trained model can now be used in a few powerful ways:\n",
        "\n",
        "- [``Model-assisted labeling``](https://blog.roboflow.com/announcing-label-assist/) speeds up labeling and annotation for adding more data into your dataset\n",
        "- ``Rapid prototyping`` or testing your model on real-world data to test model performance (explained in the next section)\n",
        "- ``Deploying to production`` with out-of-the-box options that are optimized for your model to run on multiple different devices (explained in the next section)\n",
        "\n",
        "You can also _`export/download your dataset`_ for use in training a model on your own hardware. To export your data, click \"Download Dataset\" and select your desired export format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtRMnh7YQrP9"
      },
      "source": [
        "---\n",
        "**Click `Download Dataset`**\n",
        "\n",
        "---\n",
        "\n",
        "_``You can download dataset to local or download the code snipet for a notebook. Also train a model for label assist in order to help to label your dataset``_.\n",
        "\n",
        "![imag14b](https://github.com/JuanZapa7a/covid-19/blob/master/2024-09-17_18-04.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd3HbOwkQrP9"
      },
      "source": [
        "\n",
        "---\n",
        "**Select `cancel`**\n",
        "\n",
        "---\n",
        "\n",
        "For this guide, let's train a model on the Roboflow platform. To get started, `click the \"Train with Roboflow\" button`. A window will appear where you can configure your model training job.\n",
        "\n",
        "---\n",
        "**Click `train with Roboflow`**\n",
        "\n",
        "---\n",
        "\n",
        "![imag15](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_09-47.png?raw=1)\n",
        "\n",
        "First, you will be asked to choose which model to train. Each model has performance tradeoffs that you'll want to test for your unique use case.\n",
        "\n",
        "For this guide, choose by default  `\"Roboflow 3.0\"` and press `continue`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdXIiaarQrP9"
      },
      "source": [
        "---\n",
        "**Press `Continue`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6VHm8xeQrP9"
      },
      "source": [
        "\n",
        "\n",
        "Then, you will then be asked to choose the model size. Choose \"fast\".\n",
        "\n",
        "![imag16](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_09-53.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_BCH_7rQrP9"
      },
      "source": [
        "\n",
        "---\n",
        "**Press `Continue`**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgi212hrQrP-"
      },
      "source": [
        "\n",
        "Next, You will then be asked to choose from what checkpoint you want to train.\n",
        "\n",
        "![imag17](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_09-56.png?raw=1)\n",
        "\n",
        "For the first version of a new model, we recommend training from the MS COCO checkpoint. This uses a model trained on the Microsoft COCO dataset as a \"checkpoint\" from which your model will start training. This should lead to the best performance you can achieve in your first model training job.\n",
        "\n",
        "When you have trained a version of a model, you can train using your last model as a checkpoint. This is ideal if you have trained a model that performs well that you are looking to improve. You can also use [models you have starred from Universe](https://blog.roboflow.com/launch-universe-model-checkpoint/) as a checkpoint.\n",
        "\n",
        "Click \"Start Training\" to start training your model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es_-PJOyQrP-"
      },
      "source": [
        "\n",
        "---\n",
        "**Click `Start Training`**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuiHDYFjQrP-"
      },
      "source": [
        "\n",
        "This will take between a few minutes and a day depending on how many images are in your dataset. Because our cell dataset contains less than four dozens images, we can expect the training process will not take too long.\n",
        "\n",
        "When you start training your model, an estimate will appear that shows roughly how long we think it will take for your model to train. You will see the message \"Training machine starting...\" while your model training job is allocated to a server. This may take a few moments.\n",
        "\n",
        "\n",
        "![imag18](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_10-00.png?raw=1)\n",
        "\n",
        "`Figure 1 (to be used by your NB)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpKMFPXdQrP-"
      },
      "source": [
        "---\n",
        "**Press `Okay`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96yw7ki-QrP-"
      },
      "source": [
        "\n",
        "When a machine has been assigned your dataset from which to train a model, a graph will appear on the page. This graph shows how your model is learning in real-time. As your model trains, the numbers may jump up and down. Over the long term, the lines should reach higher points on the chart.\n",
        "\n",
        "![imag19](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_10-08.png?raw=1)\n",
        "\n",
        "\n",
        "The higher the mean average precision (mAP) is, the better.\n",
        "\n",
        "💡\n",
        "> Precision is a measure of, \"when your model guesses how often does it guess correctly?\" Recall is a measure of \"has your model guessed every time that it should have guessed?\" Consider an image that has 10 red blood cells. A model that finds only one of these ten but correctly labels is as \"RBC\" has perfect precision (as every guess it makes – one – is correct) but imperfect recall (only one of ten RBC cells has been found).\n",
        "\n",
        "The mAP, precision, and recall statistics tell us about the performance of our model. You can learn more about what these statistics tell you in our guide to [mAP, precision, and recall](https://blog.roboflow.com/mean-average-precision/) and later during the course in different notebooks more in depth.\n",
        "\n",
        "You'll receive an email once your model has finished training. The email contains the training results for you to see how the model performed. If you need to improve performance, [we have recommendations](https://blog.roboflow.com/improve-computer-vision-model/) on how to do that.\n",
        "\n",
        "\n",
        "![image20](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_10-56.png?raw=1)\n",
        "\n",
        "`Figure 2 (to be used by your NB)`\n",
        "\n",
        "[View your training graphs](https://youtu.be/O-ZPxTpb2Yg?t=810&ref=blog.roboflow.com) for a more detailed view of model performance.\n",
        "\n",
        "![image21](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_11-00.png?raw=1)\n",
        "\n",
        "`Figure 3 (to be used by your NB)`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "``The term ``**``mAP@50:95``**`` (mean Average Precision at IoU 0.50 to 0.95) is a refined metric used in ``**``object detection``**`` tasks to evaluate a model's performance across different ``**``IoU thresholds``**`` (Intersection over Union)``. This gives a more comprehensive assessment of the model’s accuracy than using a single IoU threshold.\n",
        "\n",
        "### **IoU (Intersection over Union)**:\n",
        "Before explaining mAP@50:95, it's important to understand **IoU**. IoU measures the overlap between the predicted bounding box and the ground truth bounding box:\n",
        "\n",
        "$$\n",
        "\\text{IoU} = \\frac{\\text{Area of overlap}}{\\text{Area of union}}\n",
        "$$\n",
        "\n",
        "- **``Overlap``**: The area where the predicted and true bounding boxes intersect.\n",
        "- **``Union``**: The total area covered by both bounding boxes (combined area).\n",
        "\n",
        "``IoU is used to determine if a prediction is correct based on how well the predicted box overlaps with the actual object``. A higher IoU means the prediction is closer to the true object location.\n",
        "\n",
        "### **mAP@50 (mAP:0.5)**:\n",
        "- This is a specific case of **``mAP``**`` calculated using a ``**``fixed IoU threshold of 0.5``**.\n",
        "- An **IoU ≥ 0.5** means that if the overlap between the predicted and ground truth boxes is at least 50%, the prediction is considered correct.\n",
        "- In short, **mAP@50** evaluates how well the model detects objects with a 50% overlap tolerance.\n",
        "\n",
        "### **mAP@50:95 (mAP(0.5:0.95))**:\n",
        "- This is a **``generalized version``**`` of mAP that uses multiple ``**``IoU thresholds``**``, not just 0.5``.\n",
        "- It evaluates the model’s performance across a **range of IoU thresholds from 0.5 to 0.95**, increasing by 0.05 increments. Specifically, AP is calculated for the following IoU thresholds:\n",
        "  - **0.50**, **0.55**, **0.60**, **0.65**, ..., **0.95**.\n",
        "\n",
        "- The final mAP is the **average of the AP scores** computed at each IoU threshold.\n",
        "\n",
        "$$\n",
        "\\text{mAP@50:95} = \\frac{1}{10} \\sum_{IoU=0.50}^{0.95} AP(IoU)\n",
        "$$\n",
        "\n",
        "### Difference Between **mAP@50** and **mAP@50:95**:\n",
        "- **mAP@50**: A less strict metric, as it only requires a **50% overlap** (IoU ≥ 0.5) between the predicted and ground truth boxes for the prediction to be considered correct.\n",
        "- **mAP@50:95**: A more stringent metric because it evaluates performance over a **wider range of IoU thresholds**. Good performance on mAP@50:95 means the model is not only detecting objects correctly but also locating them more precisely.\n",
        "\n",
        "### Importance of **mAP@50:95**:\n",
        "- **``mAP@50``** is commonly used and simpler to interpret, but a model that performs well on **mAP@50:95** is more robust, as it is evaluated under stricter conditions.\n",
        "- **``mAP@50:95``** is the standard metric in benchmarks like the **COCO challenge**, as it provides a more complete evaluation of a model's ability, penalizing both poorly localized and imprecise predictions.\n",
        "\n",
        "### Practical Example:\n",
        "- A model with high **mAP@50** might detect objects well but have slightly imprecise bounding boxes.\n",
        "- A model with high **mAP@50:95** is more precise in both detection and localization.\n",
        "\n",
        "### Summary:\n",
        "- **mAP@50**: Computes the mean Average Precision using an IoU threshold of **0.5**. It’s a less strict evaluation.\n",
        "- **mAP@50:95**: Computes the mean Average Precision over a range of IoU thresholds from **0.5 to 0.95**. It’s a more comprehensive and rigorous metric for object detection performance."
      ],
      "metadata": {
        "id": "lSCOsJwjV2MO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvSzl9Ozc0Ua"
      },
      "source": [
        "## `NoteBook Practice 2`\n",
        "\n",
        "---\n",
        "Use this guide to create an account on Roboflow and follow the steps in the guide until you train a model on this database or a similar one (preferably). To obtain better metrics than those obtained in this guide will be valued.\n",
        "\n",
        "In your NB you must show figure 1, 2 and 3\n",
        "\n",
        "---\n",
        "\n",
        "### Instructions to improve the NoteBook (study and work about it by yourself):\n",
        "\n",
        "ChatGPT can be your great allied. Use it for your convenenceandnot necessary for this notebook.\n",
        "\n",
        "1. **Data Augmentation**:\n",
        "   - Increase the variability in your dataset by applying various data augmentation techniques such as rotation, flipping, scaling, cropping, and color adjustments.\n",
        "   - Ensure the augmented images still represent the original class accurately.\n",
        "\n",
        "2. **Increase Dataset Size**:\n",
        "   - If possible, add more annotated images to your dataset. A larger dataset can help the model generalize better.\n",
        "\n",
        "3. **Adjust Hyperparameters**:\n",
        "   - Experiment with different learning rates. A too high learning rate might cause the model to converge too quickly to a suboptimal solution, while a too low learning rate might make the training process very slow.\n",
        "   \n",
        "4. **Model Architecture**:\n",
        "   - Try using a different model architecture or a more complex one if you have sufficient computational resources. For example, consider using YOLOv5, EfficientDet, or other state-of-the-art object detection models.\n",
        "   - If using a pre-trained model, ensure that the model is fine-tuned properly for your specific dataset.\n",
        "\n",
        "5. **Training Time**:\n",
        "   - Train the model for more epochs but keep an eye on the validation loss to avoid overfitting. Early stopping can be a useful technique to halt training when the validation loss stops improving.\n",
        "\n",
        "6. **Cross-Validation**:\n",
        "   - Implement cross-validation to ensure that your model performs well across different subsets of your data. This helps in verifying that the model generalizes well.\n",
        "\n",
        "7. **Optimize Anchors**:\n",
        "   - Optimize anchor boxes based on your dataset. Properly sized anchor boxes can improve the model's ability to detect objects more accurately.\n",
        "\n",
        "8. **Post-Processing**:\n",
        "   - Fine-tune the Non-Maximum Suppression (NMS) parameters to reduce false positives and improve the precision of the model.\n",
        "\n",
        "9. **Review Annotations**:\n",
        "   - Ensure that your annotations are accurate and consistent. Misannotated or inconsistent labels can significantly affect model performance.\n",
        "\n",
        "10. **Experimentation**:\n",
        "    - Run multiple experiments with different combinations of the above techniques. Use systematic experimentation (such as grid search or random search) to find the optimal settings.\n",
        "\n",
        "By applying these strategies, you should be able to improve the metrics of your object detection model on Roboflow.\n",
        "\n",
        "Here are some of the specific metrics you should focus on improving:\n",
        "- **mAP (mean Average Precision)**: Aim to increase this metric as it represents the overall precision and recall of your model.\n",
        "- **Precision**: Work on reducing the number of false positives.\n",
        "- **Recall**: Ensure that the model detects as many relevant objects as possible, reducing false negatives.\n",
        "\n",
        "Here are brief explanations of each term:\n",
        "\n",
        "1. **mAP (mean Average Precision)**:\n",
        "   - **Description**: It is a metric used to evaluate object detection models. It is calculated by averaging the precision of each class at different [Intersection over Union (IoU)](https://wiki.cloudfactory.com/docs/mp-wiki/metrics/iou-intersection-over-union) thresholds.\n",
        "   - **More information**: [Wikipedia - Mean Average Precision](https://en.wikipedia.org/wiki/Mean_average_precision)\n",
        "\n",
        "2. **Precision**:\n",
        "   - **Description**: It is the ratio of true positives to the total predicted positives (true positives + false positives). It indicates how precise the model is in identifying relevant items.\n",
        "   - **More information**: [Wikipedia - Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall#Precision)\n",
        "\n",
        "3. **Recall**:\n",
        "   - **Description**: It is the ratio of true positives to the total actual positives (true positives + false negatives). It indicates how well the model can identify all relevant items.\n",
        "   - **More information**: [Wikipedia - Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall#Recall)\n",
        "\n",
        "These metrics are essential in evaluating machine learning models, especially in tasks such as classification and object detection.\n",
        "\n",
        "Remember to monitor the training and validation metrics closely to ensure that the changes you make are leading to actual improvements.\n",
        "\n",
        "\n",
        ">**NOTE** To be evaluated, you only need to submit the final image of the training metric (like the one shown) from the notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}