{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanZapa7a/Medical-Image-Processing/blob/main/NB4-2%20Getting%20Started%20with%20Roboflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03T45nGa2flV"
      },
      "source": [
        "# [Getting Started with Roboflow](https://blog.roboflow.com/getting-started-with-roboflow/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W21hJ4Uxdi24"
      },
      "source": [
        "\n",
        "## 1. Introduction to [Roboflow](https://docs.roboflow.com/api-reference/introduction)\n",
        "\n",
        "**`Roboflow`** is a platform that simplifies the process of building machine learning models. It provides tools for data management, annotation, preprocessing, model augmentation and deployment. Roboflow is popular among developers, with over 100,000 developers having built with [Roboflow tools](https://github.com/roboflow). Despite its popularity, there are alternatives to Roboflow, such as [INTSIG](https://www.intsig.us/), [SuperAnnotate](https://www.superannotate.com/), [Google Cloud Vision API](https://cloud.google.com/vision?hl=es) and [Encord](https://encord.com/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bryb_neRdi25"
      },
      "source": [
        "\n",
        "### Limitations of the free version of Roboflow:\n",
        "\n",
        "The free version of Roboflow allows up to 3 users. Up to 10,000 source images can be managed. 3 training credits are provided. 1,000 inference credits are awarded per month. Projects, including datasets, are open source to contribute to the community.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCkC8P2ddi25"
      },
      "source": [
        "\n",
        "### Roboflow integration with Google Colab:\n",
        "\n",
        "Roboflow integrates well with Google Colab. In fact, Roboflow has produced dozens of workbooks showing how to train computer vision models in Google Colab. Roboflow maintains a repository called [Notebooks](https://github.com/roboflow/notebooks). These workbooks are step-by-step guides on how to train models and perform other computer vision tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePD9XEIRdQwX",
        "outputId": "45beccf3-cb8f-4842-b26f-a34b09075e76"
      },
      "source": [
        "```python\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ac2tLOMdi27"
      },
      "source": [
        "\n",
        "Your private api key is in Settings > Roboflow API in Private API key. But first, you need obtain a roboflow account"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bMj9y3sAmKY",
        "outputId": "23e59230-7364-4dc8-b217-dd982a193d3a"
      },
      "source": [
        "``` python\n",
        "# Step 1: Install Roboflow CLI\n",
        "%pip install --upgrade pip -q\n",
        "%pip install roboflow -q\n",
        "\n",
        "# Step 2: Import the necessary libraries\n",
        "import os\n",
        "import roboflow\n",
        "\n",
        "# Step 3: Log in to Roboflow with your private API KEY\n",
        "rf = roboflow.Roboflow(api_key=\"yourapikey\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1S1ydKEInCg"
      },
      "source": [
        "## 2. Creating a RoboFlow Account\n",
        "\n",
        "To get started, [create a free Roboflow account](https://app.roboflow.com/?ref=blog.roboflow.com). For example, my account is associated to GitHub. `In order to explain the process I am going to create a new account`.\n",
        "\n",
        "After reviewing and accepting the terms of service, you will be asked to choose between one of two plans: the Public Plan and the Starter Plan. `Select public plan and name your workspace. \"i.e: PIM\". Push` `Create Workspace`\n",
        "\n",
        "![image.png](https://blog.roboflow.com/content/images/size/w1000/2024/02/Screenshot-2024-02-12-at-09.31.24.png)\n",
        "\n",
        "---\n",
        "**Push `Create Workspace`**\n",
        "\n",
        "---\n",
        "\n",
        "Then, `you will be asked to invite collaborators to your workspace`. These collaborators can help you annotate images or manage the vision projects in your workspace. Once you have invited people to your workspace (if you want to), you will be able to create a project. You can **press `Continue without adding others`** if you don't want invite to anyone.\n",
        "\n",
        "---\n",
        "**Press `Continue without adding others`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7Z0aWMX86-N"
      },
      "source": [
        "\n",
        "## 3. Create your project\n",
        "\n",
        "![image.png](https://blog.roboflow.com/content/images/size/w1000/2024/02/Screenshot-2024-02-12-at-10.02.25.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0SoY3l3di28"
      },
      "source": [
        "\n",
        "For this example, we will be using a `dataset of cells` to train a model that can `identify cells for counting`. This model could be used for medical analysis in a health facility. With that said, you can use any images you want to train a model.\n",
        "\n",
        "`Leave the project type as the default \"Object Detection\" option` since our model will be identifying specific objects and we want to know their location within the image.\n",
        "\n",
        "- `Project Name`: (i.e Count-cells)\n",
        "- `Annotattion Group`: (i.e. cells)\n",
        "\n",
        "Next, **Click `Create Public Project.`**\n",
        "\n",
        "---\n",
        "**Click `Create Public Project.`**.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this walkthrough, weâ€™ll use a Roboflow provided sample cell dataset (Count-cells by Harito `cells-upja`). You can obtain other [cells datasets](https://universe.roboflow.com/search?q=object%20detection%20cells).\n",
        "\n",
        "`Exactly our dataset is in this direction (please press the next link)` [Count-cells](https://universe.roboflow.com/harito/cells-rez5s).\n",
        "\n"
      ],
      "metadata": {
        "id": "cJuZD72tUOrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Press this link [Count-cells](https://universe.roboflow.com/harito/cells-rez5s)**.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "3S2N-BsrUikX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmjM97gadi29"
      },
      "source": [
        "Next, we must `click on the left in ` `Dataset` `and ` `Download Dataset` in order to download the dataset in zip format.\n",
        "\n",
        "---\n",
        " **Press `Dataset` `and ` `Download Dataset`**.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  - You can select : `download zip to computer` or `show dowload code` to be used in a notebook.\n",
        "  - This time, `we will download the zip file using COCO JSON format`.\n",
        "\n",
        "Therefore, `Check Download zip to computer and then press Continue` .\n",
        "\n",
        "---\n",
        "**Check `Download zip to computer` and press `Continue`**\n",
        "\n",
        "---\n",
        "![imagen1](https://github.com/JuanZapa7a/covid-19/blob/master/2024-09-17_12-38.png?raw=1)\n",
        "\n",
        "Next, Roboflow shows us the possible models that we can use to train the dataset. Among them, we can highlight YOLOv8, YOLOv5, and YOLOv7 and many more, which we will study further during the course.\n",
        "\n",
        "![imagen2](https://github.com/JuanZapa7a/covid-19/blob/master/2024-09-17_12-45.png?raw=1)\n",
        "\n",
        "---\n",
        "**Press `Done`**\n",
        "\n",
        "---\n",
        "\n",
        "Once you have downloaded the dataset, unzip the file. `Click and drag the extracted folders and files from Cells.v1i.coco folder from your local machine onto the highlighted upload area`. This dataset is structured in the COCO JSON format, [one of 40+ computer vision formats Roboflow supports](https://roboflow.com/formats?ref=blog.roboflow.com).\n",
        "\n",
        "---\n",
        "**Extract the file `Cells.v1i.coco.zip` in a local folder and `drop the folder` onto the highlighted upload area**\n",
        "\n",
        "---\n",
        "![imagen3](https://github.com/JuanZapa7a/covid-19/blob/master/2024-09-17_12-50.png?raw=1)\n",
        "\n",
        "\n",
        ">### **COCO JSON Format**\n",
        ">The `COCO JSON format` is a file format used to store annotations for datasets in computer vision tasks, particularly object detection, instance segmentation, and related tasks. `COCO (Common Objects in Context)` is a widely used standard in the computer vision community and provides a `structured framework for organizing and labeling image data`.\n",
        ">\n",
        ">The COCO JSON file consists of several main components:\n",
        ">\n",
        ">1. **`Info`**: General information about the dataset, such as the year, version, description, and contributor.\n",
        "    ```json\n",
        "    {\n",
        "      \"year\": 2024,\n",
        "      \"version\": \"1.0\",\n",
        "      \"description\": \"Example Dataset\",\n",
        "      \"contributor\": \"Example\",\n",
        "      \"date_created\": \"2024-07-06\"\n",
        "    }\n",
        "    ```\n",
        ">\n",
        ">2. **`Licenses`**: Information about the licenses of the images contained in the dataset.\n",
        "    ```json\n",
        "    [\n",
        "      {\n",
        "        \"id\": 1,\n",
        "        \"name\": \"Example License\",\n",
        "        \"url\": \"http://example.com/license\"\n",
        "      }\n",
        "    ]\n",
        "    ```\n",
        ">\n",
        ">3. **`Images`**: Information about each image in the dataset, including the image ID, file name, height, and width.\n",
        "    ```json\n",
        "    [\n",
        "      {\n",
        "        \"id\": 1,\n",
        "        \"width\": 640,\n",
        "        \"height\": 480,\n",
        "        \"file_name\": \"image1.jpg\",\n",
        "        \"license\": 1,\n",
        "        \"date_captured\": \"2024-07-06\"\n",
        "      }\n",
        "    ]\n",
        "    ```\n",
        ">\n",
        ">4. **`Annotations`**: Annotations associated with the images, including information about object categories, object locations (bounding boxes), and segmentation masks.\n",
        "    ```json\n",
        "    [\n",
        "      {\n",
        "        \"id\": 1,\n",
        "        \"image_id\": 1,\n",
        "        \"category_id\": 1,\n",
        "        \"segmentation\": [[100.0, 100.0, 150.0, 100.0, 150.0, 150.0, 100.0, 150.0]],\n",
        "        \"area\": 2500.0,\n",
        "        \"bbox\": [100.0, 100.0, 50.0, 50.0],\n",
        "        \"iscrowd\": 0\n",
        "      }\n",
        "    ]\n",
        "    ```\n",
        ">\n",
        ">5. **`Categories`**: Information about the different object categories present in the dataset.\n",
        "    ```json\n",
        "    [\n",
        "      {\n",
        "        \"id\": 1,\n",
        "        \"name\": \"person\",\n",
        "        \"supercategory\": \"human\"\n",
        "      }\n",
        "    ]\n",
        "    ```\n",
        ">\n",
        ">These components are structured in a JSON file that can be processed by various libraries and tools for computer vision tasks. This format facilitates interoperability and the use of datasets in various projects and experiments.\n",
        "\n",
        "Once you drop the cell-dataset folder into Roboflow, the images and annotations are processed for you to see them overlayed.\n",
        "\n",
        "![image2](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_11-19.png?raw=1)\n",
        "\n",
        "`If any of your annotations have errors, Roboflow alerts you`. For example, if some of the annotations improperly extended beyond the frame of an image, Roboflow intelligently crops the edge of the annotation to line up with the edge of the image and drops erroneous annotations that lie fully outside the image frame.\n",
        "\n",
        "**At this point, `our images have not yet been uploaded to Roboflow`**. We can verify that all the images are, indeed, the ones we want to include in our dataset and that our annotations are being parsed properly.`Any image can be deleted upon mousing over it and selecting the red trash icon`.\n",
        "\n",
        "**Note that one of our images is marked as `\"Not Annotated\"`** on the dashboard. We'll annotate this image in the next section.\n",
        "\n",
        "Everything now looks good. Click **`â€œSave and Continueâ€`** in the upper right-hand corner to upload your data.\n",
        "\n",
        "---\n",
        "**Click `Save and Continue`**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjcsy4ub86-O"
      },
      "source": [
        "\n",
        "## 4. Spliting our Dataset: Train, Test and Valid Sets\n",
        "**You will be asked to choose a dataset split**. This refers to how images will be split between three sets: `Train, Test, and Valid`.\n",
        "\n",
        "1. Your train set contains the images that will be used to train your model.\n",
        "2. Your valid set will be used during training to validate performance of your model.\n",
        "3. Your test set contains images you can use to manually test the performance of your model. Learn more about [image dataset splits](https://blog.roboflow.com/train-test-split/) and why to use them.\n",
        "\n",
        "You can set your own custom splits with Roboflow or, if one is available, use an existing split in a dataset. Our dataset has already been split with Roboflow, so we can choose the \"Use existing values\" option when asked how to split our images and clik `\"Continue\"`:\n",
        "\n",
        "![image3](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_11-41.png?raw=1)\n",
        "\n",
        "You can [upload videos](https://blog.roboflow.com/youtube-video-computer-vision/) as well as images. We already have enough images for our project, but we'll talk through this process in case you want to add video data to your projects in the future.\n",
        "\n",
        "To upload a video, go to the Upload tab in the Roboflow sidebar and drag in a video. You can also paste in the URL of a YouTube video you want to upload.\n",
        "\n",
        "![image4](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_11-47.png?raw=1)\n",
        "\n",
        "When you upload a video, you will be asked how many images should be captured per second. If you choose \"1 frame / second\", an image will be taken every second from the video and saved to Roboflow.\n",
        "\n",
        "![image5](https://blog.roboflow.com/content/images/size/w1000/2023/03/Screenshot-2023-03-20-at-11.53.53.png)\n",
        "\n",
        "When you have selected an option, click `\"Choose Frame Rate\"`. This will begin the process of collecting images from the video."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Push `Choose Frame Rate`**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "IPPlP7loS0IQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEEJ2GZ486-O"
      },
      "source": [
        "\n",
        "## 5. Annotate Images\n",
        "\n",
        "One of the images in the sample dataset is not yet annotated. `You will use `[`Roboflow Annotate`](https://roboflow.com/annotate?ref=blog.roboflow.com)` to `[`add a box (or boxes) around the unlabeled cells`](https://youtu.be/O-ZPxTpb2Yg?t=220&ref=blog.roboflow.com)` in the image`.\n",
        "\n",
        "`Annotations are the answer key from which your model learns`. The more annotated images we add, the more information our model has to learn what each class is (`in our case, more images will help our model identify what is a cell`).\n",
        "\n",
        "![image6](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_11-55.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxKvlpEhdi2-"
      },
      "source": [
        "\n",
        "---\n",
        "**Push in `Annotate Images ->`**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz0shqgsdi2-"
      },
      "source": [
        "\n",
        "1. With Roboflow [Label Assist](https://blog.roboflow.com/announcing-label-assist/) `\"Auto Label\"`, you can use previous versions of your model to annotate future versions. Label Assist uses another model to draw annotations on images for you, which means you can spend less time annotating and get a model ready for production faster than ever. You can use publicly available models hosted on [Roboflow Universe, our dataset community, for label assist](https://blog.roboflow.com/launch-universe-model-checkpoint/), too.\n",
        "2. Roboflow Labeling is not free. It is a paid service that offers professional annotation by human labelers for your datasets. Access to Roboflow Labeling requires purchasing a Starter Plan. Bounding Box annotations start at $0.04$ and Polygon annotations start at $0.08$.\n",
        "3. Manual Labeling. This is the normal first use when you have a dataset without annotations. In first place, you manual annotate some images and you train a model which is used to labelled the rest of images with \"Auto Label\". Click `\"Start Manual Labeling\"`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g9QLkbXdi2-"
      },
      "source": [
        "\n",
        "![image6](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-01.png?raw=1)\n",
        "\n",
        "\n",
        "You can **`start a Auto Label`**, **`Start Roboflow labeling`** or **`Start Manual Labeling`**\n",
        "\n",
        "---\n",
        "**Push in `Start Manual labeling`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vHyZ2iZdi2-"
      },
      "source": [
        "\n",
        "\n",
        "Next, you can assign this task to a teammate with `Invite Teammate` or `assign to myself`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl6GNne-di2-"
      },
      "source": [
        "\n",
        "![image6b](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-10_10-39.png?raw=1)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**Click `Assign to Myself`**\n",
        "\n",
        "---\n",
        "\n",
        "Now you can see that there is annotation work to be done and the labeler is yourself.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFruR4Ssdi2-"
      },
      "source": [
        "![image6c](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-10_10-46.png?raw=1)\n",
        "\n",
        "---\n",
        "**Click on `Start Annotating`**\n",
        "\n",
        "---\n",
        "\n",
        "Use your cursor to drag a box around the area on the chess board you want to annotate. A box will appear in which you can enter the label to add. In the example below, we will add boxes around cells, and assign the corresponding class: `\"Cells-upja\"`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTxZlgI9di2-"
      },
      "source": [
        "\n",
        "![image7](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-15.png?raw=1)\n",
        "\n",
        "You can also label datasets with polygons, which are shapes with multiple points drawn around an object. Using [polygons to label for object detection](https://blog.roboflow.com/polygon-vs-bounding-box-computer-vision-annotation/) may result in a small boost in model performance.\n",
        "\n",
        "Polygons are essential for `instance segmentation` projects where you want to identify the exact location, to the pixel, of an object in an image. Roboflow offers a few tools to help with labeling with polygons. You can manually label polygons using the [Polygon annotation tool](https://blog.roboflow.com/polygon-annotation-labeling/) or you can use [Smart Polygon](https://blog.roboflow.com/automated-polygon-labeling-computer-vision/) to label objects with one click.\n",
        "\n",
        "To enable Smart Polygon, click the cursor with sparkles icon in the right sidebar, above the magic wand icon. A window will pop up that asks what version of Smart Polygon you want to enable.\n",
        "\n",
        "---\n",
        "**Click the `cursor with sparkles`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opwUY8Z9di2_"
      },
      "source": [
        "\n",
        "\n",
        "![image9](https://blog.roboflow.com/content/images/2024/02/Screenshot-2024-02-12-at-10.18.39.png)\n",
        "\n",
        "---\n",
        "**Click `Enhanced`**\n",
        "\n",
        "---\n",
        "\n",
        "When Smart Polygon has loaded, you can point and click anywhere on an image to create a label. When you hover over an object, a red mask will appear that lets you see what region of the object Smart Polygon will label if you click.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SuK2Yo5di2_"
      },
      "source": [
        "\n",
        "\n",
        "![image8](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-27.png?raw=1)\n",
        "\n",
        "\n",
        "We can move the polygone and clear it.\n",
        "\n",
        "---\n",
        "\n",
        "**Click `<--`**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulVLIzzkdi2_"
      },
      "source": [
        "\n",
        "\n",
        "### Annotation Comments and History\n",
        "\n",
        "Need help from a team member on an annotation? Want to leave yourself a note for later on a particular image? We have you covered. `Click the speech bubble icon on the sidebar of the annotation tool. Then, click the place on the image you want to leave a comment.`\n",
        "\n",
        "If you have multiple people working with you on a project, you can tag them by using the @ sign, followed by their name. They will get a notification that you have commented and requested their assistance.\n",
        "\n",
        "We can see the history of our annotated image in the sidebar:\n",
        "\n",
        "To view a project at a previous point in the history, hover over the state in history that you want to preview.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrbmW64f86-O"
      },
      "source": [
        "\n",
        "## 6. Add Images to Dataset\n",
        "Once you have annotated your image, you need to add it into your dataset for use in training a model.  `Click \"Annotate\"` in the sidebar. Then, `click on the card in the \"Annotating\" section` that shows there is one annotated image for review.\n",
        "\n",
        "![image9](https://github.com/JuanZapa7a/covid-19/blob/master/2024-09-17_17-26.png?raw=1)\n",
        "\n",
        "---\n",
        "**Click `Annotate` and Click `Annotating`**\n",
        "\n",
        "---\n",
        "\n",
        "Next, click `Add Images to Dataset` to add your image to the dataset and then click `add images` to confirm:\n",
        "\n",
        "![image9](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-33.png?raw=1)\n",
        "\n",
        "![image10](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-34.png?raw=1)\n",
        "\n",
        "You can search the images in your dataset by clicking \"Dataset\" in the sidebar. The search bar runs a [semantic search on your dataset](https://blog.roboflow.com/dataset-search/) to find images related to your query. For example, if we had images with blood, leucocytes, cells, and blastocytes, we could search through them with ease.\n",
        "\n",
        "\n",
        "---\n",
        "**Click `Add Images` to Dataset**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6yvetFQ86-O"
      },
      "source": [
        "\n",
        "## 7. Preprocessing and Augmentations\n",
        "After you're done annotating and have added your annotated image to your dataset, continue to [generate a new version of your dataset](https://youtu.be/O-ZPxTpb2Yg?t=287&ref=blog.roboflow.com). This creates a point-in-time snapshot of your images processed in a particular way (think of it a bit like version control for data).\n",
        "\n",
        "\n",
        "\n",
        "![imag11](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_13-09.png?raw=1)\n",
        "\n",
        "\n",
        "click in `Create new Version`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqoOQTF5di2_"
      },
      "source": [
        "\n",
        "![imag12](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_13-13.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOlHVnC9di2_"
      },
      "source": [
        "\n",
        "From here, we can apply any [preprocessing](https://docs.roboflow.com/image-transformations/image-preprocessing?ref=blog.roboflow.com) and [augmentation](https://docs.roboflow.com/image-transformations/image-augmentation?ref=blog.roboflow.com) steps that we want to our images. Roboflow seamlessly makes sure all of your annotations correctly bound each of your labeled objects -- even if you resize, rotate, or crop.\n",
        "\n",
        "> By default, Roboflow opts you into two preprocessing steps: auto-orient and resize. Auto-orient assures your images are stored on disk the same way your applications open them for you. Resize creates a consistent size for your images, in this case smaller, to expedite training.\n",
        "\n",
        "You can also choose to augment your images which generates multiple variations of each source image to help your model generalize better.\n",
        "\n",
        "Roboflow supports auto-orient corrections, resizing, grayscaling, contrast adjustments, random flips, random 90-degree rotations, random 0 to N-degree rotations, random brightness modifications, Gaussian blurring, random shearing, random cropping, random noise, and much more. To better understand these options, refer to our [documentation](https://docs.roboflow.com/?ref=blog.roboflow.com).\n",
        "\n",
        "> We recommend starting with one or two augmentations that may work with a dataset, and adding more further down the line if necessary. Adding more augmentations does not necessarily boost the performance of your model.\n",
        "\n",
        "Roboflow recommend applying no augmentations on your first model training job. This is so that you can understand how your model performs without augmentations. If your model performs poorly without augmentations, it is likely you need to revisit your dataset to ask questions like: Are all my images labeled? Are my images consistently labeled? Do my images contain a balance of the classes I want to identify?\n",
        "\n",
        "With that said, we have done some experimentation so you can achieve the best performance without tinkering with augmentation for this cell dataset.\n",
        "\n",
        "For this project, we are going to apply two augmentations: Flip and Rotate.\n",
        "\n",
        "We recommend these augmentations for our cell dataset since cells can appear at any angle and we want to identify a cell no matter how it is positioned.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rq4aM2vdi3A"
      },
      "source": [
        "\n",
        "\n",
        "![imag13](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-11_09-53.png?raw=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THVG5Tmadi3A"
      },
      "source": [
        "\n",
        "With that said, these augmentations may not work for your data. If you are identifying an object that will only appear at one orientation (such as might be the case on cells micrographs), a flip augmentation will not help as much as others.\n",
        "\n",
        "To learn more about applying augmentations, refer to our [image augmentation and preprocessing guide](https://blog.roboflow.com/why-preprocess-augment/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uurg_7wgdi3A"
      },
      "source": [
        "\n",
        "To generate your dataset, click the `Create` button at the bottom of the page.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psdeIddNdi3A"
      },
      "source": [
        "\n",
        "It will take a few moments for your dataset to be ready. Then, you can use it to start training a model.\n",
        "\n",
        "\n",
        "![imag13](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-11_09-55.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9oum2Yd86-P"
      },
      "source": [
        "\n",
        "## 8. Prepare Data for Training\n",
        "\n",
        "Once you have generated your dataset, you can use it to train a model on the Roboflow platform.\n",
        "\n",
        "![imag13](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_09-38.png?raw=1)\n",
        "\n",
        "[Roboflow Train](https://blog.roboflow.com/new-and-improved-roboflow-train/) offers model types that you can train and host using Roboflow. We handle the GPU costs and also give you access to out-of-the-box optimized [deployment](https://docs.roboflow.com/inference?ref=blog.roboflow.com) options which we will cover later in this notebook.\n",
        "\n",
        "Your trained model can now be used in a few powerful ways:\n",
        "\n",
        "- [Model-assisted labeling](https://blog.roboflow.com/announcing-label-assist/) speeds up labeling and annotation for adding more data into your dataset\n",
        "- Rapid prototyping or testing your model on real-world data to test model performance (explained in the next section)\n",
        "- Deploying to production with out-of-the-box options that are optimized for your model to run on multiple different devices (explained in the next section)\n",
        "\n",
        "You can also export your dataset for use in training a model on your own hardware. To export your data, click \"Export Dataset\" and select your desired export format.\n",
        "\n",
        "![imag14](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_09-44.png?raw=1)\n",
        "\n",
        "> If you train a model model on your own hardware, you may be able to upload it to Roboflow for deployment. Read our Upload Model Weights guide for more information.\n",
        "\n",
        "For this guide, let's train a model on the Roboflow platform. To get started, click the \"Train with Roboflow\" button. A window will appear where you can configure your model training job.\n",
        "\n",
        "![imag15](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_09-47.png?raw=1)\n",
        "\n",
        "First, you will be asked to choose which model to train. Each model has performance tradeoffs that you'll want to test for your unique use case.\n",
        "\n",
        "For this guide, choose \"Roboflow 3.0\".\n",
        "\n",
        "\n",
        "Then, you will then be asked to choose the model size. Choose \"fast\".\n",
        "\n",
        "![imag16](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_09-53.png?raw=1)\n",
        "\n",
        "\n",
        "\n",
        "Next, You will then be asked to choose from what checkpoint you want to train.\n",
        "\n",
        "![imag17](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_09-56.png?raw=1)\n",
        "\n",
        "For the first version of a new model, we recommend training from the MS COCO checkpoint. This uses a model trained on the Microsoft COCO dataset as a \"checkpoint\" from which your model will start training. This should lead to the best performance you can achieve in your first model training job.\n",
        "\n",
        "When you have trained a version of a model, you can train using your last model as a checkpoint. This is ideal if you have trained a model that performs well that you are looking to improve. You can also use [models you have starred from Universe](https://blog.roboflow.com/launch-universe-model-checkpoint/) as a checkpoint.\n",
        "\n",
        "Click \"Start Training\" to start training your model.\n",
        "\n",
        "This will take between a few minutes and a day depending on how many images are in your dataset. Because our cell dataset contains less than four dozens images, we can expect the training process will not take too long.\n",
        "\n",
        "When you start training your model, an estimate will appear that shows roughly how long we think it will take for your model to train. You will see the message \"Training machine starting...\" while your model training job is allocated to a server. This may take a few moments.\n",
        "\n",
        "\n",
        "![imag18](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_10-00.png?raw=1)\n",
        "\n",
        "\n",
        "When a machine has been assigned your dataset from which to train a model, a graph will appear on the page. This graph shows how your model is learning in real-time. As your model trains, the numbers may jump up and down. Over the long term, the lines should reach higher points on the chart.\n",
        "\n",
        "![imag19](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_10-08.png?raw=1)\n",
        "\n",
        "\n",
        "The higher the mean average precision (mAP) is, the better.\n",
        "\n",
        "ðŸ’¡\n",
        "> Precision is a measure of, \"when your model guesses how often does it guess correctly?\" Recall is a measure of \"has your model guessed every time that it should have guessed?\" Consider an image that has 10 red blood cells. A model that finds only one of these ten but correctly labels is as \"RBC\" has perfect precision (as every guess it makes â€“ one â€“ is correct) but imperfect recall (only one of ten RBC cells has been found).\n",
        "\n",
        "The mAP, precision, and recall statistics tell us about the performance of our model. You can learn more about what these statistics tell you in our guide to [mAP, precision, and recall](https://blog.roboflow.com/mean-average-precision/).\n",
        "\n",
        "You'll receive an email once your model has finished training. The email contains the training results for you to see how the model performed. If you need to improve performance, [we have recommendations](https://blog.roboflow.com/improve-computer-vision-model/) on how to do that.\n",
        "\n",
        "\n",
        "![image20](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_10-56.png?raw=1)\n",
        "\n",
        "\n",
        "[View your training graphs](https://youtu.be/O-ZPxTpb2Yg?t=810&ref=blog.roboflow.com) for a more detailed view of model performance.\n",
        "\n",
        "![image21](https://github.com/JuanZapa7a/covid-19/blob/master/2024-07-15_11-00.png?raw=1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvSzl9Ozc0Ua"
      },
      "source": [
        "## `NoteBook Practice 2`\n",
        "\n",
        "---\n",
        "Use this guide to create an account on Roboflow and follow the steps in the guide until you train a model on this database or a similar one (preferably). To obtain better metrics than those obtained in this guide will be valued.\n",
        "\n",
        "---\n",
        "\n",
        "### Instructions to improve the NoteBook (study and work about it by yourself):\n",
        "\n",
        "ChatGPT can be your great allied. Use it for your convenence.\n",
        "\n",
        "1. **Data Augmentation**:\n",
        "   - Increase the variability in your dataset by applying various data augmentation techniques such as rotation, flipping, scaling, cropping, and color adjustments.\n",
        "   - Ensure the augmented images still represent the original class accurately.\n",
        "\n",
        "2. **Increase Dataset Size**:\n",
        "   - If possible, add more annotated images to your dataset. A larger dataset can help the model generalize better.\n",
        "\n",
        "3. **Adjust Hyperparameters**:\n",
        "   - Experiment with different learning rates. A too high learning rate might cause the model to converge too quickly to a suboptimal solution, while a too low learning rate might make the training process very slow.\n",
        "   - Adjust batch size. Sometimes, a larger batch size can help stabilize the training process.\n",
        "\n",
        "4. **Model Architecture**:\n",
        "   - Try using a different model architecture or a more complex one if you have sufficient computational resources. For example, consider using YOLOv5, EfficientDet, or other state-of-the-art object detection models.\n",
        "   - If using a pre-trained model, ensure that the model is fine-tuned properly for your specific dataset.\n",
        "\n",
        "5. **Training Time**:\n",
        "   - Train the model for more epochs but keep an eye on the validation loss to avoid overfitting. Early stopping can be a useful technique to halt training when the validation loss stops improving.\n",
        "\n",
        "6. **Cross-Validation**:\n",
        "   - Implement cross-validation to ensure that your model performs well across different subsets of your data. This helps in verifying that the model generalizes well.\n",
        "\n",
        "7. **Optimize Anchors**:\n",
        "   - Optimize anchor boxes based on your dataset. Properly sized anchor boxes can improve the model's ability to detect objects more accurately.\n",
        "\n",
        "8. **Post-Processing**:\n",
        "   - Fine-tune the Non-Maximum Suppression (NMS) parameters to reduce false positives and improve the precision of the model.\n",
        "\n",
        "9. **Review Annotations**:\n",
        "   - Ensure that your annotations are accurate and consistent. Misannotated or inconsistent labels can significantly affect model performance.\n",
        "\n",
        "10. **Experimentation**:\n",
        "    - Run multiple experiments with different combinations of the above techniques. Use systematic experimentation (such as grid search or random search) to find the optimal settings.\n",
        "\n",
        "By applying these strategies, you should be able to improve the metrics of your object detection model on Roboflow.\n",
        "\n",
        "Here are some of the specific metrics you should focus on improving:\n",
        "- **mAP (mean Average Precision)**: Aim to increase this metric as it represents the overall precision and recall of your model.\n",
        "- **Precision**: Work on reducing the number of false positives.\n",
        "- **Recall**: Ensure that the model detects as many relevant objects as possible, reducing false negatives.\n",
        "\n",
        "Here are brief explanations of each term:\n",
        "\n",
        "1. **mAP (mean Average Precision)**:\n",
        "   - **Description**: It is a metric used to evaluate object detection models. It is calculated by averaging the precision of each class at different [Intersection over Union (IoU)](https://wiki.cloudfactory.com/docs/mp-wiki/metrics/iou-intersection-over-union) thresholds.\n",
        "   - **More information**: [Wikipedia - Mean Average Precision](https://en.wikipedia.org/wiki/Mean_average_precision)\n",
        "\n",
        "2. **Precision**:\n",
        "   - **Description**: It is the ratio of true positives to the total predicted positives (true positives + false positives). It indicates how precise the model is in identifying relevant items.\n",
        "   - **More information**: [Wikipedia - Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall#Precision)\n",
        "\n",
        "3. **Recall**:\n",
        "   - **Description**: It is the ratio of true positives to the total actual positives (true positives + false negatives). It indicates how well the model can identify all relevant items.\n",
        "   - **More information**: [Wikipedia - Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall#Recall)\n",
        "\n",
        "These metrics are essential in evaluating machine learning models, especially in tasks such as classification and object detection.\n",
        "\n",
        "Remember to monitor the training and validation metrics closely to ensure that the changes you make are leading to actual improvements.\n",
        "\n",
        "\n",
        ">**NOTE** To be evaluated, you only need to submit the final image of the training metric (like the one shown) from the notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}