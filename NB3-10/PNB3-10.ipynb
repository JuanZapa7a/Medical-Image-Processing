{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMdFPzxt8kiUwFzwDlaaCxi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Lecture 3-10: Image Measurement and Feature Extraction"],"metadata":{"id":"G454633Pas-U"}},{"cell_type":"markdown","source":["## 0.- Initialize filesystem and libraries"],"metadata":{"id":"n1--HW_rHVyL"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"iTPSk68thB8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cbns7YEfg5bl"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2"]},{"cell_type":"code","source":["!pip install pydicom\n","import pydicom"],"metadata":{"id":"nbngKntDbgN8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.- Geometric measurements"],"metadata":{"id":"qHC0_ibl14Qv"}},{"cell_type":"code","source":["# Load the grayscale image\n","image_path = '/content/drive/MyDrive/PIM/Images/X-ray_4.png'\n","image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","\n","plt.figure(figsize=(5, 5))\n","plt.imshow(image, cmap='gray')\n","plt.title('Original image')\n","plt.show()"],"metadata":{"id":"tn0RWYHB4Byh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply Otsu's thresholding\n","otsu_threshold, otsu_threshold_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","print(f\"Optimal threshold (Otsu's method): {otsu_threshold}\")\n","\n","plt.figure(figsize=(10, 4))\n","\n","plt.subplot(1, 3, 1)\n","plt.hist(image.flatten(), bins=256, range=[0, 256])\n","plt.title(\"Histogram of the original image\\n (Otsu's threshold is marked with the red line)\")\n","plt.xlabel('Pixel intensity')\n","plt.ylabel('Frequency')\n","plt.axvline(otsu_threshold, color='r')  # Otsu's threshold\n","\n","plt.subplot(1, 3, 2)\n","plt.imshow(otsu_threshold_image, cmap='gray')\n","plt.title(\"Otsu's threshold\")\n","\n","plt.subplot(1, 3, 3)\n","plt.imshow(otsu_threshold_image[70:170, 80:180], cmap='gray')\n","plt.title(\"Otsu's threshold (cropped)\")\n","plt.axis('off')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Label connected components\n","num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(otsu_threshold_image, connectivity=8)\n","print(f\"Number of labels (including background): {num_labels}\")"],"metadata":{"id":"CPKxu71u-3hI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Perform opening and closing\n","structuring_element = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n","opened_image = cv2.morphologyEx(otsu_threshold_image, cv2.MORPH_OPEN, structuring_element)\n","closed_image = cv2.morphologyEx(opened_image, cv2.MORPH_CLOSE, structuring_element)\n","\n","# Label connected components\n","num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closed_image, connectivity=8)\n","print(f\"Number of labels (including background): {num_labels}\")\n","\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 2, 1)\n","plt.imshow(opened_image, cmap='gray')\n","plt.title(\"Opened image\")\n","plt.axis('off')\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(closed_image, cmap='gray')\n","plt.title(\"Closed image\")\n","plt.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"ZpGxK2A5_ytR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Label connected components\n","num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closed_image, connectivity=8)\n","\n","# Print the number of labels in the image\n","print(f\"Number of labels (including background): {num_labels}\")\n","\n","# Print unique labels\n","unique_labels = np.unique(labels) # returns the sorted unique elements from the input array\n","print(\"Unique labels in the image:\", unique_labels)\n","\n","# Plot each labeled object separately\n","plt.figure(figsize=(10, 10))\n","for label in range(1, num_labels):  # starts from 1 to skip the background\n","    # Create a binary mask for the current label\n","    mask = np.where(labels == label, 255, 0).astype(np.uint8)\n","    # for each element in the array 'labels', if the condition (labels == label)\n","    # is True, it replaces it with 255 (white), and if False, it replaces it\n","    # with 0 (black) in an image). Then, it converts the resulting array to uint8 format\n","\n","    # Plot each object in a separate subplot\n","    plt.subplot(1, num_labels-1, label)\n","    plt.imshow(mask, cmap='gray')\n","    plt.title(f'Object {label}')\n","    plt.axis('off')\n","\n","    # Print statistics for each object:\n","    print(f'Object: {label}')\n","    print(f'  Bounding Box: x={stats[label, 0]}, y={stats[label, 1]}, width={stats[label, 2]}, height={stats[label, 3]}')\n","    print(f'  Area: {stats[label, 4]} pixels')\n","    print(f'  Centroid: (x={centroids[label, 0]:.2f}, y={centroids[label, 1]:.2f})')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"405Xs17Z4-YN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert the original image to color image\n","contour_image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n","\n","# Convert the black & white image to color image\n","mask_image = cv2.cvtColor(closed_image, cv2.COLOR_GRAY2RGB)\n","\n","for label in range(1, num_labels):  # starts from 1 to skip the background\n","    # Extracts statistics for each label (x, y, width, height, area)\n","    x = stats[label, cv2.CC_STAT_LEFT]  # similar to stats[label, 0]\n","    y = stats[label, cv2.CC_STAT_TOP]  # similar to stats[label, 1]\n","    width = stats[label, cv2.CC_STAT_WIDTH]    # similar to stats[label, 2]\n","    height = stats[label, cv2.CC_STAT_HEIGHT]   # similar to stats[label, 3]\n","    area = stats[label, cv2.CC_STAT_AREA]    # similar to stats[label, 4]\n","    centroid = centroids[label]  # Centroid of each object\n","\n","    # Extract the contour for the labeled region\n","    mask = np.uint8(np.zeros_like(image)) # create an empty mask (black image with the same dimensions as the original image)\n","    mask[labels == label] = 255  # create a boolean mask (in white) for each object or label\n","    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # find the contours\n","    if contours: # if a contour was extracted, then draw it\n","        cv2.drawContours(contour_image, contours, -1, (0, 0, 255), 2)  # Draw contours in blue\n","\n","    # Extract the perimeter of the current contour\n","    perimeter = cv2.arcLength(contours[0], True)\n","\n","    # Draw the bounding box in green (0, 255, 0) with thickness of 2 pixels\n","    cv2.rectangle(mask_image, (x, y), (x + width, y + height), (0, 255, 0), 2)\n","    # Label the object\n","    cv2.putText(mask_image, f\"Object {label}\", (int(centroids[label][0]), int(centroids[label][1])),\n","                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2) # Red color, thickness = 2\n","\n","    # Calculate different shape descriptors\n","    compactness = (perimeter**2) / area if area != 0 else 0  # Compactness\n","    circularity = (4 * np.pi * area) / (perimeter**2) if perimeter != 0 else 0  # Circularity\n","    aspect_ratio = float(width) / height  # Aspect Ratio\n","    extent = float(area) / (width * height) # Extent\n","\n","    print(f'Label: {label}')\n","    print(f'  Bounding box: x={x}, y={y}, width={width}, height={height}')\n","    print(f'  Centroid: (x={centroid[0]:.2f}, y={centroid[1]:.2f})')\n","    print(f'  Area: {area} pixels')\n","    print(f'  Perimeter: {perimeter:.2f} pixels')\n","    print(f\"  Compactness: {compactness}\")\n","    print(f\"  Circularity: {circularity}\")\n","    print(f'  Aspect ratio: {aspect_ratio:.2f}')\n","    print(f'  Extent: {extent:.2f}')\n","\n","plt.figure(figsize=(10, 5))\n","\n","# Mask image (binarized)\n","plt.subplot(1, 2, 1)\n","plt.imshow(mask_image, cmap='gray')\n","plt.title('Mask image (binarized)\\n showing the bounding boxes')\n","plt.axis('off')\n","\n","plt.subplot(1,2,2)\n","plt.imshow(contour_image)\n","plt.title(\"Object contours\")\n","plt.axis('off')\n","\n","plt.show()"],"metadata":{"id":"EKXmm7TZ4JLi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Open the DICOM file\n","dicom_file = pydicom.dcmread('/content/drive/MyDrive/PIM/Images/IM000015.dcm')\n","image = dicom_file.pixel_array\n","\n","# Normalize the image to the uint8 range (0,255)\n","image_norm = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n","\n","# Binarize the image using a threshold\n","threshold = 20\n","_, binary_image = cv2.threshold(image_norm, threshold, 255, cv2.THRESH_BINARY)\n","\n","# Perform closing\n","structuring_element = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n","closed_image = np.uint8(cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, structuring_element))\n","\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 3, 1)\n","plt.imshow(image_norm, cmap='gray')\n","plt.title(\"DICOM image\")\n","plt.axis('off')\n","\n","plt.subplot(1, 3, 2)\n","plt.imshow(binary_image, cmap='gray')\n","plt.title(\"Binary image\")\n","plt.axis('off')\n","\n","plt.subplot(1, 3, 3)\n","plt.imshow(closed_image, cmap='gray')\n","plt.title(\"Closed image\")\n","plt.axis('off')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Label connected components\n","num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closed_image, connectivity=8)\n","\n","# Print the number of labels in the image\n","print(f\"Number of labels (including background): {num_labels}\")\n","\n","# Print unique labels\n","unique_labels = np.unique(labels) # returns the sorted unique elements from the input array\n","print(\"Unique labels in the image:\", unique_labels)\n","\n","# Convert the original image to color image\n","contour_image = cv2.cvtColor(image_norm, cv2.COLOR_GRAY2RGB)\n","\n","# Convert the black & white image to color image\n","mask_image = cv2.cvtColor(closed_image, cv2.COLOR_GRAY2RGB)\n","\n","for label in range(1, num_labels):  # starts from 1 to skip the background\n","    # Extracts statistics for each label (x, y, width, height, area)\n","    x = stats[label, cv2.CC_STAT_LEFT]  # similar to stats[label, 0]\n","    y = stats[label, cv2.CC_STAT_TOP]  # similar to stats[label, 1]\n","    width = stats[label, cv2.CC_STAT_WIDTH]    # similar to stats[label, 2]\n","    height = stats[label, cv2.CC_STAT_HEIGHT]   # similar to stats[label, 3]\n","    area = stats[label, cv2.CC_STAT_AREA]    # similar to stats[label, 4]\n","    centroid = centroids[label]  # Centroid of each object\n","\n","    # Extract the contour for the labeled region\n","    mask = np.uint8(np.zeros_like(image_norm)) # create an empty mask (black image with the same dimensions as the original image)\n","    mask[labels == label] = 255  # create a boolean mask (in white) for each object or label\n","    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # find the contours\n","    if contours: # if a contour was extracted, then draw it\n","        cv2.drawContours(contour_image, contours, -1, (0, 0, 255), 2)  # Draw contours in blue\n","\n","    # Extract the perimeter of the current contour\n","    perimeter = cv2.arcLength(contours[0], True)\n","\n","    # Draw the bounding box in green (0, 255, 0) with thickness of 2 pixels\n","    cv2.rectangle(mask_image, (x, y), (x + width, y + height), (0, 255, 0), 2)\n","    # Label the object\n","    cv2.putText(mask_image, f\"Object {label}\", (int(centroids[label][0]), int(centroids[label][1])),\n","                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2) # Red color, thickness = 2\n","\n","    # Calculate different shape descriptors\n","    compactness = (perimeter**2) / area if area != 0 else 0  # Compactness\n","    circularity = (4 * np.pi * area) / (perimeter**2) if perimeter != 0 else 0  # Circularity\n","    aspect_ratio = float(width) / height  # Aspect Ratio\n","    extent = float(area) / (width * height) # Extent\n","\n","    print(f'Label: {label}')\n","    print(f'  Bounding box: x={x}, y={y}, width={width}, height={height}')\n","    print(f'  Centroid: (x={centroid[0]:.2f}, y={centroid[1]:.2f})')\n","    print(f'  Area: {area} pixels')\n","    print(f'  Perimeter: {perimeter:.2f} pixels')\n","    print(f\"  Compactness: {compactness}\")\n","    print(f\"  Circularity: {circularity}\")\n","    print(f'  Aspect ratio: {aspect_ratio:.2f}')\n","    print(f'  Extent: {extent:.2f}')\n","\n","plt.figure(figsize=(10, 5))\n","\n","# Mask image (binarized)\n","plt.subplot(1, 2, 1)\n","plt.imshow(mask_image, cmap='gray')\n","plt.title('Mask image (binarized)\\n showing the bounding boxes')\n","plt.axis('off')\n","\n","plt.subplot(1,2,2)\n","plt.imshow(contour_image)\n","plt.title(\"Object contours\")\n","plt.axis('off')\n","\n","plt.show()\n","\n","\n","## Calculate real dimensions\n","\n","# Access the Pixel Spacing attribute\n","pixel_spacing = dicom_file.PixelSpacing\n","print(\"Pixel spacing: \", pixel_spacing)\n","\n","# Image dimensions in pixels\n","image_width_pixels = dicom_file.Columns\n","image_height_pixels = dicom_file.Rows\n","\n","print(\"Image width (pixels): \", image_width_pixels)\n","print(\"Image height (pixels): \", image_height_pixels)\n","\n","# Calculate real dimensions of the image\n","image_width_mm = image_width_pixels * pixel_spacing[0]\n","image_height_mm = image_height_pixels * pixel_spacing[1]\n","\n","print(\"Image width (mm): \", image_width_mm)\n","print(\"Image height (mm): \", image_height_mm)\n","\n","# Width and heigth of the head section in pixels\n","head_width_pixels = stats[label, cv2.CC_STAT_WIDTH]\n","head_height_pixels = stats[label, cv2.CC_STAT_HEIGHT]\n","\n","print(\"Head width (pixels): \", head_width_pixels)\n","print(\"Head height (pixels): \", head_height_pixels)\n","\n","# Calculate real dimensions of the head section (width, heigth)\n","head_width_mm = head_width_pixels * pixel_spacing[0]\n","head_height_mm = head_height_pixels * pixel_spacing[1]\n","\n","print(\"Head width (mm): \", head_width_mm)\n","print(\"Head height (mm): \", head_height_mm)"],"metadata":{"id":"Pij-ZLkUkTeI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.- Corner Detection"],"metadata":{"id":"lz7sv-x9xkMn"}},{"cell_type":"code","source":["# Load the grayscale image\n","image_path = '/content/drive/MyDrive/PIM/Images/X-ray_4_mod.png'\n","image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","\n","# Apply Harris corner detection\n","dst = cv2.cornerHarris(image, blockSize=2, ksize=3, k=0.04)\n","\n","# Result is dilated to mark the corners\n","kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n","dst = cv2.dilate(dst, kernel, iterations=2)\n","\n","# Create a copy of the image to mark the corners\n","image_with_corners = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n","\n","# Threshold to mark the corners in the image using a Boolean mask\n","image_with_corners[dst > 0.1 * dst.max()] = [255, 0, 0]\n","\n","\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 3, 1)\n","plt.imshow(image, cmap='gray')\n","plt.title('Original image')\n","plt.axis('off')\n","\n","plt.subplot(1, 3, 2)\n","plt.imshow(dst, cmap='gray')\n","plt.title('Harris corner distance array')\n","plt.axis('off')\n","\n","plt.subplot(1, 3, 3)\n","plt.imshow(image_with_corners)\n","plt.title('Harris corner detection')\n","plt.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"hB2zM4MpxyS7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.- Keypoints Detection"],"metadata":{"id":"azaVK3Xcxp6C"}},{"cell_type":"code","source":["# Load the grayscale image\n","image_path = '/content/drive/MyDrive/PIM/Images/X-ray_4.png'\n","image1 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","\n","# Function to apply rotation, scaling, and translation\n","def transform_image(image, angle, scale, tx, ty):\n","    # Get image dimensions\n","    rows, cols = image.shape\n","\n","    # Compute the center of the image\n","    center = (cols // 2, rows // 2)\n","\n","    # Create the transformation matrix for rotation and scaling\n","    M_rotation = cv2.getRotationMatrix2D(center, angle, scale)\n","\n","    # Apply the rotation and scaling\n","    rotated_scaled_image = cv2.warpAffine(image, M_rotation, (cols, rows))\n","\n","    # Create the translation matrix\n","    M_translation = np.float32([[1, 0, tx], [0, 1, ty]])\n","\n","    # Apply the translation\n","    transformed_image = cv2.warpAffine(rotated_scaled_image, M_translation, (cols, rows))\n","\n","    return transformed_image\n","\n","# Selectable parameters for transformation\n","angle = 45  # Rotation angle in degrees\n","scale = 0.8  # Scaling factor\n","tx, ty = 100, 50  # Translation along the x and y axes\n","\n","# Apply the transformation\n","image2 = transform_image(image1, angle, scale, tx, ty)\n","\n","\n","## Apply the SIFT algorithm\n","\n","# 1. Initialize SIFT detector\n","sift = cv2.SIFT_create(nOctaveLayers=3, contrastThreshold=0.1, edgeThreshold=10)\n","\n","# 2. Detect keypoints and descriptors with SIFT\n","# 'None' to detect keypoints in the entire image; otherwise, use a Boolean mask (255/0)\n","keypoints1, descriptors1 = sift.detectAndCompute(image1, None)\n","keypoints2, descriptors2 = sift.detectAndCompute(image2, None)\n","\n","print(\"\\nLength of keypoints in image 1: \", len(keypoints1))\n","print(\"Shape of descriptors in image 1: \", descriptors1.shape)\n","print(\"\\nLength of keypoints in image 2: \", len(keypoints2))\n","print(\"Shape of descriptors in image 2: \", descriptors2.shape)\n","\n","# Print the identified keypoints\n","#print(\"\\nCoordinates of keypoints in image 1:\")\n","#for kp in keypoints1:\n","#    print(f\"({kp.pt[0]:.2f}, {kp.pt[1]:.2f})\")\n","\n","#print(\"\\nCoordinates of keypoints in image 2:\")\n","#for kp in keypoints2:\n","#    print(f\"({kp.pt[0]:.2f}, {kp.pt[1]:.2f})\")\n","\n","# 3. Draw keypoints on the images\n","image1_keypoints = cv2.drawKeypoints(image1, keypoints1, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","image2_keypoints = cv2.drawKeypoints(image2, keypoints2, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","\n","# Plot the images with keypoints\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 2, 1)\n","plt.imshow(image1_keypoints, cmap='gray')\n","plt.title(\"Keypoints in image 1\")\n","plt.axis('off')\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(image2_keypoints, cmap='gray')\n","plt.title(\"Keypoints in image 2\")\n","plt.axis('off')\n","\n","plt.show()\n","\n","# 4a. Use the Brute-Force Matcher to match keypoints based on their descriptors\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n","matches = bf.match(descriptors1, descriptors2)\n","\n","# 4b. Sort the matches based on their distances (lower distance is better)\n","def get_distance(match): # this function receives an object, 'match', which have a property called 'distance'\n","    return match.distance # accesses and returns the 'distance' attribute of the 'match' object\n","\n","# sorts the 'matches' list using the sorted function\n","# sorted() returns a new sorted list and leaves the original list unchanged\n","# key=get_distance indicates the sorted() function to use the get_distance function to extract\n","#   the value to sort by (in this case, the distance attribute)\n","matches = sorted(matches, key=get_distance)\n","print(\"Number of matches: \", len(matches))\n","\n","# 5. Draw the matched keypoints between the two images\n","# Plotting of the best matches (ordered by distance)\n","matched_image = cv2.drawMatches(image1, keypoints1, image2, keypoints2, matches[:10], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","\n","# Plot the matched keypoints\n","plt.figure(figsize=(10, 5))\n","plt.imshow(matched_image)\n","plt.title(\"Matched keypoints\")\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"P_Rvu0sWlpZe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.- Shape Detection"],"metadata":{"id":"KcgRZZ-4xbin"}},{"cell_type":"code","source":["from skimage.filters import frangi\n","\n","# Load the image in grayscale\n","image_path = '/content/drive/MyDrive/PIM/Images/Retina_blood_vessel_9.png'\n","#image_path = '/content/drive/MyDrive/PIM/Images/Cerebral_Angiogram_Lateral_Wikipedia.jpg'\n","image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","image_float = np.float32(image)\n","\n","# Apply CLAHE algorithm\n","clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","clahe_image = clahe.apply(image)\n","\n","# Convert the CLAHE image to float and normalize it to the range [0, 1]\n","clahe_image_float = cv2.normalize(clahe_image.astype(np.float32), None, 0.0, 1.0, cv2.NORM_MINMAX)\n","\n","# Apply the Frangi filter\n","frangi_filtered = frangi(clahe_image_float, gamma=15, black_ridges=True)\n","print(f\"Minimum and maximum values of the Frangi image: {np.min(frangi_filtered)}, {np.max(frangi_filtered)}\")\n","\n","# Scale the Frangi output back to [0, 255] and convert it to uint8\n","scaled_frangi = cv2.normalize(frangi_filtered, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n","\n","# Apply histogram equalization\n","equalized_frangi = cv2.equalizeHist(scaled_frangi)\n","\n","\n","plt.figure(figsize=(8, 12))\n","\n","# Display the original image\n","plt.subplot(3, 2, 1)\n","plt.title(\"Original image\")\n","plt.imshow(image, cmap='gray', vmin=0, vmax=255)\n","plt.axis('off')\n","\n","# Display the CLAHE-enhanced image\n","plt.subplot(3, 2, 2)\n","plt.title(\"CLAHE-enhanced image\")\n","plt.imshow(clahe_image, cmap='gray', vmin=0, vmax=255)\n","plt.axis('off')\n","\n","# Display the normalized Frangi filtered image\n","plt.subplot(3, 2, 3)\n","plt.title(\"Frangi filtered image (normalized)\")\n","plt.imshow(scaled_frangi, cmap='gray', vmin=0, vmax=255)\n","plt.axis('off')\n","\n","# Display the histogram-equalized Frangi filtered image\n","plt.subplot(3, 2, 4)\n","plt.title(f\"Histogram equalized image\")\n","plt.imshow(equalized_frangi, cmap='gray', vmin=0, vmax=255)\n","plt.axis('off')\n","\n","# Display the histogram of the Frangi filtered image\n","plt.subplot(3, 2, 5)\n","plt.hist(scaled_frangi.flatten(), bins=256, range=[0, 256], color='black')\n","plt.title(f'Histogram of the\\n Frangi image')\n","\n","# Display the histogram of the equalized image\n","plt.subplot(3, 2, 6)\n","plt.hist(equalized_frangi.flatten(), bins=256, range=[0, 256], color='black')\n","plt.title(f'Histogram of the\\n equalized image')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"5HW_SXM2xaKm"},"execution_count":null,"outputs":[]}]}