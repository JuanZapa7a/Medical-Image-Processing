{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanZapa7a/Medical-Image-Processing/blob/main/Medical%20Instance%20Segmentation%20with%20Mask%20RCNN%20Custom%20Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yriBsaV_QxZ"
      },
      "source": [
        "# Medical Instance Segmentation with Mask RCNN Custom Finetuning.\n",
        "\n",
        "Mask R-CNN extends [Faster R-CNN](http://paperswithcode.com/method/faster-r-cnn) to solve instance segmentation tasks. It achieves this by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. In principle, Mask R-CNN is an intuitive extension of Faster R-CNN, but constructing the mask branch properly is critical for good results.\n",
        "\n",
        "Most importantly, Faster R-CNN was not designed for pixel-to-pixel alignment between network inputs and outputs. This is evident in how [RoIPool](http://paperswithcode.com/method/roi-pooling), the de facto core operation for attending to instances, performs coarse spatial quantization for feature extraction. To fix the misalignment, Mask R-CNN utilises a simple, quantization-free layer, called [RoIAlign](http://paperswithcode.com/method/roi-align), that faithfully preserves exact spatial locations.\n",
        "\n",
        "## Dataset Overview:\n",
        "\n",
        "The [NuInsSeg dataset](https://www.kaggle.com/datasets/ipateam/nuinsseg/data) contains more than 30k manually segmented nuclei from 31 human and mouse organs and 665 image patches extracted from H&E-stained whole slide images. We also provide ambiguous area masks for the entire dataset to show in which areas manual semantic/instance segmentation were impossible.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Upload your Kaggle API Key**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfMsAlRn_PXP"
      },
      "outputs": [],
      "source": [
        "%pip install -q kaggle\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**Install Kaggle API Library**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "**Copy the API key to `~/.kaggle`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "%mkdir -p ~/.kaggle\n",
        "%cp ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls -al ~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "**Download ipateam/nuinsseg**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!kaggle datasets download -d ipateam/nuinsseg --unzip --force ./dataset-Nuclei"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q pycocotools\n",
        "\n",
        "---\n",
        "\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "import json\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import requests\n",
        "from   zipfile import ZipFile\n",
        "import argparse\n",
        "import shutil\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn\n",
        "import torchvision\n",
        "\n",
        "\n",
        "from torchvision import transforms as T\n",
        "\n",
        "from pycocotools import mask as coco_mask\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Data Preparation\n",
        "\n",
        "\n",
        "Clean up of the Nuclei dataset\n",
        "Can be downloaded from: https://www.kaggle.com/datasets/ipateam/nuinsseg?resource=download\n",
        "\n",
        "The dataset comes with a lot of subdirectories that can be very useful depending\n",
        "on the task of your interest. For our Mask RCNN and Ultralytics training, we just\n",
        "need the raw images and labeled masks that we will convert to appropriate formats.\n",
        "So let us delete all unwanted data and keep only the raw images, binary masks\n",
        "and label masks.\n",
        "\n",
        "Keep the directories with names 'tissue images', 'mask binary without border', and 'label masks modify'\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def prune_subdirectories(base_dir,keep_dirs):\n",
        "    #Iterate through each subdirs in base dir\n",
        "    for root_dir in os.listdir(base_dir):\n",
        "        root_path = os.path.join(base_dir,root_dir)\n",
        "        if os.path.isdir(root_path):\n",
        "          #  print(f\"Processing: {root_path}\")\n",
        "           #List all subdirs inside the current root dir\n",
        "           for sub_dir in os.listdir(root_path):\n",
        "               sub_path = os.path.join(root_path, sub_dir)\n",
        "               #If the subdirectory isn't in the keep list, delete it\n",
        "               if os.path.isdir(sub_path) and sub_dir not in keep_dirs:\n",
        "                  # print(f\"Deleting: {sub_path}\")\n",
        "                  shutil.rmtree(sub_path)\n",
        "               elif os.path.isdir(sub_path):\n",
        "                  # print(f\"Keeping: {sub_path}\")\n",
        "                  pass\n",
        "\n",
        "\n",
        "base_directory = \"Dataset-Nuclei\"\n",
        "directories_to_keep = ['tissue images', 'mask binary witthout border', 'label masks modify']\n",
        "\n",
        "prune_subdirectories(base_directory,directories_to_keep)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Install Pip Tree globally\n",
        "%%capture\n",
        "!sudo apt install tree\n",
        "\n",
        "\n",
        "!tree --dirsfirst -L 2  \"Dataset-Nuclei\"\n",
        "\n",
        "Dataset-Nuclei\n",
        "├── human bladder\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human brain\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human cardia\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human cerebellum\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human epiglottis\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human jejunum\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human kidney\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human liver\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human lung\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human melanoma\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human muscle\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human oesophagus\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human pancreas\n",
        "│   ├── label masks modify\n",
        "│   ├── tissue images\n",
        "│   └── Thumbs.db\n",
        "├── human peritoneum\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human placenta\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human pylorus\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human rectum\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human salivory gland\n",
        "│   ├── label masks modify\n",
        "│   ├── tissue images\n",
        "│   └── Thumbs.db\n",
        "├── human spleen\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human testis\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human tongue\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human tonsile\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── human umbilical cord\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── mouse fat (white and brown)_subscapula\n",
        "│   ├── label masks modify\n",
        "│   ├── tissue images\n",
        "│   └── Thumbs.db\n",
        "├── mouse femur\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── mouse heart\n",
        "│   ├── label masks modify\n",
        "│   ├── tissue images\n",
        "│   └── Thumbs.db\n",
        "├── mouse kidney\n",
        "│   ├── label masks modify\n",
        "│   ├── tissue images\n",
        "│   └── Thumbs.db\n",
        "├── mouse liver\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── mouse muscle_tibia\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "├── mouse spleen\n",
        "│   ├── label masks modify\n",
        "│   └── tissue images\n",
        "└── mouse thymus\n",
        "    ├── label masks modify\n",
        "    └── tissue images\n",
        "\n",
        "93 directories, 5 files\n",
        "#Convert Label Masks to Coco Json Single File annotation\n",
        "\n",
        "\"\"\"\n",
        "With this code, we will convert our labeled mask image annotations to coco json\n",
        "format so they can be used in training Mask R-CNN.\n",
        "\n",
        "\"\"\"\n",
        "def get_image_mask_pairs(data_dir):\n",
        "    image_paths = []\n",
        "    mask_paths = []\n",
        "\n",
        "    for root,_,files in os.walk(data_dir):\n",
        "        if 'tissue images' in root:\n",
        "            for file in files:\n",
        "                if file.endswith('.png'):\n",
        "                    image_paths.append(os.path.join(root,file))\n",
        "                    mask_paths.append(os.path.join(root.replace('tissue images','label masks modify'), file.replace('.png','.tif')))\n",
        "    return image_paths, mask_paths\n",
        "\n",
        "def mask_to_polygons(mask,epsilon=1.0):\n",
        "    contours,_ = cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    polygons = []\n",
        "    for contour in contours:\n",
        "        if len(contour) > 2:\n",
        "           poly = contour.reshape(-1).tolist()\n",
        "           if len(poly) > 4: #Ensures valid polygon\n",
        "              polygons.append(poly)\n",
        "    return polygons\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def process_data(image_paths, mask_paths, output_dir,train=True):\n",
        "    annotations = []\n",
        "    images = []\n",
        "    image_id = 0\n",
        "    ann_id = 0\n",
        "\n",
        "    for img_path, mask_path in zip(image_paths, mask_paths):\n",
        "        image_id += 1\n",
        "        img = cv2.imread(img_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "        # Copy image to output directory\n",
        "        shutil.copy(img_path, os.path.join(output_dir, os.path.basename(img_path)))\n",
        "\n",
        "        images.append({\n",
        "            \"id\": image_id,\n",
        "            \"file_name\": os.path.basename(img_path),\n",
        "            \"height\": img.shape[0],\n",
        "            \"width\": img.shape[1]\n",
        "        })\n",
        "\n",
        "        unique_values = np.unique(mask)\n",
        "        for value in unique_values:\n",
        "            if value == 0:  # Ignore background\n",
        "                continue\n",
        "\n",
        "            object_mask = (mask == value).astype(np.uint8) * 255\n",
        "            polygons = mask_to_polygons(object_mask)\n",
        "\n",
        "            for poly in polygons:\n",
        "                ann_id += 1\n",
        "                annotations.append({\n",
        "                    \"id\": ann_id,\n",
        "                    \"image_id\": image_id,\n",
        "                    \"category_id\": 1,  # Only one category: Nuclei\n",
        "                    \"segmentation\": [poly],\n",
        "                    \"area\": cv2.contourArea(np.array(poly).reshape(-1, 2)),\n",
        "                    \"bbox\": list(cv2.boundingRect(np.array(poly).reshape(-1, 2))),\n",
        "                    \"iscrowd\": 0\n",
        "                })\n",
        "\n",
        "    coco_input = {\n",
        "        \"images\": images,\n",
        "        \"annotations\": annotations,\n",
        "        \"categories\": [{\"id\": 1, \"name\": \"Nuclei\"}]\n",
        "    }\n",
        "\n",
        "    if train:\n",
        "        with open(os.path.join(output_dir, 'instances_train2017.json'), 'w') as f:\n",
        "            json.dump(coco_input, f)\n",
        "    else:\n",
        "        with open(os.path.join(output_dir, 'instances_val2017.json'), 'w') as f:\n",
        "            json.dump(coco_input, f)\n",
        "\n",
        "#instances_train2017.json\n",
        "def main():\n",
        "    data_dir = 'Dataset-Nuclei'\n",
        "    output_dir = 'Nuclei_Instance_COCO_input'\n",
        "    train_dir = os.path.join(output_dir, 'train2017') #we will stick with naming from official repo scripts\n",
        "    val_dir = os.path.join(output_dir, 'val2017')\n",
        "\n",
        "    # Create output directories\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "    image_paths, mask_paths = get_image_mask_pairs(data_dir)\n",
        "\n",
        "    # Split data into train and val\n",
        "    train_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Process train and val data\n",
        "    process_data(train_img_paths, train_mask_paths, train_dir,train=True)\n",
        "    process_data(val_img_paths, val_mask_paths, val_dir,train=False)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "!mkdir ./Nuclei_Instance_COCO_input/annotations\n",
        "!mv ./Nuclei_Instance_COCO_input/train2017/instances_train2017.json  ./Nuclei_Instance_COCO_input/annotations/\n",
        "!mv ./Nuclei_Instance_COCO_input/val2017/instances_val2017.json  ./Nuclei_Instance_COCO_input/annotations/\n",
        "\n",
        "!mkdir -p ./Nuclei_Instance_COCO_input/outputs/training/nuclei_instance_out\n",
        "!mkdir -p ./Nuclei_Instance_COCO_input/outputs/inference/nuclei_instance_out\n",
        "!tree --dirsfirst -L 1 \"Nuclei_Instance_COCO_input\"\n",
        "Nuclei_Instance_COCO_input\n",
        "├── annotations\n",
        "├── outputs\n",
        "├── train2017\n",
        "└── val2017\n",
        "\n",
        "4 directories, 0 files\n",
        "!tree --dirsfirst -L 1 \"Nuclei_Instance_COCO_input/annotations\"\n",
        "Nuclei_Instance_COCO_input/annotations\n",
        "├── instances_train2017.json\n",
        "└── instances_val2017.json\n",
        "\n",
        "0 directories, 2 files\n",
        "Visualise Coco Label - Dataset visualise - Only Contours\n",
        "\n",
        "\n",
        "def display_images_with_coco_annotations(image_paths, annotations, display_type='both', filled=True):\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
        "\n",
        "    for ax, img_path in zip(axs.ravel(), image_paths):\n",
        "        # Load image using OpenCV and convert it from BGR to RGB color space\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        ax.imshow(image)\n",
        "        ax.axis('off')  # Turn off the axes\n",
        "\n",
        "        # Get image filename to match with annotations\n",
        "        img_filename = os.path.basename(img_path)\n",
        "        img_id = next(item for item in annotations['images'] if item[\"file_name\"] == img_filename)['id']\n",
        "\n",
        "        # Filter annotations for the current image\n",
        "        img_annotations = [ann for ann in annotations['annotations'] if ann['image_id'] == img_id]\n",
        "\n",
        "        green_color = (0, 0,1)  # RGB for green\n",
        "\n",
        "        for ann in img_annotations:\n",
        "            # Display bounding box\n",
        "            if display_type in ['bbox', 'both']:\n",
        "                bbox = ann['bbox']\n",
        "                rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3],\n",
        "                                         linewidth=1, edgecolor=green_color,\n",
        "                                         facecolor='none')\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "            # Display segmentation polygon\n",
        "            if display_type in ['seg', 'both']:\n",
        "                for seg in ann['segmentation']:\n",
        "                    poly = [(seg[i], seg[i+1]) for i in range(0, len(seg), 2)]\n",
        "                    if filled == False:\n",
        "                        polygon = patches.Polygon(poly, closed=True, edgecolor=green_color, fill=False)\n",
        "                    else:\n",
        "                        polygon = patches.Polygon(poly, closed=True, edgecolor=green_color, fill=True, facecolor=green_color, alpha=0.7)\n",
        "\n",
        "                    ax.add_patch(polygon)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "# Load COCO annotations\n",
        "with open('Nuclei_Instance_COCO_input/annotations/instances_train2017.json','r') as f:\n",
        "     annotations = json.load(f)\n",
        "\n",
        "# Get all image files\n",
        "image_dir = \"Nuclei_Instance_COCO_input/train2017\"\n",
        "all_images_files = [os.path.join(image_dir,img['file_name']) for img in annotations['images']]\n",
        "random_image_files = random.sample(all_images_files,4)\n",
        "\n",
        "# Choose between 'bbox', 'seg', or 'both'\n",
        "display_type = \"seg\"\n",
        "display_images_with_coco_annotations(random_image_files,annotations,display_type,fil\n",
        "                                     \n",
        "                                     \n",
        "                                     \n",
        "                                     \n",
        "                                     \n",
        "                                     \n",
        "                                     \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From torchvision download training scripts for detection that we will be using for training Mask RCNN:\n",
        "https://github.com/pytorch/vision/tree/main/references/detection\n",
        "\n",
        "Create folder scripts in current working directory of colab and have these torchvision scripts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class_names = \"\"\"\n",
        "INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__',\n",
        "    'Nuclei',\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "with open('class_names.py', 'w') as file:\n",
        "    file.write(class_names)\n",
        "    \n",
        "    \n",
        "!tree --dirsfirst -L 2 \"..\"\n",
        "..\n",
        "├── Nuclei_Instance_COCO_input\n",
        "│   ├── annotations\n",
        "│   ├── outputs\n",
        "│   ├── train2017\n",
        "│   └── val2017\n",
        "├── scripts\n",
        "│   ├── class_names.py\n",
        "│   ├── coco_eval.py\n",
        "│   ├── coco_utils.py\n",
        "│   ├── engine.py\n",
        "│   ├── group_by_aspect_ratio.py\n",
        "│   ├── presets.py\n",
        "│   ├── train.py\n",
        "│   ├── transforms.py\n",
        "│   └── utils.py\n",
        "└── nuinsseg.zip\n",
        "\n",
        "6 directories, 10 files\n",
        "\n",
        "'''In train.py script change the following :'''\n",
        "\n",
        "#train.py\n",
        "\n",
        "import torch.nn as nn\n",
        "from class_names import INSTANCE_CATEGORY_NAMES as class_names\n",
        "\n",
        "#Next  to this line\n",
        "model = torchvision.models.get_model(\n",
        "        args.model, weights=args.weights, weights_backbone=args.weights_backbone, num_classes=num_classes, **kwargs\n",
        "    )\n",
        "model.roi_heads.box_predictor.cls_score = nn.Linear(in_features=1024, out_features=len(class_names),bias=True)\n",
        "model.roi_heads.box_predictor.bbox_pred = nn.Linear(in_features=1024, out_features=len(class_names)*4,bias=True)\n",
        "model.roi_heads.mask_predictor.mask_fcn_logits = nn.Conv2d(256, len(class_names),kernel_size=(1,1),stride=(1,1))\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "!python train.py \\\n",
        "--data-path ../Nuclei_Instance_COCO_input \\\n",
        "--model maskrcnn_resnet50_fpn_v2 \\\n",
        "--weights MaskRCNN_ResNet50_FPN_V2_Weights.COCO_V1 \\\n",
        "--batch-size 4 \\\n",
        "--epochs 10 \\\n",
        "--lr 0.005 \\\n",
        "--output-dir ../Nuclei_Instance_COCO_input/outputs/training/nuclei_instance_out \\\n",
        "--amp \\\n",
        "--lr-steps 10 \\\n",
        "--data-augmentation lsj \\\n",
        "--use-copypaste \\\n",
        "--workers 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "INFERENCE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(pretrained=False)\n",
        "\n",
        "from class_names import INSTANCE_CATEGORY_NAMES as class_names\n",
        "\n",
        "model.roi_heads.box_predictor.cls_score = nn.Linear(in_features=1024,out_features=len(class_names),bias=True)\n",
        "model.roi_heads.box_predictor.bbox_pred = nn.Linear(in_features=1024,out_features=len(class_names)*4,bias=True)\n",
        "model.roi_heads.mask_predictor.mask_fcn_logits = nn.Conv2d(256,len(class_names),kernel_size=(1,1),stride=(1,1))\n",
        "OUT_DIR = \"../Nuclei_Instance_COCO_input/outputs\"\n",
        "# ckpt = torch.load(os.path.join(OUT_DIR,\"training/nuclei_instance_out/checkpoint.pth\"))\n",
        "ckpt = torch.load(\"../Nuclei_Instance_COCO_input/outputs/training/nuclei_instance_out/checkpoint.pth\")\n",
        "model.load_state_dict(ckpt['model'])\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device).eval()\n",
        "print(model)\n",
        "np.random.seed(0)\n",
        "\n",
        "def get_outputs(image, model, threshold):\n",
        "    # print(\"Get out Image shape\",image.shape)\n",
        "    with torch.no_grad():\n",
        "        # forward pass of the image through the model.\n",
        "        outputs = model(image)\n",
        "\n",
        "    # get all the scores\n",
        "    scores = list(outputs[0]['scores'].detach().cpu().numpy())\n",
        "    # index of those scores which are above a certain threshold\n",
        "    thresholded_preds_inidices = [scores.index(i) for i in scores if i > threshold]\n",
        "    thresholded_preds_count = len(thresholded_preds_inidices)\n",
        "    # get the masks\n",
        "    masks = (outputs[0]['masks']>0.5).squeeze().detach().cpu().numpy()\n",
        "    # discard masks for objects which are below threshold\n",
        "    masks = masks[:thresholded_preds_count]\n",
        "\n",
        "    # get the bounding boxes, in (x1, y1), (x2, y2) format\n",
        "    boxes = [[(int(i[0]), int(i[1])), (int(i[2]), int(i[3]))]  for i in outputs[0]['boxes'].detach().cpu()]\n",
        "    # discard bounding boxes below threshold value\n",
        "    boxes = boxes[:thresholded_preds_count]\n",
        "    # get the classes labels\n",
        "    labels = [class_names[i] for i in outputs[0]['labels']]\n",
        "    return masks, boxes, labels\n",
        "np.random.seed(0)\n",
        "\n",
        "def get_outputs(image, model, threshold):\n",
        "    # print(\"Get out Image shape\",image.shape)\n",
        "    with torch.no_grad():\n",
        "        # forward pass of the image through the model.\n",
        "        outputs = model(image)\n",
        "\n",
        "    # get all the scores\n",
        "    scores = list(outputs[0]['scores'].detach().cpu().numpy())\n",
        "    # index of those scores which are above a certain threshold\n",
        "    thresholded_preds_inidices = [scores.index(i) for i in scores if i > threshold]\n",
        "    thresholded_preds_count = len(thresholded_preds_inidices)\n",
        "    # get the masks\n",
        "    masks = (outputs[0]['masks']>0.5).squeeze().detach().cpu().numpy()\n",
        "    # discard masks for objects which are below threshold\n",
        "    masks = masks[:thresholded_preds_count]\n",
        "\n",
        "    # get the bounding boxes, in (x1, y1), (x2, y2) format\n",
        "    boxes = [[(int(i[0]), int(i[1])), (int(i[2]), int(i[3]))]  for i in outputs[0]['boxes'].detach().cpu()]\n",
        "    # discard bounding boxes below threshold value\n",
        "    boxes = boxes[:thresholded_preds_count]\n",
        "    # get the classes labels\n",
        "    labels = [class_names[i] for i in outputs[0]['labels']]\n",
        "    return masks, boxes, labels\n",
        "def draw_segmentation_map(image, masks, boxes, labels):\n",
        "    alpha = 1.0\n",
        "    beta = 0.5 # transparency for the segmentation map\n",
        "    gamma = 0 # scalar added to each sum\n",
        "    #convert the original PIL image into NumPy format\n",
        "    image = np.array(image)\n",
        "    # convert from RGN to OpenCV BGR format\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    for i in range(len(masks)):\n",
        "        # apply a random color mask to each object\n",
        "        color = [random.randint(0, 255) for _ in range(3)]\n",
        "        if masks[i].any() == True:\n",
        "            red_map = np.zeros_like(masks[i]).astype(np.uint8)\n",
        "            green_map = np.zeros_like(masks[i]).astype(np.uint8)\n",
        "            blue_map = np.zeros_like(masks[i]).astype(np.uint8)\n",
        "            red_map[masks[i] == 1], green_map[masks[i] == 1], blue_map[masks[i] == 1] = color\n",
        "            # combine all the masks into a single image\n",
        "            segmentation_map = np.stack([red_map, green_map, blue_map], axis=2)\n",
        "            # apply mask on the image\n",
        "            cv2.addWeighted(image, alpha, segmentation_map, beta, gamma, image)\n",
        "\n",
        "            # draw the bounding boxes around the objects\n",
        "            cv2.rectangle(image, boxes[i][0], boxes[i][1], color=color,\n",
        "                        thickness=2)\n",
        "            # put the label text above the objects\n",
        "            # cv2.putText(image , labels[i], (boxes[i][0][0], boxes[i][0][1]-10),\n",
        "            #             cv2.FONT_HERSHEY_SIMPLEX, 1, color,\n",
        "            #             thickness=2, lineType=cv2.LINE_AA)\n",
        "    return image\n",
        "validation_path = \"../Nuclei_Instance_COCO_input/val2017\"\n",
        "image_paths = glob.glob(os.path.join(validation_path,'*png'))\n",
        "transform = T.Compose([\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "fig = plt.figure(figsize=(10,25),layout=\"constrained\")\n",
        "\n",
        "for image_path in image_paths:\n",
        "    # print(image_path)\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    # keep a copy of the original image for OpenCV functions and applying masks\n",
        "    orig_image = image.copy()\n",
        "\n",
        "    image = transform(image)\n",
        "    #add a batch dimension\n",
        "    image = image.unsqueeze(0).to(device)\n",
        "    # print(\"Image shape\",image.shape)\n",
        "\n",
        "    masks,boxes,labels = get_outputs(image,model,threshold=0.5)\n",
        "\n",
        "    result = draw_segmentation_map(orig_image,masks,boxes,labels)\n",
        "\n",
        "    save_path = f\"{OUT_DIR}/inference/nuclei_instance_out{image_path.split(os.path.sep)[-1].split('.')[0]}.jpg\"\n",
        "    cv2.imwrite(save_path, result)\n",
        "\n",
        "    #visualise images\n",
        "    plt.imshow(result)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOpfkKawQX4/fcfskxf3+mJ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
