{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanZapa7a/Medical-Image-Processing/blob/main/Roboflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03T45nGa2flV"
      },
      "source": [
        "# [Getting Started with Roboflow](https://blog.roboflow.com/getting-started-with-roboflow/)\n",
        "\n",
        "## 1. Introduction to [Roboflow](https://docs.roboflow.com/api-reference/introduction)\n",
        "\n",
        "Roboflow is a platform that simplifies the process of building machine learning models. It provides tools for data management, annotation, preprocessing, model augmentation and deployment. Roboflow is popular among developers, with over 100,000 developers having built with Roboflow tools[^1^][1][^2^][2]. Despite its popularity, there are alternatives to Roboflow, such as INTSIG, SuperAnnotate, Google Cloud Vision API and Encord[^3^][4].\n",
        "\n",
        "### Limitations of the free version of Roboflow:\n",
        "\n",
        "The free version of Roboflow allows up to 3 users. Up to 10,000 source images can be managed. 3 training credits are provided. 1,000 inference credits are awarded per month. Projects, including datasets, are open source to contribute to the community.\n",
        "\n",
        "### Roboflow integration with Google Colab:\n",
        "\n",
        "Roboflow integrates well with Google Colab. In fact, Roboflow has produced dozens of workbooks showing how to train computer vision models in Google Colab345 . These workbooks are step-by-step guides on how to train models and perform other computer vision tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bMj9y3sAmKY",
        "outputId": "6f8a3184-2652-44c5-848f-ef4478f9f97c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.32-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting certifi==2023.7.22 (from roboflow)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl.metadata (722 bytes)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from roboflow) (3.8.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from roboflow) (1.26.2)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from roboflow) (10.3.0)\n",
            "Requirement already satisfied: python-dateutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from roboflow) (2.2.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from roboflow) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib->roboflow) (4.53.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib->roboflow) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->roboflow) (3.3.2)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'opencv-python-headless' candidate (version 4.8.0.74 at https://files.pythonhosted.org/packages/76/02/f128517f3ade4bb5f71e2afd8461dba70e3f466ce745fa1fd1fade9ad1b7/opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from https://pypi.org/simple/opencv-python-headless/) (requires-python:>=3.6))\n",
            "Reason for being yanked: deprecated, use 4.8.0.76\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading roboflow-1.1.32-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-magic, opencv-python-headless, idna, cycler, chardet, certifi, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.6.2\n",
            "    Uninstalling certifi-2024.6.2:\n",
            "      Successfully uninstalled certifi-2024.6.2\n",
            "Successfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.32\n"
          ]
        }
      ],
      "source": [
        "# Paso 1: Instalación de Roboflow CLI\n",
        "%pip install roboflow\n",
        "\n",
        "# Paso 2: Importar las bibliotecas necesarias\n",
        "import os\n",
        "import roboflow\n",
        "\n",
        "# Paso 3: Iniciar sesión en Roboflow\n",
        "rf = roboflow.Roboflow(api_key=\"5xvhWbT7GJjHZvn6ukFk\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1S1ydKEInCg"
      },
      "source": [
        "## 2. Creating a RoboFlow Account\n",
        "\n",
        "To get started, [create a free Roboflow account](https://app.roboflow.com/?ref=blog.roboflow.com). For example, my account is associated to GitHub.\n",
        "\n",
        "After reviewing and accepting the terms of service, you will be asked to choose between one of two plans: the Public Plan and the Starter Plan.\n",
        "\n",
        "![image.png](https://blog.roboflow.com/content/images/size/w1000/2024/02/Screenshot-2024-02-12-at-09.31.24.png)\n",
        "\n",
        "Then, you will be asked to invite collaborators to your workspace. These collaborators can help you annotate images or manage the vision projects in your workspace.\n",
        "\n",
        "Once you have invited people to your workspace (if you want to), you will be able to create a project.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 3. Create a Project\n",
        "\n",
        "![image.png](https://blog.roboflow.com/content/images/size/w1000/2024/02/Screenshot-2024-02-12-at-10.02.25.png)\n",
        "\n",
        "For this example, we will be using a dataset of cells to train a model that can identify cells for counting. This model could be used for medical analysis in a  health facility. With that said, you can use any images you want to train a model.\n",
        "\n",
        "Leave the project type as the default \"Object Detection\" option since our model will be identifying specific objects and we want to know their location within the image.\n",
        "\n",
        "Click “Create Public Project.” to continue.\n",
        "\n",
        "For this walkthrough, we’ll use a Roboflow provided sample cell dataset (Count-cells by FirstProject `cells-upja`). [Download the cell dataset](https://universe.roboflow.com/search?q=object%20detection%20cells).\n",
        "\n",
        "Once you have downloaded the dataset, unzip the file. Click and drag the folder called screw-dataset from your local machine onto the highlighted upload area. This dataset is structured in the COCO JSON format, [one of 40+ computer vision formats Roboflow supports](https://roboflow.com/formats?ref=blog.roboflow.com).\n",
        "\n",
        "\n",
        "### COCO JSON Format\n",
        "The COCO JSON format is a file format used to store annotations for datasets in computer vision tasks, particularly object detection, instance segmentation, and related tasks. COCO (Common Objects in Context) is a widely used standard in the computer vision community and provides a structured framework for organizing and labeling image data.\n",
        "\n",
        "The COCO JSON file consists of several main components:\n",
        "\n",
        "1. **Info**: General information about the dataset, such as the year, version, description, and contributor.\n",
        "    ```json\n",
        "    {\n",
        "      \"year\": 2024,\n",
        "      \"version\": \"1.0\",\n",
        "      \"description\": \"Example Dataset\",\n",
        "      \"contributor\": \"Example\",\n",
        "      \"date_created\": \"2024-07-06\"\n",
        "    }\n",
        "    ```\n",
        "\n",
        "2. **Licenses**: Information about the licenses of the images contained in the dataset.\n",
        "    ```json\n",
        "    [\n",
        "      {\n",
        "        \"id\": 1,\n",
        "        \"name\": \"Example License\",\n",
        "        \"url\": \"http://example.com/license\"\n",
        "      }\n",
        "    ]\n",
        "    ```\n",
        "\n",
        "3. **Images**: Information about each image in the dataset, including the image ID, file name, height, and width.\n",
        "    ```json\n",
        "    [\n",
        "      {\n",
        "        \"id\": 1,\n",
        "        \"width\": 640,\n",
        "        \"height\": 480,\n",
        "        \"file_name\": \"image1.jpg\",\n",
        "        \"license\": 1,\n",
        "        \"date_captured\": \"2024-07-06\"\n",
        "      }\n",
        "    ]\n",
        "    ```\n",
        "\n",
        "4. **Annotations**: Annotations associated with the images, including information about object categories, object locations (bounding boxes), and segmentation masks.\n",
        "    ```json\n",
        "    [\n",
        "      {\n",
        "        \"id\": 1,\n",
        "        \"image_id\": 1,\n",
        "        \"category_id\": 1,\n",
        "        \"segmentation\": [[100.0, 100.0, 150.0, 100.0, 150.0, 150.0, 100.0, 150.0]],\n",
        "        \"area\": 2500.0,\n",
        "        \"bbox\": [100.0, 100.0, 50.0, 50.0],\n",
        "        \"iscrowd\": 0\n",
        "      }\n",
        "    ]\n",
        "    ```\n",
        "\n",
        "5. **Categories**: Information about the different object categories present in the dataset.\n",
        "    ```json\n",
        "    [\n",
        "      {\n",
        "        \"id\": 1,\n",
        "        \"name\": \"person\",\n",
        "        \"supercategory\": \"human\"\n",
        "      }\n",
        "    ]\n",
        "    ```\n",
        "\n",
        "These components are structured in a JSON file that can be processed by various libraries and tools for computer vision tasks. This format facilitates interoperability and the use of datasets in various projects and experiments.\n",
        "\n",
        "Once you drop the cell-dataset folder into Roboflow, the images and annotations are processed for you to see them overlayed.\n",
        "\n",
        "![image2](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_11-19.png?raw=1)\n",
        "\n",
        "If any of your annotations have errors, Roboflow alerts you. For example, if some of the annotations improperly extended beyond the frame of an image, Roboflow intelligently crops the edge of the annotation to line up with the edge of the image and drops erroneous annotations that lie fully outside the image frame.\n",
        "\n",
        "At this point, our images have not yet been uploaded to Roboflow. We can verify that all the images are, indeed, the ones we want to include in our dataset and that our annotations are being parsed properly. Any image can be deleted upon mousing over it and selecting the trash icon.\n",
        "\n",
        "Note that one of our images is marked as `\"Not Annotated\"` on the dashboard. We'll annotate this image in the next section.\n",
        "\n",
        "Everything now looks good. Click `“Save and Continue”` in the upper right-hand corner to upload your data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " \n",
        "## 4. Spliting our Dataset: Train, Test and Valid Sets\n",
        "You will be asked to choose a dataset split. This refers to how images will be split between three sets: `Train, Test, and Valid`.\n",
        "\n",
        "1. Your train set contains the images that will be used to train your model.\n",
        "2. Your valid set will be used during training to validate performance of your model.\n",
        "3. Your test set contains images you can use to manually test the performance of your model. Learn more about [image dataset splits](https://blog.roboflow.com/train-test-split/) and why to use them.\n",
        "\n",
        "You can set your own custom splits with Roboflow or, if one is available, use an existing split in a dataset. Our dataset has already been split with Roboflow, so we can choose the \"Use existing values\" option when asked how to split our images:\n",
        "\n",
        "![image3](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_11-41.png?raw=1)\n",
        "\n",
        "You can [upload videos](https://blog.roboflow.com/youtube-video-computer-vision/) as well as images. We already have enough images for our project, but we'll talk through this process in case you want to add video data to your projects in the future.\n",
        "\n",
        "To upload a video, go to the Upload tab in the Roboflow sidebar and drag in a video. You can also paste in the URL of a YouTube video you want to upload.\n",
        "\n",
        "![image4](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_11-47.png?raw=1)\n",
        "\n",
        "When you upload a video, you will be asked how many images should be captured per second. If you choose \"1 frame / second\", an image will be taken every second from the video and saved to Roboflow.\n",
        "\n",
        "![image5](https://blog.roboflow.com/content/images/size/w1000/2023/03/Screenshot-2023-03-20-at-11.53.53.png)\n",
        "\n",
        "When you have selected an option, click \"Choose Frame Rate\". This will begin the process of collecting images from the video.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 5. Annotate Images\n",
        "\n",
        "One of the images in the sample dataset is not yet annotated. You will use [Roboflow Annotate](https://roboflow.com/annotate?ref=blog.roboflow.com) to [add a box around the unlabeled screws](https://youtu.be/O-ZPxTpb2Yg?t=220&ref=blog.roboflow.com) in the image.\n",
        "\n",
        "Annotations are the answer key from which your model learns. The more annotated images we add, the more information our model has to learn what each class is (in our case, more images will help our model identify what is a cell).\n",
        "\n",
        "![image6](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_11-55.png?raw=1)\n",
        "\n",
        "With Roboflow [Label Assist](https://blog.roboflow.com/announcing-label-assist/), you can use previous versions of your model to annotate future versions. Label Assist uses another model to draw annotations on images for you, which means you can spend less time annotating and get a model ready for production faster than ever.\n",
        "\n",
        "You can use publicly available models hosted on [Roboflow Universe, our dataset community, for label assist](https://blog.roboflow.com/launch-universe-model-checkpoint/), too.\n",
        "\n",
        "![image6](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-01.png?raw=1)\n",
        "\n",
        "Use your cursor to drag a box around the area on the chess board you want to annotate. A box will appear in which you can enter the label to add. In the example below, we will add boxes around cells, and assign the corresponding class:\n",
        "\n",
        "![image7](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-15.png?raw=1)\n",
        "\n",
        "You can also label [object detection] datasets with polygons, which are shapes with multiple points drawn around an object. Using [polygons to label for object detection](https://blog.roboflow.com/polygon-vs-bounding-box-computer-vision-annotation/) may result in a small boost in model performance.\n",
        "\n",
        "Polygons are essential for `instance segmentation` projects where you want to identify the exact location, to the pixel, of an object in an image. Roboflow offers a few tools to help with labeling with polygons. You can manually label polygons using the [Polygon annotation tool](https://blog.roboflow.com/polygon-annotation-labeling/) or you can use [Smart Polygon](https://blog.roboflow.com/automated-polygon-labeling-computer-vision/) to label objects with one click.\n",
        "\n",
        "To enable Smart Polygon, click the cursor with sparkles icon in the right sidebar, above the magic wand icon. A window will pop up that asks what version of Smart Polygon you want to enable. Click \"Enhanced\".\n",
        "\n",
        "\n",
        "\n",
        "![image9](https://blog.roboflow.com/content/images/2024/02/Screenshot-2024-02-12-at-10.18.39.png)\n",
        "\n",
        "When Smart Polygon has loaded, you can point and click anywhere on an image to create a label. When you hover over an object, a red mask will appear that lets you see what region of the object Smart Polygon will label if you click.\n",
        "\n",
        "\n",
        "![image8](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-27.png?raw=1)\n",
        "\n",
        "\n",
        "We can move the polygone and clear it.\n",
        "\n",
        "\n",
        "### Annotation Comments and History\n",
        "\n",
        "Need help from a team member on an annotation? Want to leave yourself a note for later on a particular image? We have you covered. Click the speech bubble icon on the sidebar of the annotation tool. Then, click the place on the image you want to leave a comment.\n",
        "\n",
        "f you have multiple people working with you on a project, you can tag them by using the @ sign, followed by their name. They will get a notification that you have commented and requested their assistance.\n",
        "\n",
        "We can see the history of our annotated image in the sidebar:\n",
        "\n",
        "To view a project at a previous point in the history, hover over the state in history that you want to preview.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 6. Add Images to Dataset\n",
        "Once you have annotated your image, you need to add it into your dataset for use in training a model. To do so, exit out of the annotation tool and click \"Annotate\" in the sidebar. Then, click on the card in the \"Annotating\" section that shows there is one annotated image for review.\n",
        "\n",
        "Next, click \"Add Images to Dataset\" to add your image to the dataset:\n",
        "\n",
        "![image9](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-33.png?raw=1)\n",
        "\n",
        "![image10](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_12-34.png?raw=1)\n",
        "\n",
        "You can search the images in your dataset by clicking \"Dataset\" in the sidebar. The search bar runs a [semantic search on your dataset](https://blog.roboflow.com/dataset-search/) to find images related to your query. For example, if we had images with blood, leucocytes, cells, and blastocytes, we could search through them with ease.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 7. Preprocessing and Augmentations\n",
        "After you're done annotating and have added your annotated image to your dataset, continue to [generate a new version of your dataset](https://youtu.be/O-ZPxTpb2Yg?t=287&ref=blog.roboflow.com). This creates a point-in-time snapshot of your images processed in a particular way (think of it a bit like version control for data).\n",
        "\n",
        "\n",
        "\n",
        "![imag11](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_13-09.png?raw=1)\n",
        "\n",
        "\n",
        "![imag12](https://github.com/JuanZapa7a/covid-19/blob/master/2024-04-10_13-13.png?raw=1)\n",
        "\n",
        "From here, we can apply any [preprocessing](https://docs.roboflow.com/image-transformations/image-preprocessing?ref=blog.roboflow.com) and [augmentation](https://docs.roboflow.com/image-transformations/image-augmentation?ref=blog.roboflow.com) steps that we want to our images. Roboflow seamlessly makes sure all of your annotations correctly bound each of your labeled objects -- even if you resize, rotate, or crop.\n",
        "\n",
        "> By default, Roboflow opts you into two preprocessing steps: auto-orient and resize. Auto-orient assures your images are stored on disk the same way your applications open them for you. Resize creates a consistent size for your images, in this case smaller, to expedite training.\n",
        "\n",
        "You can also choose to augment your images which generates multiple variations of each source image to help your model generalize better.\n",
        "\n",
        "Roboflow supports auto-orient corrections, resizing, grayscaling, contrast adjustments, random flips, random 90-degree rotations, random 0 to N-degree rotations, random brightness modifications, Gaussian blurring, random shearing, random cropping, random noise, and much more. To better understand these options, refer to our [documentation](https://docs.roboflow.com/?ref=blog.roboflow.com).\n",
        "\n",
        "> We recommend starting with one or two augmentations that may work with a dataset, and adding more further down the line if necessary. Adding more augmentations does not necessarily boost the performance of your model.\n",
        "\n",
        "Roboflow recommend applying no augmentations on your first model training job. This is so that you can understand how your model performs without augmentations. If your model performs poorly without augmentations, it is likely you need to revisit your dataset to ask questions like: Are all my images labeled? Are my images consistently labeled? Do my images contain a balance of the classes I want to identify?\n",
        "\n",
        "With that said, we have done some experimentation so you can achieve the best performance without tinkering with augmentation for this cell dataset.\n",
        "\n",
        "For this project, we are going to apply two augmentations: Flip and Rotate.\n",
        "\n",
        "We recommend these augmentations for our cell dataset since cells can appear at any angle and we want to identify a cell no matter how it is positioned.\n",
        "\n",
        "\n",
        "Figura\n",
        "\n",
        "\n",
        "With that said, these augmentations may not work for your data. If you are identifying an object that will only appear at one orientation (such as might be the case on an assembly line), a flip augmentation will not help as much as others.\n",
        "\n",
        "To learn more about applying augmentations, refer to our [image augmentation and preprocessing guide](https://blog.roboflow.com/why-preprocess-augment/).\n",
        "\n",
        "To generate your dataset, click the \"Create\" button at the bottom of the page.\n",
        "\n",
        "It will take a few moments for your dataset to be ready. Then, you can use it to start training a model.\n",
        "\n",
        "## Prepare Data for Training\n",
        "\n",
        "Once you have generated your dataset, you can use it to train a model on the Roboflow platform.\n",
        "\n",
        "[Roboflow Train](https://blog.roboflow.com/new-and-improved-roboflow-train/) offers model types that you can train and host using Roboflow. We handle the GPU costs and also give you access to out-of-the-box optimized [deployment](https://docs.roboflow.com/inference?ref=blog.roboflow.com) options which we will cover later in this guide.\n",
        "\n",
        "Your trained model can now be used in a few powerful ways:\n",
        "\n",
        "- [Model-assisted labeling](https://blog.roboflow.com/announcing-label-assist/) speeds up labeling and annotation for adding more data into your dataset\n",
        "- Rapid prototyping or testing your model on real-world data to test model performance (explained in the next section)\n",
        "- Deploying to production with out-of-the-box options that are optimized for your model to run on multiple different devices (explained in the next section)\n",
        "\n",
        "You can also export your dataset for use in training a model on your own hardware. To export your data, click \"Export Dataset\" and select your desired export format.\n",
        "\n",
        "> If you train a model model on your own hardware, you may be able to upload it to Roboflow for deployment. Read our Upload Model Weights guide for more information.\n",
        "\n",
        "For this guide, let's train a model on the Roboflow platform.\n",
        "\n",
        "Figura\n",
        "\n",
        "\n",
        "To get started, click the \"Train with Roboflow\" button. A window will appear where you can configure your model training job.\n",
        "\n",
        "Figura\n",
        "\n",
        "First, you will be asked to choose which model to train. Each model has performance tradeoffs that you'll want to test for your unique use case.\n",
        "\n",
        "For this guide, choose \"Fast\". You will then be asked to choose from what checkpoint you want to train.\n",
        "\n",
        "Figura\n",
        "\n",
        "\n",
        "For the first version of a new model, we recommend training from the MS COCO checkpoint. This uses a model trained on the Microsoft COCO dataset as a \"checkpoint\" from which your model will start training. This should lead to the best performance you can achieve in your first model training job.\n",
        "\n",
        "When you have trained a version of a model, you can train using your last model as a checkpoint. This is ideal if you have trained a model that performs well that you are looking to improve. You can also use [models you have starred from Universe](https://blog.roboflow.com/launch-universe-model-checkpoint/) as a checkpoint.\n",
        "\n",
        "Click \"Start Training\" to start training your model.\n",
        "\n",
        "This will take between a few minutes and a day depending on how many images are in your dataset. Because our screw dataset contains less than a dozen images, we can expect the training process will not take too long.\n",
        "\n",
        "When you start training your model, an estimate will appear that shows roughly how long we think it will take for your model to train. You will see the message \"Training machine starting...\" while your model training job is allocated to a server. This may take a few moments.\n",
        "\n",
        "\n",
        "Figure\n",
        "\n",
        "\n",
        "When a machine has been assigned your dataset from which to train a model, a graph will appear on the page. This graph shows how your model is learning in real-time. As your model trains, the numbers may jump up and down. Over the long term, the lines should reach higher points on the chart.\n",
        "\n",
        "\n",
        "The higher the mean average precision (mAP) is, the better.\n",
        "\n",
        "💡\n",
        "> Precision is a measure of, \"when your model guesses how often does it guess correctly?\" Recall is a measure of \"has your model guessed every time that it should have guessed?\" Consider an image that has 10 red blood cells. A model that finds only one of these ten but correctly labels is as \"RBC\" has perfect precision (as every guess it makes – one – is correct) but imperfect recall (only one of ten RBC cells has been found).\n",
        "\n",
        "The mAP, precision, and recall statistics tell us about the performance of our model. You can learn more about what these statistics tell you in our guide to [mAP, precision, and recall](https://blog.roboflow.com/mean-average-precision/).\n",
        "\n",
        "You'll receive an email once your model has finished training. The email contains the training results for you to see how the model performed. If you need to improve performance, [we have recommendations](https://blog.roboflow.com/improve-computer-vision-model/) on how to do that.\n",
        "\n",
        "\n",
        "Figure\n",
        "\n",
        "\n",
        "[View your training graphs](https://youtu.be/O-ZPxTpb2Yg?t=810&ref=blog.roboflow.com) for a more detailed view of model performance.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMFLYwmlvoSNr1fxnOQwlJO",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
