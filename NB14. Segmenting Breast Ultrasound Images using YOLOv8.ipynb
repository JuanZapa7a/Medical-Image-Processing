{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FYrUe-AtjBZC"
      },
      "outputs": [],
      "source": [
        "%pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "4TES2xHFjBZD",
        "outputId": "021a3327-1300-466f-ec8f-946300d31518"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b25028b5-5704-431f-bed0-95ad8e42df68\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b25028b5-5704-431f-bed0-95ad8e42df68\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdmrN8FNjBZD",
        "outputId": "0ec33a24-cfd0-4717-d7e1-a6f3aa131ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 72\n",
            "drwx------ 1 root root 4096 Jul 24 07:03 .\n",
            "drwxr-xr-x 1 root root 4096 Jul 24 07:01 ..\n",
            "-r-xr-xr-x 1 root root 1169 Jan  1  2000 .bashrc\n",
            "drwxr-xr-x 1 root root 4096 Jul 22 13:40 .cache\n",
            "drwxr-xr-x 3 root root 4096 Jul 22 13:40 .config\n",
            "drwxr-xr-x 5 root root 4096 Jul 22 13:40 .ipython\n",
            "drwx------ 1 root root 4096 Jul 22 13:40 .jupyter\n",
            "drwxr-xr-x 2 root root 4096 Jul 24 07:03 .kaggle\n",
            "drwxr-xr-x 2 root root 4096 Jul 24 07:02 .keras\n",
            "drwx------ 3 root root 4096 Jul 22 13:14 .launchpadlib\n",
            "drwxr-xr-x 1 root root 4096 Jul 22 13:40 .local\n",
            "drwxr-xr-x 4 root root 4096 Jul 22 13:40 .npm\n",
            "-rw-r--r-- 1 root root  161 Jul  9  2019 .profile\n",
            "-r-xr-xr-x 1 root root  254 Jan  1  2000 .tmux.conf\n",
            "-rw-r--r-- 1 root root  211 Jul 22 13:40 .wget-hsts\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p ~/.kaggle\n",
        "%cp ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls -al ~"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf9WQIsHjg6g",
        "outputId": "f3273fa0-2a9f-458f-ee67-f88285a17423"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                         title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "----------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "rabieelkharoua/students-performance-dataset                 📚 Students Performance Dataset 📚                     66KB  2024-06-12 23:09:20          19900        438  1.0              \n",
            "nelgiriyewithana/most-streamed-spotify-songs-2024           Most Streamed Spotify Songs 2024                    496KB  2024-06-15 18:50:51          14856        316  1.0              \n",
            "ihelon/coffee-sales                                         Coffee Sales                                         11KB  2024-07-18 10:06:43           5940         98  1.0              \n",
            "abdullahshf/neet-ug-2024-results-all-india                  NEET UG 2024 Results - All India                     12MB  2024-07-21 16:30:14            524         26  1.0              \n",
            "priyamchoksi/100000-diabetes-clinical-dataset               Comprehensive Diabetes Clinical Dataset(100k rows)  896KB  2024-07-20 15:11:02            541         23  1.0              \n",
            "humairmunir/lung-cancer-risk-dataset                        Lung Cancer Dataset                                  21KB  2024-07-17 14:25:57            795         28  1.0              \n",
            "adarshde/electric-vehicle-population-dataset                Electric Vehicle Population DataSet                   6MB  2024-07-17 17:17:38           1619         32  1.0              \n",
            "priyamchoksi/adult-census-income-dataset                    Adult Census Income Dataset                         450KB  2024-07-07 17:01:37            697         30  1.0              \n",
            "fahmidachowdhury/e-commerce-sales-analysis                  📈 E-Commerce Sales Analysis                          35KB  2024-07-04 20:02:23           2820         51  0.9411765        \n",
            "utsavdey1410/food-nutrition-dataset                         Food Nutrition Dataset                              694KB  2024-06-29 19:42:01           3390         88  1.0              \n",
            "ivansher/nasa-nearest-earth-objects-1910-2024               NASA | Nearest Earth Objects (1910-2024)             13MB  2024-07-18 13:17:11            777         28  1.0              \n",
            "dataanalyst001/world-population-growth-rate-by-cities-2024  World population growth rate by cities 2024          16KB  2024-07-07 09:04:40            423         17  1.0              \n",
            "adityabhaumik/ipl-2024-matches                              IPL 2024 Matches                                      3KB  2024-07-10 18:18:03            752         22  1.0              \n",
            "suchintikasarkar/sentiment-analysis-for-mental-health       Sentiment Analysis for Mental Health                 11MB  2024-07-05 13:58:31           1472         44  1.0              \n",
            "dataanalyst001/world-literacy-rate-by-country               World Literacy Rate by Country                        2KB  2024-07-15 08:28:28           1038         24  1.0              \n",
            "preethamgouda/campaign-data                                 campaign_data                                         3MB  2024-07-19 07:34:22            321         31  1.0              \n",
            "stacknishant/nse-stock-historical-price-data                NSE Stock Historical price data                      20MB  2024-07-11 10:58:10           1509         29  1.0              \n",
            "zahrayazdani81/carsdataset                                  CarsDataset                                           4KB  2024-07-01 16:25:36           1315         22  0.7058824        \n",
            "krishd123/uefa-euro-2024-records                            ⚽UEFA Euro 2024 Records🏆                              5KB  2024-07-17 04:33:13            596         28  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                       Melbourne Housing Snapshot                          451KB  2018-06-05 12:52:24         152665       1505  0.7058824        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list -s \"breast\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0DosuVpjpLF",
        "outputId": "8c2aef8c-394b-4c50-bb84-3dfa66bc2f7a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                              title                                           size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "---------------------------------------------------------------  ---------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "reihanenamdari/breast-cancer                                     Breast Cancer                                   43KB  2022-08-08 19:25:55          21458        277  1.0              \n",
            "yasserh/breast-cancer-dataset                                    Breast Cancer Dataset                           49KB  2021-12-29 19:07:20          58152        441  1.0              \n",
            "paultimothymooney/breast-histopathology-images                   Breast Histopathology Images                     3GB  2017-12-19 05:46:40          64452        997  0.75             \n",
            "imtkaggleteam/breast-cancer                                      Breast Cancer                                   49KB  2023-10-21 19:19:28           2121         98  1.0              \n",
            "nancyalaswad90/breast-cancer-dataset                             Breast Cancer Dataset                           49KB  2022-06-17 12:33:29          12343        213  0.9411765        \n",
            "aryashah2k/breast-ultrasound-images-dataset                      Breast Ultrasound Images Dataset               195MB  2021-03-14 04:29:54          31514        333  1.0              \n",
            "uciml/breast-cancer-wisconsin-data                               Breast Cancer Wisconsin (Diagnostic) Data Set   49KB  2016-09-25 10:49:04         375001       3558  0.85294116       \n",
            "piotrgrabo/breastcancerproteomes                                 Breast Cancer Proteomes                          5MB  2019-11-14 05:15:12          14735        365  0.64705884       \n",
            "merishnasuwal/breast-cancer-prediction-dataset                   Breast Cancer Prediction Dataset                 8KB  2018-09-26 12:41:51          30963        272  0.8235294        \n",
            "marshuu/breast-cancer                                            Breast cancer (cleaned)                          3KB  2023-01-08 09:22:50           4103         58  1.0              \n",
            "utkarshx27/breast-cancer-dataset-used-royston-and-altman         Breast Cancer Dataset                           10KB  2023-05-09 10:42:51           2549         54  1.0              \n",
            "vijayaadithyanvg/breast-cancer-prediction                        Breast Cancer Prediction                        49KB  2022-09-22 09:57:09           3000         54  0.9705882        \n",
            "faysalmiah1721758/breast-cancer-data                             Breast Cancer Dataset                            2KB  2023-08-14 06:01:43           1595         48  1.0              \n",
            "amandam1/breastcancerdataset                                     Real Breast Cancer Data                         11KB  2021-08-05 17:58:17           8271        101  1.0              \n",
            "simjeg/lymphoma-subtype-classification-fl-vs-cll                 Breast Histology Images                         33MB  2017-05-13 09:14:28           6017         65  0.75             \n",
            "krupadharamshi/breast-cancer-dataset                             Breast Cancer Dataset                           49KB  2024-06-16 06:59:35           1043         29  1.0              \n",
            "fatemehmehrparvar/breast-cancer-prediction                       Breast Cancer Prediction                         2KB  2024-01-16 16:23:39           1231         56  0.7647059        \n",
            "adhamelkomy/breast-cancer                                        Breast Cancer                                   49KB  2024-03-01 20:13:17            927         30  0.7058824        \n",
            "vuppalaadithyasairam/ultrasound-breast-images-for-breast-cancer  Ultrasound Breast Images for Breast Cancer     564MB  2022-11-03 05:51:50           2195         50  0.75             \n",
            "brunogrisci/breast-cancer-gene-expression-cumida                 Breast cancer gene expression - CuMiDa          62MB  2020-02-01 10:51:48           3910         81  0.9705882        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d aryashah2k/breast-ultrasound-images-dataset --unzip --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP2hIoggkgr1",
        "outputId": "6175931e-8235-4527-f978-ffb2fbd220bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/aryashah2k/breast-ultrasound-images-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading breast-ultrasound-images-dataset.zip to /content\n",
            " 92% 179M/195M [00:01<00:00, 144MB/s]\n",
            "100% 195M/195M [00:01<00:00, 150MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pip Tree globally\n",
        "\n",
        "!sudo apt install tree -q\n",
        "\n",
        "\n",
        "!tree --dirsfirst -L 1  \"Dataset_BUSI_with_GT\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYz1hbbOkpPZ",
        "outputId": "1f08830d-b74e-4a49-afb3-f190e7df284b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "tree is already the newest version (2.0.2-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "\u001b[01;34mDataset_BUSI_with_GT\u001b[0m\n",
            "├── \u001b[01;34mbenign\u001b[0m\n",
            "├── \u001b[01;34mmalignant\u001b[0m\n",
            "└── \u001b[01;34mnormal\u001b[0m\n",
            "\n",
            "3 directories, 0 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pip Tree globally\n",
        "\n",
        "!sudo apt install tree -q\n",
        "\n",
        "\n",
        "!tree --dirsfirst -L 2  \"Dataset_BUSI_with_GT\"| head -n 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4341386b-94fe-4bf9-d250-ef355650b7ad",
        "id": "50dS2-Kjs1jM"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "tree is already the newest version (2.0.2-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Dataset_BUSI_with_GT\n",
            "├── benign\n",
            "│   ├── benign (100)_mask_1.png\n",
            "│   ├── benign (100)_mask.png\n",
            "│   ├── benign (100).png\n",
            "│   ├── benign (101)_mask.png\n",
            "│   ├── benign (101).png\n",
            "│   ├── benign (102)_mask.png\n",
            "│   ├── benign (102).png\n",
            "│   ├── benign (103)_mask.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the paths\n",
        "original_dataset_dir = 'Dataset_BUSI_with_GT'\n",
        "base_dir = 'BreastUltraSoundImages'\n",
        "\n",
        "# Define new paths for train, val, and test\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Create directories if they do not exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# List the classes\n",
        "classes = ['benign', 'malignant', 'normal']\n",
        "\n",
        "# Function to copy images\n",
        "def copy_images(class_name, src_dir, train_dst, val_dst, test_dst, train_ratio=0.7, val_ratio=0.15):\n",
        "    # List all images in the class\n",
        "    images = os.listdir(src_dir)\n",
        "    images = [os.path.join(src_dir, img) for img in images]\n",
        "\n",
        "    # Split into train, val, and test\n",
        "    train_images, temp_images = train_test_split(images, train_size=train_ratio, random_state=42)\n",
        "    val_images, test_images = train_test_split(temp_images, test_size=val_ratio/(val_ratio + (1 - train_ratio)), random_state=42)\n",
        "\n",
        "    # Create class directories in train, val, and test\n",
        "    train_class_dir = os.path.join(train_dst, class_name)\n",
        "    val_class_dir = os.path.join(val_dst, class_name)\n",
        "    test_class_dir = os.path.join(test_dst, class_name)\n",
        "\n",
        "    # Create directories if they do not exist\n",
        "    os.makedirs(train_class_dir, exist_ok=True)\n",
        "    os.makedirs(val_class_dir, exist_ok=True)\n",
        "    os.makedirs(test_class_dir, exist_ok=True)\n",
        "\n",
        "    # Copy images\n",
        "    for img in train_images:\n",
        "        shutil.copy(img, train_class_dir)\n",
        "\n",
        "    for img in val_images:\n",
        "        shutil.copy(img, val_class_dir)\n",
        "\n",
        "    for img in test_images:\n",
        "        shutil.copy(img, test_class_dir)\n",
        "\n",
        "    # Return one image from train, val, and test for display\n",
        "    return train_images[0], val_images[0], test_images[0]\n",
        "\n",
        "# Dictionaries to store image paths for each class\n",
        "train_sample_images = {}\n",
        "val_sample_images = {}\n",
        "test_sample_images = {}\n",
        "\n",
        "# Copy images for each class and get a sample image from each class\n",
        "for class_name in classes:\n",
        "    src_dir = os.path.join(original_dataset_dir, class_name)\n",
        "    train_img, val_img, test_img = copy_images(class_name, src_dir, train_dir, val_dir, test_dir)\n",
        "    train_sample_images[class_name] = train_img\n",
        "    val_sample_images[class_name] = val_img\n",
        "    test_sample_images[class_name] = test_img\n",
        "\n",
        "print(\"Dataset reorganized successfully\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jPKQjO5s6KD",
        "outputId": "d3adfc7f-7c3e-44a8-b714-c9fedbfe22fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset reorganized successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"BreastUltraSoundImages\""
      ],
      "metadata": {
        "id": "x4Q1L8Aqzlx7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the paths\n",
        "original_dataset_dir = 'Dataset_BUSI_with_GT'\n",
        "base_dir = 'BreastUltraSoundImages'\n",
        "\n",
        "# Define new paths for train, val, and test\n",
        "image_dir = os.path.join(base_dir, 'images')\n",
        "label_dir = os.path.join(base_dir, 'labels')\n",
        "train_image_dir = os.path.join(image_dir, 'train')\n",
        "val_image_dir = os.path.join(image_dir, 'val')\n",
        "test_image_dir = os.path.join(image_dir, 'test')\n",
        "train_label_dir = os.path.join(label_dir, 'train')\n",
        "val_label_dir = os.path.join(label_dir, 'val')\n",
        "test_label_dir = os.path.join(label_dir, 'test')\n",
        "\n",
        "# Create directories if they do not exist\n",
        "os.makedirs(train_image_dir, exist_ok=True)\n",
        "os.makedirs(val_image_dir, exist_ok=True)\n",
        "os.makedirs(test_image_dir, exist_ok=True)\n",
        "os.makedirs(train_label_dir, exist_ok=True)\n",
        "os.makedirs(val_label_dir, exist_ok=True)\n",
        "os.makedirs(test_label_dir, exist_ok=True)\n",
        "\n",
        "# List the classes\n",
        "classes = ['benign', 'malignant', 'normal']\n",
        "\n",
        "# Function to copy images and corresponding labels\n",
        "def copy_images_and_labels(class_name, src_image_dir, src_label_dir, train_image_dst, val_image_dst, test_image_dst,\n",
        "                           train_label_dst, val_label_dst, test_label_dst, train_ratio=0.7, val_ratio=0.15):\n",
        "    # List all images in the class\n",
        "    images = os.listdir(src_image_dir)\n",
        "    images = [img for img in images if img.endswith('.png')]  # Adjust the extension if needed\n",
        "    image_paths = [os.path.join(src_image_dir, img) for img in images]\n",
        "    label_paths = [os.path.join(src_label_dir, img.replace('.png', '_mask.png')) for img in images]  # Adjust the mask naming convention\n",
        "\n",
        "    # Split into train, val, and test\n",
        "    train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
        "        image_paths, label_paths, train_size=train_ratio, random_state=42)\n",
        "    val_images, test_images, val_labels, test_labels = train_test_split(\n",
        "        temp_images, temp_labels, test_size=val_ratio / (val_ratio + (1 - train_ratio)), random_state=42)\n",
        "\n",
        "    # Create class directories in train, val, and test\n",
        "    train_image_class_dir = os.path.join(train_image_dst, class_name)\n",
        "    val_image_class_dir = os.path.join(val_image_dst, class_name)\n",
        "    test_image_class_dir = os.path.join(test_image_dst, class_name)\n",
        "    train_label_class_dir = os.path.join(train_label_dst, class_name)\n",
        "    val_label_class_dir = os.path.join(val_label_dst, class_name)\n",
        "    test_label_class_dir = os.path.join(test_label_dst, class_name)\n",
        "\n",
        "    # Create directories if they do not exist\n",
        "    os.makedirs(train_image_class_dir, exist_ok=True)\n",
        "    os.makedirs(val_image_class_dir, exist_ok=True)\n",
        "    os.makedirs(test_image_class_dir, exist_ok=True)\n",
        "    os.makedirs(train_label_class_dir, exist_ok=True)\n",
        "    os.makedirs(val_label_class_dir, exist_ok=True)\n",
        "    os.makedirs(test_label_class_dir, exist_ok=True)\n",
        "\n",
        "    # Copy images and labels\n",
        "    for img, label in zip(train_images, train_labels):\n",
        "        if os.path.exists(label):  # Ensure the label file exists before copying\n",
        "            shutil.copy(img, train_image_class_dir)\n",
        "            shutil.copy(label, train_label_class_dir)\n",
        "\n",
        "    for img, label in zip(val_images, val_labels):\n",
        "        if os.path.exists(label):  # Ensure the label file exists before copying\n",
        "            shutil.copy(img, val_image_class_dir)\n",
        "            shutil.copy(label, val_label_class_dir)\n",
        "\n",
        "    for img, label in zip(test_images, test_labels):\n",
        "        if os.path.exists(label):  # Ensure the label file exists before copying\n",
        "            shutil.copy(img, test_image_class_dir)\n",
        "            shutil.copy(label, test_label_class_dir)\n",
        "\n",
        "# Copy images and labels for each class\n",
        "for class_name in classes:\n",
        "    src_image_dir = os.path.join(original_dataset_dir, class_name)\n",
        "    src_label_dir = os.path.join(original_dataset_dir, class_name)  # Adjust if masks are in a different directory\n",
        "    copy_images_and_labels(class_name, src_image_dir, src_label_dir, train_image_dir, val_image_dir, test_image_dir,\n",
        "                           train_label_dir, val_label_dir, test_label_dir)\n",
        "\n",
        "print(\"Dataset reorganized successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtJHJu0d0iOv",
        "outputId": "ceceb1f8-da86-4945-bc43-98669fdd36ac"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset reorganized successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Define the paths\n",
        "base_dir = 'BreastUltraSoundImages'\n",
        "image_dir = os.path.join(base_dir, 'images')\n",
        "label_dir = os.path.join(base_dir, 'labels')\n",
        "\n",
        "# List the classes and assign them IDs\n",
        "classes = ['benign', 'malignant', 'normal']\n",
        "class_id_mapping = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "\n",
        "# Function to convert bounding box to YOLO format\n",
        "def convert_to_yolo_format(size, box):\n",
        "    dw = 1. / size[0]\n",
        "    dh = 1. / size[1]\n",
        "    x_center = (box[0] + box[1]) / 2.0\n",
        "    y_center = (box[2] + box[3]) / 2.0\n",
        "    width = box[1] - box[0]\n",
        "    height = box[3] - box[2]\n",
        "    x_center *= dw\n",
        "    width *= dw\n",
        "    y_center *= dh\n",
        "    height *= dh\n",
        "    return (x_center, y_center, width, height)\n",
        "\n",
        "# Function to create annotation files for YOLO\n",
        "def create_yolo_annotations(class_name, src_label_dir, img_dir):\n",
        "    label_files = [f for f in os.listdir(src_label_dir) if f.endswith('_mask.png')]\n",
        "    class_id = class_id_mapping[class_name]\n",
        "\n",
        "    for label_file in label_files:\n",
        "        image_file = label_file.replace('_mask.png', '.png')\n",
        "        img_path = os.path.join(img_dir, image_file)\n",
        "        label_path = os.path.join(src_label_dir, label_file)\n",
        "\n",
        "        # Check if the image file exists\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"Warning: Image file {img_path} not found.\")\n",
        "            continue\n",
        "\n",
        "        # Load the mask and find contours\n",
        "        mask = cv2.imread(label_path, 0)\n",
        "        if mask is None:\n",
        "            print(f\"Warning: Mask file {label_path} not found or could not be loaded.\")\n",
        "            continue\n",
        "\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Load the image to get its dimensions\n",
        "        img = Image.open(img_path)\n",
        "        w, h = img.size\n",
        "\n",
        "        # Create annotation file for YOLO\n",
        "        yolo_annotation = []\n",
        "        if contours:\n",
        "            for contour in contours:\n",
        "                x, y, w_box, h_box = cv2.boundingRect(contour)\n",
        "                box = (x, x+w_box, y, y+h_box)\n",
        "                yolo_box = convert_to_yolo_format((w, h), box)\n",
        "                yolo_annotation.append(f\"{class_id} {' '.join(map(str, yolo_box))}\\n\")\n",
        "        else:\n",
        "            # If there are no contours, create an empty annotation file\n",
        "            yolo_annotation.append(\"\")\n",
        "\n",
        "        # Write annotations to file in the same directory as the mask\n",
        "        annotation_file = label_path.replace('_mask.png', '.txt')\n",
        "        with open(annotation_file, 'w') as f:\n",
        "            f.writelines(yolo_annotation)\n",
        "        #print(f\"Created annotation file: {annotation_file}\")\n",
        "\n",
        "        # Remove the mask file after creating the annotation\n",
        "        os.remove(label_path)\n",
        "        #print(f\"Removed mask file: {label_path}\")\n",
        "\n",
        "# Process each class and its subdirectories\n",
        "for class_name in classes:\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        src_label_dir = os.path.join(label_dir, split, class_name)\n",
        "        img_dir = os.path.join(image_dir, split, class_name)\n",
        "\n",
        "        if os.path.exists(src_label_dir) and os.path.exists(img_dir):\n",
        "            create_yolo_annotations(class_name, src_label_dir, img_dir)\n",
        "        else:\n",
        "            if not os.path.exists(src_label_dir):\n",
        "                print(f\"Label directory for class {class_name} in {split} not found: {src_label_dir}\")\n",
        "            if not os.path.exists(img_dir):\n",
        "                print(f\"Image directory for class {class_name} in {split} not found: {img_dir}\")\n",
        "\n",
        "print(\"Annotations creation process completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KfXUhtZDmSF",
        "outputId": "5f3f2dc2-c33e-498d-874e-9c303740a798"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotations creation process completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the paths\n",
        "base_dir = 'BreastUltraSoundImages'\n",
        "image_dir = os.path.join(base_dir, 'images')\n",
        "label_dir = os.path.join(base_dir, 'labels')\n",
        "\n",
        "# List the classes\n",
        "classes = ['benign', 'malignant', 'normal']\n",
        "splits = ['train', 'val', 'test']\n",
        "\n",
        "# Function to check for missing annotation files\n",
        "def check_annotations():\n",
        "    for split in splits:\n",
        "        for class_name in classes:\n",
        "            img_subdir = os.path.join(image_dir, split, class_name)\n",
        "            lbl_subdir = os.path.join(label_dir, split, class_name)\n",
        "\n",
        "            # Check if the image and label directories exist\n",
        "            if not os.path.exists(img_subdir):\n",
        "                print(f\"Image directory not found: {img_subdir}\")\n",
        "                continue\n",
        "            if not os.path.exists(lbl_subdir):\n",
        "                print(f\"Label directory not found: {lbl_subdir}\")\n",
        "                continue\n",
        "\n",
        "            # List all images and labels\n",
        "            image_files = [f for f in os.listdir(img_subdir) if f.endswith('.png')]\n",
        "            label_files = [f for f in os.listdir(lbl_subdir) if f.endswith('.txt')]\n",
        "\n",
        "            # Create sets of file names (excluding extensions)\n",
        "            image_files_set = {os.path.splitext(f)[0] for f in image_files}\n",
        "            label_files_set = {os.path.splitext(f)[0] for f in label_files}\n",
        "\n",
        "            # Check for missing annotation files\n",
        "            missing_labels = image_files_set - label_files_set\n",
        "            if missing_labels:\n",
        "                print(f\"Missing labels for the following images in {split}/{class_name}:\")\n",
        "                for missing in missing_labels:\n",
        "                    print(f\"  {missing}.png\")\n",
        "\n",
        "# Run the check\n",
        "check_annotations()\n"
      ],
      "metadata": {
        "id": "9S_vD5CBCIJV"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree --dirsfirst -L 4 --filelimit 10 \"BreastUltraSoundImages\""
      ],
      "metadata": {
        "id": "UzijcRFpG7Jj",
        "outputId": "275b15c0-975d-4a87-aa34-a22adbeea763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34mBreastUltraSoundImages\u001b[0m\n",
            "├── \u001b[01;34mimages\u001b[0m\n",
            "│   ├── \u001b[01;34mtest\u001b[0m\n",
            "│   │   ├── \u001b[01;34mbenign\u001b[0m  [40 entries exceeds filelimit, not opening dir]\n",
            "│   │   ├── \u001b[01;34mmalignant\u001b[0m  [28 entries exceeds filelimit, not opening dir]\n",
            "│   │   └── \u001b[01;34mnormal\u001b[0m  [13 entries exceeds filelimit, not opening dir]\n",
            "│   ├── \u001b[01;34mtrain\u001b[0m\n",
            "│   │   ├── \u001b[01;34mbenign\u001b[0m  [308 entries exceeds filelimit, not opening dir]\n",
            "│   │   ├── \u001b[01;34mmalignant\u001b[0m  [145 entries exceeds filelimit, not opening dir]\n",
            "│   │   └── \u001b[01;34mnormal\u001b[0m  [93 entries exceeds filelimit, not opening dir]\n",
            "│   └── \u001b[01;34mval\u001b[0m\n",
            "│       ├── \u001b[01;34mbenign\u001b[0m  [89 entries exceeds filelimit, not opening dir]\n",
            "│       ├── \u001b[01;34mmalignant\u001b[0m  [37 entries exceeds filelimit, not opening dir]\n",
            "│       └── \u001b[01;34mnormal\u001b[0m  [27 entries exceeds filelimit, not opening dir]\n",
            "└── \u001b[01;34mlabels\u001b[0m\n",
            "    ├── \u001b[01;34mtest\u001b[0m\n",
            "    │   ├── \u001b[01;34mbenign\u001b[0m  [40 entries exceeds filelimit, not opening dir]\n",
            "    │   ├── \u001b[01;34mmalignant\u001b[0m  [28 entries exceeds filelimit, not opening dir]\n",
            "    │   └── \u001b[01;34mnormal\u001b[0m  [13 entries exceeds filelimit, not opening dir]\n",
            "    ├── \u001b[01;34mtrain\u001b[0m\n",
            "    │   ├── \u001b[01;34mbenign\u001b[0m  [308 entries exceeds filelimit, not opening dir]\n",
            "    │   ├── \u001b[01;34mmalignant\u001b[0m  [145 entries exceeds filelimit, not opening dir]\n",
            "    │   └── \u001b[01;34mnormal\u001b[0m  [93 entries exceeds filelimit, not opening dir]\n",
            "    └── \u001b[01;34mval\u001b[0m\n",
            "        ├── \u001b[01;34mbenign\u001b[0m  [89 entries exceeds filelimit, not opening dir]\n",
            "        ├── \u001b[01;34mmalignant\u001b[0m  [37 entries exceeds filelimit, not opening dir]\n",
            "        └── \u001b[01;34mnormal\u001b[0m  [27 entries exceeds filelimit, not opening dir]\n",
            "\n",
            "26 directories, 0 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ultralytics"
      ],
      "metadata": {
        "id": "tEWBpEzZIg5p",
        "outputId": "c6b98a5c-6680-4271-cf0c-9364081e1d94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.8/824.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create yaml archive\n",
        "\n",
        "import yaml\n",
        "\n",
        "# Contenido del archivo YAML\n",
        "data = {\n",
        "    'path': '../BreastUltraSoundImages', # Path to the dataset directory\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'test': 'images/test',\n",
        "\n",
        "    'nc': 3,  # Número de clases (benign, malignant, normal)\n",
        "    'names': {\n",
        "        0: 'benign',\n",
        "        1: 'malignant',\n",
        "        2: 'normal'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Crear y escribir en el archivo blood_cell_cancer.yaml\n",
        "with open('data.yaml', 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False, allow_unicode=True)\n",
        "\n",
        "print(\"Archivo data.yaml creado exitosamente.\")"
      ],
      "metadata": {
        "id": "OpQqPgDvIsgc",
        "outputId": "3e05f81f-6a42-4b2b-84ce-3f1ffd543711",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo data.yaml creado exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Cargar el modelo YOLOv8 para segmentación\n",
        "model = YOLO('yolov8n-seg.pt')\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.train(data='data.yaml', epochs=100, imgsz=640)\n"
      ],
      "metadata": {
        "id": "yCJ_XLf8K6DQ",
        "outputId": "6b5c461b-3e05-48aa-a76c-6c80bdf1e3ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-seg.pt to 'yolov8n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.74M/6.74M [00:00<00:00, 56.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.64 🚀 Python-3.10.12 torch-2.3.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.pt, data=data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train3\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1   1004665  ultralytics.nn.modules.head.Segment          [3, 32, 64, [64, 128, 256]]   \n",
            "YOLOv8n-seg summary: 261 layers, 3,264,201 parameters, 3,264,185 gradients, 12.1 GFLOPs\n",
            "\n",
            "Transferred 381/417 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train3', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/BreastUltraSoundImages/labels/train/benign.cache... 546 images, 93 backgrounds, 0 corrupt: 100%|██████████| 546/546 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/BreastUltraSoundImages/labels/val/benign.cache... 153 images, 27 backgrounds, 0 corrupt: 100%|██████████| 153/153 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/segment/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train3\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/35 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar predicciones\n",
        "results = model.predict(source='BreastUltraSoundImages/images/test', save=True)\n"
      ],
      "metadata": {
        "id": "n3P3KW4YK9jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo\n",
        "metrics = model.val(data='data.yaml')\n",
        "print(metrics)\n"
      ],
      "metadata": {
        "id": "T9Xe7aq2LAO5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}