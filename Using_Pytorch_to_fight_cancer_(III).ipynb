{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmXRlP6T8AUZRJ6UH5auBM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanZapa7a/Medical-Image-Processing/blob/main/Using_Pytorch_to_fight_cancer_(III).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5HFbho9zRFy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Early Stopping\n",
        "\n",
        "Early stopping is a technique used in machine learning model training to halt training before the model begins to overfit the training data. This is done by monitoring a metric of interest on the validation set and stopping training when the metric ceases to improve for a certain number of consecutive epochs.\n",
        "\n",
        "You can use the Python standard library os to create a directory named \"train\" in the current directory and then save the trained models (pth) in that directory. Here's an example of how to do it:\n"
      ],
      "metadata": {
        "id": "DGh9fvxLP4Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "# Current directory\n",
        "current_dir = os.getcwd()\n",
        "print(current_dir)\n",
        "\n",
        "# Path to the \"train\" directory\n",
        "train_dir = os.path.join(current_dir, 'train')\n",
        "\n",
        "# Check if the \"train\" directory already exists\n",
        "if not os.path.exists(train_dir):\n",
        "    # Create the \"train\" directory if it doesn't exist\n",
        "    os.makedirs(train_dir)\n",
        "\n",
        "# Save the trained model in the \"train\" directory\n",
        "model_path = os.path.join(train_dir, 'myCNN.pth')\n",
        "torch.save(model.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "XSjM73nldus8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "784c8918-0a76-4ef6-f07b-d88151ddae5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Checkpoints and Early Stopping](https://machinelearningmastery.com/managing-a-pytorch-training-process-with-checkpoints-and-early-stopping/)\n",
        "\n",
        "Application checkpointing is a fault tolerance technique. In this approach, a snapshot of the state of the system is taken in case of system failure. If there is a problem, you can resume from the snapshot. The checkpoint may be used directly or as the starting point for a new run, picking up where it left off. When training deep learning models, the checkpoint captures the weights of the model. These weights can be used to make predictions as-is or as the basis for ongoing training.\n",
        "\n",
        "PyTorch does not provide any function for checkpointing but it has functions for retrieving and restoring weights of a model. So you can implement checkpointing logic with them. Let’s make a checkpoint and a resume function, which simply save weights from a model and load them back:"
      ],
      "metadata": {
        "id": "Ca1eABcNcro6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint(model, filename):\n",
        "  model_path = os.path.join(train_dir, filename)\n",
        "  torch.save(model.state_dict(), model_path)\n",
        "\n",
        "def resume(model, filename):\n",
        "  model.load_state_dict(torch.load(filename))"
      ],
      "metadata": {
        "id": "iGShmsWTdDfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "If you want to add checkpoints to the training loop, you can do it at the end of the outer for-loop, where the model validation with the test set is done.\n",
        "\n",
        "You will see a number of files created in your working directory. This code is going to checkpoint the model fro each epoch. Each of these file is a ZIP file with the pickled model weight. Nothing forbid you to checkpoint inside the inner for-loop but due to the overhead it incurs, it is not a good idea to checkpoint too frequent."
      ],
      "metadata": {
        "id": "QZUhZ7_pHIDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a instance from your model\n",
        "model = myCNN().to(device)\n",
        "\n",
        "# Load the state to your new instance\n",
        "model.load_state_dict(torch.load(\"myCNN.pth\"))\n"
      ],
      "metadata": {
        "id": "u3qZE_sHquVW",
        "outputId": "4f2abc72-dea6-42ee-bbb3-e545c3e7e375",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "loss_train_history = []\n",
        "accuracy_train_history = []\n",
        "loss_test_history = []\n",
        "accuracy_test_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  loss_train,acc_train = train(train_dataloader, model, criterion, optimizer)\n",
        "  loss_train_history.append(loss_train)\n",
        "  accuracy_train_history.append(acc_train)\n",
        "  loss_test,acc_test= test(test_dataloader, model, criterion)\n",
        "  loss_test_history.append(loss_test)\n",
        "  accuracy_test_history.append(acc_test)\n",
        "  checkpoint(model, f\"epoch-{epoch}.pth\")\n",
        "\n",
        "# save metrics in a .CSV file.\n",
        "with open('metrics_myCNN_2.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Epoch', 'Train Loss', 'Train Accuracy', 'Test Loss', 'Test Accuracy'])\n",
        "    for epoch, (train_loss, train_accuracy, test_loss, test_accuracy) in enumerate(zip(loss_train_history, accuracy_train_history, loss_test_history, accuracy_test_history)):\n",
        "        writer.writerow([epoch+1, train_loss, train_accuracy, test_loss, test_accuracy])\n",
        "\n",
        "\n",
        "print(\"Done!. Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ2ZQOQBQZj_",
        "outputId": "e6096036-a0ae-4ed4-fd17-d89c6499394b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/85 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "[1/10 epochs,  2700/ 2700 data]:  99%|█████████▉| 84/85 [00:09<00:00, 11.90it/s, Accuracy=82.3%, Training_Loss=0.382]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "[1/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  9.26it/s, Accuracy=82.3%, Training_Loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  9.43it/s, Accuracy=82.3%, Training_Loss=0.384]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00, 10.52it/s, Accuracy=82.3%, Training_Loss=0.384]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  8.79it/s, Accuracy=82.3%, Training_Loss=0.384]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:11<00:00,  7.40it/s, Accuracy=82.3%, Training_Loss=0.383]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[6/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  9.26it/s, Accuracy=82.3%, Training_Loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[7/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:14<00:00,  6.06it/s, Accuracy=82.3%, Training_Loss=0.383]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[8/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  8.38it/s, Accuracy=82.3%, Training_Loss=0.383]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[9/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  9.07it/s, Accuracy=82.3%, Training_Loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[10/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00,  9.53it/s, Accuracy=82.3%, Training_Loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Done!. Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The question is of all model which is the best one? It will be studied forward."
      ],
      "metadata": {
        "id": "qEyKRGREHpar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use a fault tolerance technique where training resumes from a particular epoch. That is, if the training loop was interrupted in the middle of epoch 3 so the last checkpoint is from epoch 2, setting start_epoch = 3 above will do.\n",
        "\n",
        "This action cannot be simulated in jupyter notebook because we cannot  halt the cell, anyway the code could be this.\n",
        "```python\n",
        "epochs = 10\n",
        "\n",
        "loss_train_history = []\n",
        "accuracy_train_history = []\n",
        "loss_val_history = []\n",
        "accuracy_val_history = []\n",
        "\n",
        "start_epoch = 0\n",
        "if start_epoch > 0:\n",
        "    resume_epoch = start_epoch - 1\n",
        "    resume(model, f\"epoch-{resume_epoch}.pth\")\n",
        "\n",
        "for epoch in range(start_epoch, epochs):\n",
        "  loss_train,acc_train = train(train_dataloader, model, criterion, optimizer)\n",
        "  loss_train_history.append(loss_train)\n",
        "  accuracy_train_history.append(acc_train)\n",
        "  loss_test,acc_test= test(test_dataloader, model, criterion)\n",
        "  loss_test_history.append(loss_test)\n",
        "  accuracy_test_history.append(acc_test)\n",
        "  checkpoint(model, f\"epoch-{epoch}.pth\")\n",
        "\n",
        "# save metrics in a .CSV file.\n",
        "with open('metrics_myCNN_3.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Epoch', 'Train Loss', 'Train Accuracy', 'Test Loss', 'Test Accuracy'])\n",
        "    for epoch, (train_loss, train_accuracy, test_loss, test_accuracy) in enumerate(zip(loss_train_history, accuracy_train_history, loss_test_history, accuracy_test_history)):\n",
        "        writer.writerow([epoch+1, train_loss, train_accuracy, test_loss, test_accuracy])\n",
        "\n",
        "print(\"Done!. Finished Training\")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "aILpbo2QI0NC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes, there are states outside of the model and you may want to checkpoint it as well. One particular example is the optimizer, which in cases like Adam, there are dynamically adjusted momentum. If you restarted your training loop, you may want to restore the momentum at the optimizer as well. It is not difficult to do. The idea is to make your `checkpoint()` function more complicated thanks to `torch.save()` and `torch.load()` function are backed by `pickle`, so you can use it with a list or dict container."
      ],
      "metadata": {
        "id": "h_BLpj5iOHDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint(model, filename):\n",
        "    torch.save({\n",
        "    'optimizer': optimizer.state_dict(),\n",
        "    'model': model.state_dict(),\n",
        "}, filename)\n",
        "\n",
        "def resume(model, filename):\n",
        "    model.load_state_dict(torch.load(filename)['model'])\n",
        "    optimizer.load_state_dict(torch.load(filename)['optimizer'])\n"
      ],
      "metadata": {
        "id": "bam1poEBOMo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "loss_train_history = []\n",
        "accuracy_train_history = []\n",
        "loss_val_history = []\n",
        "accuracy_val_history = []\n",
        "\n",
        "start_epoch = 0\n",
        "if start_epoch > 0:\n",
        "    resume_epoch = start_epoch - 1\n",
        "    resume(model, f\"epoch-{resume_epoch}.pth\")\n",
        "\n",
        "for epoch in range(start_epoch, epochs):\n",
        "  loss_train,acc_train = train(train_dataloader, model, criterion, optimizer)\n",
        "  loss_train_history.append(loss_train)\n",
        "  accuracy_train_history.append(acc_train)\n",
        "  loss_test,acc_val= test(test_dataloader, model, criterion)\n",
        "  loss_test_history.append(loss_test)\n",
        "  accuracy_test_history.append(acc_test)\n",
        "  checkpoint(model, f\"epoch-{epoch}.pth\")\n",
        "print(\"Done!. Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA1xXu56PyBr",
        "outputId": "e90c4b10-a882-4734-877a-9202400f3bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  8.74it/s, Accuracy=82.3%, Training_Loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  8.70it/s, Accuracy=82.3%, Training_Loss=0.384]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00,  9.78it/s, Accuracy=82.3%, Training_Loss=0.383]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00, 10.31it/s, Accuracy=82.3%, Training_Loss=0.383]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  9.11it/s, Accuracy=82.3%, Training_Loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Done!. Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checkpointing is not only for fault tolerance. You can also use it to keep your best model. How to define what is the best is `subjective` but considering the score from the test set is a sensible method. Let’s say to keep only the best model ever found.\n",
        "\n",
        "The variable `best_accuracy` is to keep track on the highest validation accuracy (`val_acc`) obtained so far, which is in a percentage range of 0 to 100. Whenever a higher accuracy is observed, the model is checkpointed to the file `best_model.pth`. The best model is restored after the entire training loop, via the `resume()` function which was created before.\n",
        "\n",
        "Afterward, you can make predictions with the model on unseen data. Beware that, if you’re using a different metric for checkpointing, e.g., the cross entropy loss, the better model should come with a lower cross entropy. Thus you should keep track on the lowest cross entropy obtained.\n",
        "\n",
        "\n",
        "The training loop can be modified as follows:"
      ],
      "metadata": {
        "id": "5BW8pqlyQScD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "best_accuracy = -1\n",
        "\n",
        "\n",
        "loss_train_history = []\n",
        "accuracy_train_history = []\n",
        "loss_val_history = []\n",
        "accuracy_val_history = []\n",
        "\n",
        "start_epoch = 0\n",
        "if start_epoch > 0:\n",
        "    resume_epoch = start_epoch - 1\n",
        "    resume(model, f\"epoch-{resume_epoch}.pth\")\n",
        "\n",
        "for epoch in range(start_epoch, epochs):\n",
        "  loss_train,acc_train = train(train_dataloader, model, criterion, optimizer)\n",
        "  loss_train_history.append(loss_train)\n",
        "  accuracy_train_history.append(acc_train)\n",
        "  loss_test,acc_test= test(test_dataloader, model, criterion)\n",
        "  loss_val_history.append(loss_test)\n",
        "  accuracy_val_history.append(acc_test)\n",
        "  if acc_val > best_accuracy:\n",
        "    best_accuracy = acc_val\n",
        "    checkpoint(model, f\"best_model.pth\")\n",
        "    print(f'best model in epoch:{epoch+1}')\n",
        "print(\"Done!. Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8U62vnuQ4Bh",
        "outputId": "31b0f431-f079-4ad9-eecb-a0177f0732cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00, 10.10it/s, Accuracy=82.3%, Training_Loss=0.383]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "best model in epoch:1\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00, 10.38it/s, Accuracy=82.3%, Training_Loss=0.381]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  9.35it/s, Accuracy=82.3%, Training_Loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  8.14it/s, Accuracy=82.3%, Training_Loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  9.02it/s, Accuracy=82.3%, Training_Loss=0.385]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Done!. Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8elYcuFlXhyz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also checkpoint the model per epoch unconditionally together with the best model checkpointing, as you are free to create multiple checkpoint files. Since the code above is the find the best model and make a copy of it, you may usually see a further optimization to the training loop by stopping it early if the hope to see model improvement is slim. This is the early stopping technique that can save time in training.\n",
        "\n",
        "The code above validates the model with test set at the end of each epoch and keeps the best model found into a checkpoint file. The simplest strategy for early stopping is to set up a threshold of\n",
        " epochs. If you didn’t see the model improved over the last\n",
        " epochs, you terminate the training loop in the middle. This can be implemented as follows:"
      ],
      "metadata": {
        "id": "T0SuZj_iZ1dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "early_stop_thresh = 5\n",
        "best_accuracy = -1\n",
        "best_epoch = -1\n",
        "\n",
        "\n",
        "loss_train_history = []\n",
        "accuracy_train_history = []\n",
        "loss_val_history = []\n",
        "accuracy_val_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  loss_train,acc_train = train(train_dataloader, model, criterion, optimizer)\n",
        "  loss_train_history.append(loss_train)\n",
        "  accuracy_train_history.append(acc_train)\n",
        "  loss_test,acc_test= test(test_dataloader, model, criterion)\n",
        "  loss_test_history.append(loss_test)\n",
        "  accuracy_test_history.append(acc_test)\n",
        "  if acc_val > best_accuracy:\n",
        "    best_accuracy = acc_val\n",
        "    best_epoch = epoch+1\n",
        "    checkpoint(model, f\"best_model.pth\")\n",
        "    print(f'best model in epoch={epoch+1} with Accuracy={(100*acc_val):>0.1f}%')\n",
        "  elif epoch - best_epoch >= early_stop_thresh:\n",
        "    print(f\"Early stopped training at epoch {epoch+1} due to {early_stop_thresh} epochs whitout enhacement\")\n",
        "    break  # terminate the training loop\n",
        "print(\"Done!. Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FowZLIjY-_D",
        "outputId": "87e9f54f-4eae-4b30-c2b6-e476ee35bf92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1/50 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:07<00:00, 10.76it/s, Accuracy=82.3%, Training_Loss=0.384]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "best model in epoch=1 with Accuracy=78.0%\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/50 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00,  9.72it/s, Accuracy=82.3%, Training_Loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/50 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  9.16it/s, Accuracy=82.3%, Training_Loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/50 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  8.98it/s, Accuracy=82.3%, Training_Loss=0.384]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/50 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00, 10.52it/s, Accuracy=82.3%, Training_Loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[6/50 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00,  9.84it/s, Accuracy=82.3%, Training_Loss=0.383]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[7/50 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  9.24it/s, Accuracy=82.3%, Training_Loss=0.383]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 78.0%, Test_Loss: 0.446153 \n",
            "\n",
            "Early stopped training at epoch 7 due to 5 epochs whitout enhacement\n",
            "Done!. Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.set_title('Training and Test Plots')\n",
        "ax.plot(range(7), loss_train_history, label=\"Train Loss\")\n",
        "ax.plot(range(7), accuracy_train_history, label=\"Train Accuracy\")\n",
        "ax.plot(range(15), loss_test_history, label=\"Test Loss\")\n",
        "ax.plot(range(15), accuracy_test_history, label=\"Test Accuracy\")\n",
        "ax.set_xlabel(\"Epochs\")\n",
        "ax.set_ylabel(\"Train\")\n",
        "ax.legend()\n",
        "\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "s-rFDprhy4ib",
        "outputId": "7dc78ddd-7746-4f2b-d086-4bd591336bfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (15,) and (22,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-31f72b5b0a83>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_train_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_test_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Test Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_test_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Test Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    505\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (15,) and (22,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}