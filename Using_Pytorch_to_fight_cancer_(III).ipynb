{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanZapa7a/Medical-Image-Processing/blob/main/Using_Pytorch_to_fight_cancer_(III).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z5HFbho9zRFy",
        "outputId": "01960479-3c9a-4218-cc71-529c3ef7b3da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 17 15:33:06 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "vu_A6rw500CL",
        "outputId": "bde01d93-e9e1-4baa-9683-4308ab64fb01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vxnbZ-Wu1BOd",
        "outputId": "1b3195f0-e80f-4a61-cf42-109e35c84aae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "datasets_dir = os.path.join(HOME, \"datasets\")\n",
        "os.makedirs(datasets_dir, exist_ok=True)\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "DPyP573N1Klc",
        "outputId": "e1aacf56-70bf-4f51-ed6d-0e2d516beaba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to new datsets folder\n",
        "os.chdir(datasets_dir)\n",
        "print('dataset_dir =', os.getcwd())\n",
        "if  not os.path.isfile('exp0.zip'):\n",
        "  !wget -q https://www.dropbox.com/s/7ir1jixrs1aw55n/exp0.zip\n",
        "!unzip -qq -o exp0.zip"
      ],
      "metadata": {
        "id": "bt4gIsT81Zlq",
        "outputId": "a34c7034-fd1f-4ad8-d1e7-016fa029be9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset_dir = /content/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# 1. Calculate the mean and standard deviation on the training set.\n",
        "# train, validation and test data directory\n",
        "\n",
        "train_dir = \"/content/datasets/exp0/train/\"\n",
        "val_dir  = \"/content/datasets/exp0/test/\"\n",
        "test_dir   = \"/content/datasets/exp0/val/\"\n",
        "\n",
        "# transform to calculate mean and standard desviation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()  # transform images to tensor\n",
        "])\n",
        "\n",
        "# Load the ImageFolder dataset and apply the transformation\n",
        "dataset = datasets.ImageFolder(root= train_dir, transform=transform)\n",
        "\n",
        "# it's better to use a loader to retrieve images (tensors)\n",
        "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Initialize variables to store the sum of pixel values and\n",
        "# standard deviation.\n",
        "# These variables are set to floating-point zeros to ensure\n",
        "# accurate calculations.\n",
        "mean_sum = 0.0\n",
        "std_sum = 0.0\n",
        "total_samples = 0\n",
        "\n",
        "# Iterates over the data loader (loader),\n",
        "# calculates the mean and standard deviation across all channels\n",
        "# for each batch(0) and spatial dimensions (height(2) and width(3))\n",
        "for images, _ in loader:\n",
        "    mean_sum += torch.mean(images, dim=[0, 2, 3])\n",
        "    std_sum += torch.std(images, dim=[0, 2, 3])\n",
        "    total_samples += 1\n",
        "\n",
        "mean = mean_sum / total_samples\n",
        "std = std_sum / total_samples\n",
        "\n",
        "print(\"Total train samples:\", total_samples)\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Std:\", std)"
      ],
      "metadata": {
        "id": "bcxFIoZU590E",
        "outputId": "4d46b903-b4e5-47d7-9a7d-48e29c464d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7ee8243e8433>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# for each batch(0) and spatial dimensions (height(2) and width(3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mmean_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mstd_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtotal_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Normalize the training set using these statistics.\n",
        "\n",
        "\n",
        "train_set = datasets.ImageFolder(train_dir,transform = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)])\n",
        ")\n",
        "\n",
        "# 3. Normalize the test and validation set using the same statistics\n",
        "# calculated on the training set.\n",
        "val_set = datasets.ImageFolder(val_dir,transform = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)])\n",
        ")\n",
        "\n",
        "test_set = datasets.ImageFolder(test_dir,transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)])\n",
        ")\n",
        "\n",
        "print(f\"Length of Train Data :{len(train_set)}\")\n",
        "print(f\"Length of Validation Data : {len(val_set)}\")\n",
        "print(f\"Length of Test Data : {len(test_set)}\")\n",
        "\n",
        "classes = train_set.classes\n",
        "print('Classes: ', classes)"
      ],
      "metadata": {
        "id": "ee3tpXcn61Ci",
        "outputId": "2ef90108-e80d-4aa1-d2ad-1584034f11df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of Train Data :2700\n",
            "Length of Validation Data : 600\n",
            "Length of Test Data : 300\n",
            "Classes:  ['class_0', 'class_1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, criterion, optimizer):\n",
        "  running_loss, corrects, current = 0, 0, 0\n",
        "  size = len(dataloader.dataset) # number images from dataset\n",
        "  print(f\"Training:\")\n",
        "  model.train() #training mode on\n",
        "  loop = tqdm(train_dataloader) # Initialize a progress bar\n",
        "  for batch, (X, y) in enumerate(loop):\n",
        "    # take data (X) and label (y) from a batch\n",
        "    X, y = X.to(device), y.to(device) # Move the data and labels\n",
        "                                      # to the device (CPU or GPU)\n",
        "\n",
        "    # forward pass\n",
        "    preds = model(X) # Compute predictions\n",
        "    loss = criterion(preds, y) # Compute the loss between predictions and labels\n",
        "\n",
        "    # backpropagation\n",
        "    optimizer.zero_grad()   # zero the gradient buffers\n",
        "    loss.backward()         # compute gradients to backwards\n",
        "    optimizer.step()        # Does the \"update weights\" of model\n",
        "\n",
        "    # Calculate Output Metrics training_loss, training_accuracy\n",
        "\n",
        "    # 1. loss.item() contains the loss of entire mini-batch converted to scalar\n",
        "    running_loss += loss.item() # Accumulate the loss for this batch\n",
        "\n",
        "    # 2. current image (last image in the batch) for progressive bar\n",
        "    current += len(X) # Update the current number of processed images\n",
        "\n",
        "    # 3. From the predictions, I select the index (class) of the one with\n",
        "    # the highest value and compare it with the label (class). The boolean value\n",
        "    # is converted into a float (true becomes 1, false becomes 0), and all are\n",
        "    # summed up. Finally, 'item' converts them into a scalar value.\n",
        "    # This way, 'corrects' reflects the number of correct predictions (accuracy)\n",
        "    corrects += (preds.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    # 4. running loss is the sum of our loss. Training loss is a running average\n",
        "    # through batches\n",
        "    training_loss = running_loss/(batch+1)\n",
        "\n",
        "    # 5. Training accuracy = number of corrects predictions/number of processed images\n",
        "    training_accuracy = corrects/current\n",
        "\n",
        "    # Update the progress bar with current epoch, batch, and metrics\n",
        "    loop.set_description(f'[{epoch + 1}/{epochs} epochs, {current:>5d}/{len(train_dataloader.dataset):>5d} data]')\n",
        "    loop.set_postfix(Training_Loss=training_loss, Accuracy=f'{100*corrects/current:>0.1f}%')\n",
        "\n",
        "  return training_loss, training_accuracy"
      ],
      "metadata": {
        "id": "gQKZ1_eb7MOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val(dataloader, model, criterion):\n",
        "  size = len(dataloader.dataset) # number images from dataset to evaluate\n",
        "  num_batches = len(dataloader)  # number of batches\n",
        "\n",
        "  # Evaluation (test)) Mode\n",
        "  model.eval()\n",
        "\n",
        "  val_loss, corrects = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # prediction for a dataset not used in training\n",
        "      # compute prediction error and number of corrects\n",
        "      # through batches\n",
        "      preds = model(X)\n",
        "      val_loss += criterion(preds, y).item()\n",
        "      corrects += (preds.argmax(1) == y).type(torch.float).sum().item()\n",
        "  val_loss /= num_batches\n",
        "  corrects /= size\n",
        "  print(f\"Val: \\n Accuracy: {(100*corrects):>0.1f}%, val_Loss: {val_loss:>8f} \\n\")\n",
        "\n",
        "  return val_loss, corrects"
      ],
      "metadata": {
        "id": "7EwQGti57PTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F58jmQBT7S2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "model = files.upload()"
      ],
      "metadata": {
        "id": "q2aqazpX1soX",
        "outputId": "0ccf6581-2579-4f70-92b2-6777aaf74752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c97dbebb-deb2-49bd-b4fa-5bd205953102\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c97dbebb-deb2-49bd-b4fa-5bd205953102\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving myCNN.pth to myCNN.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Early Stopping\n",
        "\n",
        "Early stopping is a technique used in machine learning model training to halt training before the model begins to overfit the training data. This is done by monitoring a metric of interest on the validation set and stopping training when the metric ceases to improve for a certain number of consecutive epochs.\n",
        "\n",
        "You can use the Python standard library os to create a directory named \"train\" in the current directory and then save the trained models (pth) in that directory. Here's an example of how to do it:\n"
      ],
      "metadata": {
        "id": "DGh9fvxLP4Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "# Current directory\n",
        "current_dir = os.getcwd()\n",
        "print(current_dir)\n",
        "\n",
        "# Path to the \"train\" directory\n",
        "train_dir = os.path.join(current_dir, 'train')\n",
        "\n",
        "# Check if the \"train\" directory already exists\n",
        "if not os.path.exists(train_dir):\n",
        "    # Create the \"train\" directory if it doesn't exist\n",
        "    os.makedirs(train_dir)\n",
        "\n",
        "# Save the trained model in the \"train\" directory\n",
        "#model_path = os.path.join(train_dir, 'myCNN.pth')\n",
        "#torch.save(model.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "XSjM73nldus8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeea0ed2-4646-4721-a17d-20cd6f946309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Large Model\n",
        "class myCNN(nn.Module):\n",
        "    def __init__(self): # defines the constructor method __init__()\n",
        "                        # for the myCNN class. This method is called\n",
        "                        # when an instance of the class is created.\n",
        "        super().__init__() # calls the constructor of the parent class\n",
        "                           # (nn.Module) using Python's super() function.\n",
        "                           # It initializes the parent class, allowing the\n",
        "                           # myCNN class to inherit functionality from nn.Module.\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "\n",
        "            # Layer 1: Conv2d\n",
        "            # Input: (batch_size, 3, 64, 64)\n",
        "            # Output: (batch_size, 32, 64, 64)\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Layer 2: Conv2d\n",
        "            # Input: (batch_size, 32, 64, 64)\n",
        "            # Output: (batch_size, 64, 64, 64)\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Layer 3: MaxPool2d\n",
        "            # Input: (batch_size, 64, 64, 64)\n",
        "            # Output: (batch_size, 64, 32, 32)\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Layer 4: Conv2d\n",
        "            # Input: (batch_size, 64, 32, 32)\n",
        "            # Output: (batch_size, 128, 32, 32)\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Layer 5: Conv2d\n",
        "            # Input: (batch_size, 128, 32, 32)\n",
        "            # Output: (batch_size, 128, 32, 32)\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Layer 6: MaxPool2d\n",
        "            # Input: (batch_size, 128, 32, 32)\n",
        "            # Output: (batch_size, 128, 16, 16)\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Layer 7: Conv2d\n",
        "            # Input: (batch_size, 128, 16, 16)\n",
        "            # Output: (batch_size, 256, 16, 16)\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Layer 8: Conv2d\n",
        "            # Input: (batch_size, 256, 16, 16)\n",
        "            # Output: (batch_size, 256, 16, 16)\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Layer 9: MaxPool2d\n",
        "            # Input: (batch_size, 256, 16, 16)\n",
        "            # Output: (batch_size, 256, 8, 8)\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Layer 10: Flatten\n",
        "            # Input: (batch_size, 256, 8, 8)\n",
        "            # Output: (batch_size, 16384)\n",
        "            nn.Flatten(),\n",
        "\n",
        "            # Layer 11: Linear\n",
        "            # Input: (batch_size, 16384)\n",
        "            # Output: (batch_size, 128)\n",
        "            nn.Linear(16384, 128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Layer 12: Linear\n",
        "            # Input: (batch_size, 128)\n",
        "            # Output: (batch_size, 64)\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Layer 13: Linear\n",
        "            # Input: (batch_size, 64)\n",
        "            # Output: (batch_size, 2)\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "    # The forward method takes a single argument xb,\n",
        "    # which represents the input data to the neural network.\n",
        "    # Inside the forward method, the input xb is passed through the\n",
        "    # neural network layers defined in self.network. The result of this\n",
        "    # computation is then returned as the output of the forward method.\n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ],
      "metadata": {
        "id": "_4cAsPmU3RIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Create a instance from your model\n",
        "model = myCNN().to(device)\n",
        "if torch.cuda.device_count() > 1:\n",
        "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
        "  model = nn.DataParallel(model)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# Load the state to your new instance\n",
        "#model.load_state_dict(torch.load(\"myCNN.pth\"))\n"
      ],
      "metadata": {
        "id": "u3qZE_sHquVW",
        "outputId": "7c218086-9701-4b5e-e01f-c805ebc761a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "myCNN(\n",
            "  (network): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU()\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU()\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU()\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU()\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Flatten(start_dim=1, end_dim=-1)\n",
            "    (16): Linear(in_features=16384, out_features=128, bias=True)\n",
            "    (17): ReLU()\n",
            "    (18): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (19): ReLU()\n",
            "    (20): Linear(in_features=64, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch size defines how many training or testing samples\n",
        "# to use in a single iteration\n",
        "batch_size = 32\n",
        "# epochs define the number of iterations\n",
        "epochs = 10\n",
        "# num_classes define the number of the class\n",
        "num_classes = len(classes)\n",
        "print(f\"Number of Classes: {num_classes}\")"
      ],
      "metadata": {
        "id": "nlxYAmAy8nBT",
        "outputId": "33d7be08-20c4-4421-8b74-baf71d95d873",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Classes: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders object for training/val loop.\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "  train_set,\n",
        "  batch_size=batch_size,\n",
        "  shuffle=True,\n",
        "  num_workers=2)\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "  val_set,\n",
        "  batch_size=batch_size,\n",
        "  shuffle=False,\n",
        "  num_workers=2)"
      ],
      "metadata": {
        "id": "xCkMxeHc8XVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "#criterion = nn.BCELoss()\n",
        "#criterion = nn.BCEWithLogitsLoss()\n",
        "# Define your optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(),\n",
        "                            lr=0.001,\n",
        "                            momentum=0.9,\n",
        "                            weight_decay=0.001 )\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "OjTqB04G89Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Checkpoints and Early Stopping](https://machinelearningmastery.com/managing-a-pytorch-training-process-with-checkpoints-and-early-stopping/)\n",
        "\n",
        "Application checkpointing is a fault tolerance technique. In this approach, a snapshot of the state of the system is taken in case of system failure. If there is a problem, you can resume from the snapshot. The checkpoint may be used directly or as the starting point for a new run, picking up where it left off. When training deep learning models, the checkpoint captures the weights of the model. These weights can be used to make predictions as-is or as the basis for ongoing training.\n",
        "\n",
        "PyTorch does not provide any function for checkpointing but it has functions for retrieving and restoring weights of a model. So you can implement checkpointing logic with them. Let’s make a checkpoint and a resume function, which simply save weights from a model and load them back:"
      ],
      "metadata": {
        "id": "Ca1eABcNcro6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def checkpoint(model, filename):\n",
        "  model_path = os.path.join(train_dir, filename)\n",
        "  torch.save(model.state_dict(), model_path)\n",
        "\n",
        "def resume(model, filename):\n",
        "  model.load_state_dict(torch.load(filename))"
      ],
      "metadata": {
        "id": "iGShmsWTdDfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "If you want to add checkpoints to the training loop, you can do it at the end of the outer for-loop, where the model validation with the test set is done.\n",
        "\n",
        "You will see a number of files created in your working directory. This code is going to checkpoint the model fro each epoch. Each of these file is a ZIP file with the pickled model weight. Nothing forbid you to checkpoint inside the inner for-loop but due to the overhead it incurs, it is not a good idea to checkpoint too frequent."
      ],
      "metadata": {
        "id": "QZUhZ7_pHIDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm # progress bar\n",
        "import csv\n",
        "\n",
        "loss_train_history = []\n",
        "accuracy_train_history = []\n",
        "loss_val_history = []\n",
        "accuracy_val_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  loss_train,acc_train = train(train_dataloader, model, criterion, optimizer)\n",
        "  loss_train_history.append(loss_train)\n",
        "  accuracy_train_history.append(acc_train)\n",
        "  loss_val,acc_val= val(val_dataloader, model, criterion)\n",
        "  loss_val_history.append(loss_val)\n",
        "  accuracy_val_history.append(acc_val)\n",
        "  checkpoint(model, f\"epoch-{epoch}.pth\")\n",
        "\n",
        "# save metrics in a .CSV file.\n",
        "with open(os.path.join(train_dir,'metrics_myCNN_2.csv'), 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Epoch', 'Train Loss', 'Train Accuracy', 'Test Loss', 'Test Accuracy'])\n",
        "    for epoch, (train_loss, train_accuracy, test_loss, test_accuracy) in enumerate(zip(loss_train_history, accuracy_train_history, loss_test_history, accuracy_test_history)):\n",
        "        writer.writerow([epoch+1, train_loss, train_accuracy, test_loss, test_accuracy])\n",
        "\n",
        "\n",
        "print(\"Done!. Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ2ZQOQBQZj_",
        "outputId": "ae3d4900-c633-43e1-d59e-7a83c3dff679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/85 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "[1/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00, 11.36it/s, Accuracy=76.0%, Training_Loss=0.463]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "[1/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  7.98it/s, Accuracy=76.0%, Training_Loss=0.463]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 75.2%, val_Loss: 0.474446 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  8.48it/s, Accuracy=75.1%, Training_Loss=0.48]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 76.8%, val_Loss: 0.464692 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00,  9.68it/s, Accuracy=75.7%, Training_Loss=0.464]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 76.0%, val_Loss: 0.462019 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  8.71it/s, Accuracy=76.2%, Training_Loss=0.46]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 77.5%, val_Loss: 0.466488 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  8.03it/s, Accuracy=76.1%, Training_Loss=0.46]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 76.8%, val_Loss: 0.464840 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[6/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  7.81it/s, Accuracy=76.4%, Training_Loss=0.458]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 77.3%, val_Loss: 0.463628 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[7/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  8.35it/s, Accuracy=76.4%, Training_Loss=0.457]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 77.5%, val_Loss: 0.461931 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[8/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00,  9.82it/s, Accuracy=76.2%, Training_Loss=0.458]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 76.3%, val_Loss: 0.458215 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[9/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  8.59it/s, Accuracy=76.6%, Training_Loss=0.458]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 75.8%, val_Loss: 0.473937 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[10/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  7.86it/s, Accuracy=76.1%, Training_Loss=0.454]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 77.7%, val_Loss: 0.458022 \n",
            "\n",
            "Done!. Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The question is of all model which is the best one? It will be studied forward."
      ],
      "metadata": {
        "id": "qEyKRGREHpar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use a fault tolerance technique where training resumes from a particular epoch. That is, if the training loop was interrupted in the middle of epoch 3 so the last checkpoint is from epoch 2, setting start_epoch = 3 above will do.\n",
        "\n",
        "This action cannot be simulated in jupyter notebook because we cannot  halt the cell, anyway the code could be this.\n",
        "```python\n",
        "epochs = 10\n",
        "\n",
        "loss_train_history = []\n",
        "accuracy_train_history = []\n",
        "loss_val_history = []\n",
        "accuracy_val_history = []\n",
        "\n",
        "start_epoch = 0\n",
        "if start_epoch > 0:\n",
        "    resume_epoch = start_epoch - 1\n",
        "    resume(model, f\"epoch-{resume_epoch}.pth\")\n",
        "\n",
        "for epoch in range(start_epoch, epochs):\n",
        "  loss_train,acc_train = train(train_dataloader, model, criterion, optimizer)\n",
        "  loss_train_history.append(loss_train)\n",
        "  accuracy_train_history.append(acc_train)\n",
        "  loss_test,acc_test= test(test_dataloader, model, criterion)\n",
        "  loss_test_history.append(loss_test)\n",
        "  accuracy_test_history.append(acc_test)\n",
        "  checkpoint(model, f\"epoch-{epoch}.pth\")\n",
        "\n",
        "# save metrics in a .CSV file.\n",
        "with open('metrics_myCNN_3.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Epoch', 'Train Loss', 'Train Accuracy', 'Test Loss', 'Test Accuracy'])\n",
        "    for epoch, (train_loss, train_accuracy, test_loss, test_accuracy) in enumerate(zip(loss_train_history, accuracy_train_history, loss_test_history, accuracy_test_history)):\n",
        "        writer.writerow([epoch+1, train_loss, train_accuracy, test_loss, test_accuracy])\n",
        "\n",
        "print(\"Done!. Finished Training\")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "aILpbo2QI0NC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes, there are states outside of the model and you may want to checkpoint it as well. One particular example is the optimizer, which in cases like Adam, there are dynamically adjusted momentum. If you restarted your training loop, you may want to restore the momentum at the optimizer as well. It is not difficult to do. The idea is to make your `checkpoint()` function more complicated thanks to `torch.save()` and `torch.load()` function are backed by `pickle`, so you can use it with a list or dict container."
      ],
      "metadata": {
        "id": "h_BLpj5iOHDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint(model, filename):\n",
        "    torch.save({\n",
        "    'optimizer': optimizer.state_dict(),\n",
        "    'model': model.state_dict(),\n",
        "}, filename)\n",
        "\n",
        "def resume(model, filename):\n",
        "    model.load_state_dict(torch.load(filename)['model'])\n",
        "    optimizer.load_state_dict(torch.load(filename)['optimizer'])\n"
      ],
      "metadata": {
        "id": "bam1poEBOMo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "loss_train_history = []\n",
        "accuracy_train_history = []\n",
        "loss_val_history = []\n",
        "accuracy_val_history = []\n",
        "\n",
        "start_epoch = 0\n",
        "if start_epoch > 0:\n",
        "    resume_epoch = start_epoch - 1\n",
        "    resume(model, f\"epoch-{resume_epoch}.pth\")\n",
        "\n",
        "for epoch in range(start_epoch, epochs):\n",
        "  loss_train,acc_train = train(train_dataloader, model, criterion, optimizer)\n",
        "  loss_train_history.append(loss_train)\n",
        "  accuracy_train_history.append(acc_train)\n",
        "  loss_val,acc_val= val(val_dataloader, model, criterion)\n",
        "  loss_val_history.append(loss_val)\n",
        "  accuracy_val_history.append(acc_val)\n",
        "  checkpoint(model, f\"epoch-{epoch}.pth\")\n",
        "print(\"Done!. Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA1xXu56PyBr",
        "outputId": "28959179-8b7f-4157-dd81-353ffbf49633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/85 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "[1/5 epochs,  2700/ 2700 data]:  98%|█████████▊| 83/85 [00:10<00:00, 10.31it/s, Accuracy=72.5%, Training_Loss=0.517]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "[1/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  8.38it/s, Accuracy=72.5%, Training_Loss=0.517]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 72.5%, val_Loss: 0.530897 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  7.85it/s, Accuracy=72.9%, Training_Loss=0.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 73.0%, val_Loss: 0.522763 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  7.83it/s, Accuracy=72.9%, Training_Loss=0.505]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 74.8%, val_Loss: 0.498030 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:11<00:00,  7.67it/s, Accuracy=73.1%, Training_Loss=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 74.8%, val_Loss: 0.492389 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00,  9.66it/s, Accuracy=73.2%, Training_Loss=0.497]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 73.8%, val_Loss: 0.513702 \n",
            "\n",
            "Done!. Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checkpointing is not only for fault tolerance. You can also use it to keep your best model. How to define what is the best is `subjective` but considering the score from the test set is a sensible method. Let’s say to keep only the best model ever found.\n",
        "\n",
        "The variable `best_accuracy` is to keep track on the highest validation accuracy (`val_acc`) obtained so far, which is in a percentage range of 0 to 100. Whenever a higher accuracy is observed, the model is checkpointed to the file `best_model.pth`. The best model is restored after the entire training loop, via the `resume()` function which was created before.\n",
        "\n",
        "Afterward, you can make predictions with the model on unseen data. Beware that, if you’re using a different metric for checkpointing, e.g., the cross entropy loss, the better model should come with a lower cross entropy. Thus you should keep track on the lowest cross entropy obtained.\n",
        "\n",
        "\n",
        "The training loop can be modified as follows:"
      ],
      "metadata": {
        "id": "5BW8pqlyQScD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "best_accuracy = -1\n",
        "\n",
        "\n",
        "loss_train_history = []\n",
        "accuracy_train_history = []\n",
        "loss_val_history = []\n",
        "accuracy_val_history = []\n",
        "\n",
        "start_epoch = 0\n",
        "if start_epoch > 0:\n",
        "    resume_epoch = start_epoch - 1\n",
        "    resume(model, f\"epoch-{resume_epoch}.pth\")\n",
        "\n",
        "for epoch in range(start_epoch, epochs):\n",
        "  loss_train,acc_train = train(train_dataloader, model, criterion, optimizer)\n",
        "  loss_train_history.append(loss_train)\n",
        "  accuracy_train_history.append(acc_train)\n",
        "  loss_val,acc_val= val(val_dataloader, model, criterion)\n",
        "  loss_val_history.append(loss_val)\n",
        "  accuracy_val_history.append(acc_val)\n",
        "  if acc_val > best_accuracy:\n",
        "    best_accuracy = acc_val\n",
        "    checkpoint(model, f\"best_model.pth\")\n",
        "    print(f'best model in epoch:{epoch+1}')\n",
        "print(\"Done!. Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8U62vnuQ4Bh",
        "outputId": "255d8e2e-5ef1-482a-8d32-534fcd0ae987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/85 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "[1/5 epochs,  2700/ 2700 data]:  99%|█████████▉| 84/85 [00:08<00:00,  7.00it/s, Accuracy=73.4%, Training_Loss=0.495]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "[1/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00,  9.67it/s, Accuracy=73.4%, Training_Loss=0.495]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 75.5%, val_Loss: 0.494090 \n",
            "\n",
            "best model in epoch:1\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00,  9.82it/s, Accuracy=73.3%, Training_Loss=0.492]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 74.5%, val_Loss: 0.484447 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  7.81it/s, Accuracy=74.2%, Training_Loss=0.489]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 76.0%, val_Loss: 0.478884 \n",
            "\n",
            "best model in epoch:3\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  8.06it/s, Accuracy=74.8%, Training_Loss=0.487]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 76.3%, val_Loss: 0.478514 \n",
            "\n",
            "best model in epoch:4\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  8.09it/s, Accuracy=74.2%, Training_Loss=0.488]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 75.2%, val_Loss: 0.484394 \n",
            "\n",
            "Done!. Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8elYcuFlXhyz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also checkpoint the model per epoch unconditionally together with the best model checkpointing, as you are free to create multiple checkpoint files. Since the code above is the find the best model and make a copy of it, you may usually see a further optimization to the training loop by stopping it early if the hope to see model improvement is slim. This is the early stopping technique that can save time in training.\n",
        "\n",
        "The code above validates the model with test set at the end of each epoch and keeps the best model found into a checkpoint file. The simplest strategy for early stopping is to set up a threshold of\n",
        " epochs. If you didn’t see the model improved over the last\n",
        " epochs, you terminate the training loop in the middle. This can be implemented as follows:"
      ],
      "metadata": {
        "id": "T0SuZj_iZ1dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "early_stop_thresh = 5\n",
        "best_accuracy = -1\n",
        "best_epoch = -1\n",
        "\n",
        "\n",
        "loss_train_history = []\n",
        "accuracy_train_history = []\n",
        "loss_val_history = []\n",
        "accuracy_val_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  loss_train,acc_train = train(train_dataloader, model, criterion, optimizer)\n",
        "  loss_train_history.append(loss_train)\n",
        "  accuracy_train_history.append(acc_train)\n",
        "  loss_test,acc_test= val(val_dataloader, model, criterion)\n",
        "  loss_val_history.append(loss_val)\n",
        "  accuracy_val_history.append(acc_val)\n",
        "  if acc_val > best_accuracy:\n",
        "    best_accuracy = acc_val\n",
        "    best_epoch = epoch+1\n",
        "    checkpoint(model, f\"best_model.pth\")\n",
        "    print(f'best model in epoch={epoch+1} with Accuracy={(100*acc_val):>0.1f}%')\n",
        "  elif epoch - best_epoch >= early_stop_thresh:\n",
        "    print(f\"Early stopped training at epoch {epoch+1} due to {early_stop_thresh} epochs whitout enhacement\")\n",
        "    break  # terminate the training loop\n",
        "print(\"Done!. Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FowZLIjY-_D",
        "outputId": "9f68a452-a947-457a-cdc0-80ec772a645f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  8.49it/s, Accuracy=75.2%, Training_Loss=0.477]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 74.2%, val_Loss: 0.484050 \n",
            "\n",
            "best model in epoch=1 with Accuracy=75.2%\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  7.81it/s, Accuracy=75.9%, Training_Loss=0.469]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 76.5%, val_Loss: 0.467156 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  7.86it/s, Accuracy=75.7%, Training_Loss=0.471]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 77.0%, val_Loss: 0.465733 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:09<00:00,  8.65it/s, Accuracy=75.1%, Training_Loss=0.472]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 75.7%, val_Loss: 0.470965 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:08<00:00,  9.67it/s, Accuracy=75.6%, Training_Loss=0.471]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 76.7%, val_Loss: 0.463271 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[6/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:10<00:00,  8.35it/s, Accuracy=76.6%, Training_Loss=0.467]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 76.5%, val_Loss: 0.475570 \n",
            "\n",
            "Training:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[7/10 epochs,  2700/ 2700 data]: 100%|██████████| 85/85 [00:11<00:00,  7.72it/s, Accuracy=75.2%, Training_Loss=0.476]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: \n",
            " Accuracy: 75.8%, val_Loss: 0.465537 \n",
            "\n",
            "Early stopped training at epoch 7 due to 5 epochs whitout enhacement\n",
            "Done!. Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.set_title('Training and Val Plots')\n",
        "ax.plot(range(7), loss_train_history, label=\"Train Loss\")\n",
        "ax.plot(range(7), accuracy_train_history, label=\"Train Accuracy\")\n",
        "ax.plot(range(7), loss_val_history, label=\"Val Loss\")\n",
        "ax.plot(range(7), accuracy_val_history, label=\"Val Accuracy\")\n",
        "ax.set_xlabel(\"Epochs\")\n",
        "ax.set_ylabel(\"Train\")\n",
        "ax.legend()\n",
        "\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "s-rFDprhy4ib",
        "outputId": "b190f6a0-025c-402f-f7b8-4f8d13a0a4a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}